[
  {
    "objectID": "software/vscode/index.html",
    "href": "software/vscode/index.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "Visual Studio Code (VS Code) is a versatile code editor used for writing, editing, and developing text-based documents and programs. It is recommended for collaborative code-first data and technology projects at IPA.",
    "crumbs": [
      "Software Guides",
      "Code Environments",
      "VS Code"
    ]
  },
  {
    "objectID": "software/vscode/index.html#how-to-install-vs-code",
    "href": "software/vscode/index.html#how-to-install-vs-code",
    "title": "Visual Studio Code",
    "section": "How to Install VS Code?",
    "text": "How to Install VS Code?\nTo install VS Code, download and install the latest software version from the Visual Studio Code website or run the following from the command line if you have the Windows Package Manager, winget, installed:\n\nWindowsMacOSLinux\n\n\nwinget install Microsoft.VisualStudioCode\n\n\nbrew install --cask visual-studio-code\n\n\nsudo snap install code --classic",
    "crumbs": [
      "Software Guides",
      "Code Environments",
      "VS Code"
    ]
  },
  {
    "objectID": "software/vscode/index.html#using-vs-code",
    "href": "software/vscode/index.html#using-vs-code",
    "title": "Visual Studio Code",
    "section": "Using VS Code",
    "text": "Using VS Code\nThe best starting point for familiarizing yourself with VS Code is the documentation.\nSome particularly helpful references in the documentation are:\n\nEditing with VS Code\nGit Source control in VS Code\nPython in VS Code",
    "crumbs": [
      "Software Guides",
      "Code Environments",
      "VS Code"
    ]
  },
  {
    "objectID": "software/vscode/index.html#recommended-extensions",
    "href": "software/vscode/index.html#recommended-extensions",
    "title": "Visual Studio Code",
    "section": "Recommended Extensions",
    "text": "Recommended Extensions\nThe core software and functionality in VS Code gives you a lot of useful tools for writing, editing, and collaborating. Additionally, you can add functionality through Extensions.\nSome helpful extensions are the following:\n\nPython Extension - language syntax for Python programming\nRuff - Python linting and code formatting\nR Extension - Interacting with R from VS Code\nGitHub Pull Requests - review and manage GitHub pull requests and issues in Visual Studio Code\nJupyter Extension - for developing with jupyter notebooks\nJust - support for Justfiles\nQuarto Extension - support for writing and building Quarto projects\nMarkdown All in One - support for Markdown\nMarkdown Preview Mermaid Support - support for Mermaid diagrams in Markdown\nConventional Commits - support for writing easy to understand commit messages",
    "crumbs": [
      "Software Guides",
      "Code Environments",
      "VS Code"
    ]
  },
  {
    "objectID": "software/stata/data-processing-stata.html#sorting-data",
    "href": "software/stata/data-processing-stata.html#sorting-data",
    "title": "Data Processing in Stata",
    "section": "Sorting data",
    "text": "Sorting data\nNot only could it be useful, but crucial, to sort your observations in a particular way when cleaning or creating outcomes.\nYou can use the sort command in Stata to achieve this. Of course you can order your observation based on ordering one variable, but you can go further and sort your data on multiple variables. For example if you have a long dataset that contains two variables person id and survey round and for each person it has three survey rounds, then if you sort id round you will sort the data by person and within each person you will sort by the survey rounds.\n\nsort sorts observations in ascending order (i.e. lowest to highest)\nMissing values in stata are equivalent to infinity and thus will be sorted to the bottom of your sort if they exist\n\n*Example of points 1 and 2 above\nsysuse bplong, clear\n    sort when patient\n    sort patient when\n    preserve\n    replace when = . if _n == 25\n    sort when patient //where did the missing value get sorted to?\nrestore\n\nYou can flip the order you sort by using gsort and using a negative sign in front of the variable name (i.e. sort largest to smallest)\n\nsysuse bplong, clear\n*Use sort to see how it normally sorts males first (smallest to largest)\nsort sex patient\n\n/*\ngsort by -sex to see how to sort largest to smallest\n(Notice the patient order does not change within gender)\n*/\ngsort -sex patient\n\nIf the observations of the variables you sort on are not unique, Stata will randomize their order in a new randomization every time you sort (i.e. you will not get a consistent order if you re-run your code, even in a script)\n\nsysuse bplong, clear\n/*\nNotice that gender-patient does not uniquely identify\nour observations\n*/\nsort sex patient\n/*\nFlag the row numbers where Stata sorted the \"before\"\nobservations for each person\n*/\ngen flag_before1 = _n if when == 1\n*Do the exact same sort as above\nsort sex patient\n/*\nAgain flag the row numbers where Stata sorted the \"before\"\nobservations for each person this time\n*/\ngen flag_before2 = _n if when == 1\n/*\nNotice that the two flag_before variables are not always equal i.e.\nthe \"before\" observation ended up in a different place even though\nwe did the same sort twice\n*/\n\nYou have two options to make sure your sorts are consistent\n\nUse the option stable to make sure Stata uses the same randomization every time\n\nYou cannot use this option with `gsort’\n\nThe preferred method is to specify a combination of variables that uniquely identifies your observations. This removes the randomization and makes your sort outcome be exactly what you specify and expect\n\n\nsysuse bplong, clear\n/*\nNotice that gender-patient does not uniquely identify\nour observations\n*/\nsort sex patient when\n/*\nFlag the row numbers where Stata sorted the \"before\"\nobservations for each person\n*/\ngen flag_before1 = _n if when == 1\n*Do the exact same sort as above\nsort sex patient when\n/*\nAgain flag the row numbers where Stata sorted the \"before\"\nobservations for each person this time\n*/\ngen flag_before2 = _n if when == 1\n*Now the flags are always equal\n\nThe by function\nYou can use the by function to create variables within groups, but in order to use by you must sort before hand. Thus, we recommend to use bysort instead.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Data Processing in Stata"
    ]
  },
  {
    "objectID": "software/stata/data-processing-stata.html#bysort-gen-and-egen",
    "href": "software/stata/data-processing-stata.html#bysort-gen-and-egen",
    "title": "Data Processing in Stata",
    "section": "bysort, gen, and egen",
    "text": "bysort, gen, and egen\nbysort combined with gen/egen is probably one of the most useful command combinations when cleaning and creating outcomes.\n\nNotice that your data set will be sorted by all the variables (including those in parenthesis) you specify\nBut you will create new variables by only what variables you specify outside the parenthesis\nPay attention to whether the function you are using needs to specify gen or egen\n\nNotice that sum works for both gen and egen (even though it is not in the egen documentation and works differently\n\negen + sum = creates a total for all values specified in the by\ngen + sum = creates a cumulative sum over the observations specified\n\n\n\nSee help egen to read about all of the egen functions\nFurther: - You can ssc install egen more that has even more functions you can use. - You can ssc install ereplace to be able to use the egen functions but as a replace, so you don’t have to create multiples variables.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Data Processing in Stata"
    ]
  },
  {
    "objectID": "software/stata/data-processing-stata.html#preservingrestoring-data",
    "href": "software/stata/data-processing-stata.html#preservingrestoring-data",
    "title": "Data Processing in Stata",
    "section": "Preserving/restoring data",
    "text": "Preserving/restoring data\nYou can use collapse when you want to create summary statistics of your data, or some of your variables. Note that collapse works by replacing your data with the summary statistics of each variable that you request. If you are familiar with egen, you can think of collapse as equivalent to egen, except than rather making a new variable it replaces your variables. Additionally, any variables you don’t specify will be dropped. This means this command erases your data. Because of this destructive nature there are several best practices to use around collapse.\nIt is common you would like to maintain your dataset while outputting some summary statistics. You can quickly do this by preserving, collapsing, and then restoring your data.\nsysuse census, clear\npreserve\ncollapse (mean) pop (median) medage, by(region)\nsave \"example.dta\", replace\nrestore\n\n\n\n\n\n\nExplain why you use the statistic you choose\n\n\n\nIn the comments of your do-file, you should write why you chose the collapse statistic you chose for each variable. This is especially important when multiple statistics would result in the same thing and you chose one arbitrarily. For example, if you have a constant variable for what you are collapsing on, so you pick mean instead of mode or first non missing, this is important for someone to know later. If they are adding in more data and run into errors they need to know why you picked what you did and it will help them understand the data structure and errors.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Data Processing in Stata"
    ]
  },
  {
    "objectID": "software/stata/data-processing-stata.html#asserting-beforehand",
    "href": "software/stata/data-processing-stata.html#asserting-beforehand",
    "title": "Data Processing in Stata",
    "section": "Asserting beforehand",
    "text": "Asserting beforehand\nIt is important you code asserts before you collapse to check that you’re variables are what you are expecting. For example, if you think you have a constant var among the variables you are collapsing on - you should check prior to collapsing. If you are wrong, you could not know based on the stat you choose, and it is hard to check after the collapse since the data is gone.\n\n\n\n\n\n\nUsing egen, duplicates drop instead\n\n\n\nAn alternative to using collapse is using egen and the dropping duplicates instead. This way once you make your statistics you can do some assert functions to check that everything was created the way you think they were created.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Data Processing in Stata"
    ]
  },
  {
    "objectID": "software/stata/conditions-operators-stata.html",
    "href": "software/stata/conditions-operators-stata.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "software/quarto/index.html",
    "href": "software/quarto/index.html",
    "title": "Getting started with Quarto",
    "section": "",
    "text": "The following video provides a quick introduction to Quarto:",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Getting started with Quarto"
    ]
  },
  {
    "objectID": "software/quarto/index.html#how-to-install-quarto",
    "href": "software/quarto/index.html#how-to-install-quarto",
    "title": "Getting started with Quarto",
    "section": "How to install Quarto?",
    "text": "How to install Quarto?\n\nWindowsMacOSLinux\n\n\n# Install Quarto\nwinget install Posit.Quarto\n\n\n# Install Quarto\nbrew install --cask quarto\n\n\nTo install Quarto on Linux, see https://quarto.org/docs/get-started/",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Getting started with Quarto"
    ]
  },
  {
    "objectID": "software/quarto/index.html#using-quarto",
    "href": "software/quarto/index.html#using-quarto",
    "title": "Getting started with Quarto",
    "section": "Using Quarto",
    "text": "Using Quarto\nWe recommend using the Quarto Extension for Visual Studio Code. You can install the extension by searching for “Quarto” in the Extensions view (Ctrl+Shift+X). Alternatively, you can install the extension from the Visual Studio Code Marketplace.\nIf you use Jupyter Lab or RStudio, Quarto works directly with those tools as well.\nThe best place to start for learning how to use Quarto is Quarto’s tutorial, Hello, Quarto.\nAs an example, this repository uses Quarto to build the handbook.\nIn the root of the git repository, there is a _quarto.yml file that contains the metadata used to compile the handbook. Components of the handbook are written in Markdown, either standard Markdown (.md) or Quarto Markdown (.qmd). The benefit of standard markdown is that it is more portable and works with standard Markdown editors (e.g. GitHub), while Quarto markdown allows for computations that are embedded in the document. If you want more advanced formatting or computations, .qmd may be a preferable choice. The Quarto Documentation provides helpful guides on how to use Markdown as well as the added features that Quarto Markdown offers.\nFor an example of how to use Quarto within common academic and research workflows, see:",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Getting started with Quarto"
    ]
  },
  {
    "objectID": "software/quarto/index.html#learning-resources",
    "href": "software/quarto/index.html#learning-resources",
    "title": "Getting started with Quarto",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nTutorials:\n\nHello, Quarto\nComputations\nAuthoring\n\nQuarto Documentation\nQuarto Gallery of Examples",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Getting started with Quarto"
    ]
  },
  {
    "objectID": "software/python/index.html#how-to-install-python",
    "href": "software/python/index.html#how-to-install-python",
    "title": "Python",
    "section": "How to install Python?",
    "text": "How to install Python?\nThere are many ways to install Python. We recommend using Python in a virtual environment to avoid conflicts with other Python installations on your system.\nWe recommend using uv as a a simple way to create and manage Python virtual environments.\nYou can manage the python packages that are installed in the virtual environment using a pyproject.toml file. See the pyproject.toml example in this repository for an example of how to manage Python packages. To add package dependencies to the virtual environment, using uv, you can run:\nFirst, install uv using winget (Windows) or brew (MacOS/Linux):\n\nWindowsMacOSLinux\n\n\n# Install uv\nwinget install astral-sh.uv\n\n\n# Install uv\nbrew install uv\n\n\n# Install uv\nbrew install uv\n\n\n\nAdd libraries to the virtual environment using uv add ...:\n\n&gt; uv add jupyterlab pandas matplotlib seaborn",
    "crumbs": [
      "Software Guides",
      "Python",
      "Getting Started with Python"
    ]
  },
  {
    "objectID": "software/python/index.html#coding-conventions",
    "href": "software/python/index.html#coding-conventions",
    "title": "Python",
    "section": "Coding Conventions",
    "text": "Coding Conventions\nWe highly recommend working with a virtual environment to manage Python dependencies. The pyproject.toml is the preferred way to keep track of python dependencies as well as project-specific python conventions.\nWe recommend using Ruff to enforce linting and formatting rules. In most cases you can use the default linting and formatting rules provided by ruff. However, you can customize the rules by modifying the [tool.ruff] section of the pyproject.toml file in the root of your project. for more about the configuration options, see the Ruff documentation.\nIf you are working in a virtual environment created in this repository, you automatically have access toRuff via just lint-py and just fmt-python commands to lint and format your code.\nFor more inspiration, see the GitLab Data Team’s Python Guide and Google’s Python Style Guide.",
    "crumbs": [
      "Software Guides",
      "Python",
      "Getting Started with Python"
    ]
  },
  {
    "objectID": "software/python/index.html#example-usage",
    "href": "software/python/index.html#example-usage",
    "title": "Python",
    "section": "Example Usage",
    "text": "Example Usage\nLet’s load an example World Bank data via Gapminder using the causaldata package.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.formula.api as sm\nfrom causaldata import gapminder\n\nLoad the Gapminder data as a pandas DataFrame:\n\ndf = gapminder.load_pandas().data\n\nWe can check the dimensions of the DataFrame using df.info():\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   country    1704 non-null   object \n 1   continent  1704 non-null   object \n 2   year       1704 non-null   int64  \n 3   lifeExp    1704 non-null   float64\n 4   pop        1704 non-null   int64  \n 5   gdpPercap  1704 non-null   float64\ndtypes: float64(2), int64(2), object(2)\nmemory usage: 80.0+ KB\n\n\nLet’s take a look at the first few rows of the DataFrame using df.head():\n\ndf.head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n\n\n\n\n\nTake a look at the relationship between GDP per Capita and Life Expectancy:\n\nsns.scatterplot(x=\"gdpPercap\", y=\"lifeExp\", hue=\"continent\", data=df).set(\n    xscale=\"log\", ylabel=\"Life Expectancy\", xlabel=\"GDP per Capita\"\n)\n\n\n\n\n\n\n\n\nSeparate the data by year, focusing on 1957 and 2007:\n\nsns.relplot(\n    data=df.where(df[\"year\"].isin([1957, 2007])),\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    col=\"year\",\n    hue=\"continent\",\n    col_wrap=1,\n    kind=\"scatter\",\n    palette=\"muted\",\n).set(xscale=\"log\", ylabel=\"Life Expectancy\", xlabel=\"GDP per Capita\")",
    "crumbs": [
      "Software Guides",
      "Python",
      "Getting Started with Python"
    ]
  },
  {
    "objectID": "software/python/index.html#learning-resources",
    "href": "software/python/index.html#learning-resources",
    "title": "Python",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nThe Python Tutorial\nPython Data Science Handbook\nEfficient Python for Data Scientists\nThe Hitchhiker’s Guide to Python",
    "crumbs": [
      "Software Guides",
      "Python",
      "Getting Started with Python"
    ]
  },
  {
    "objectID": "software/guides/venv.html#python-virtual-environments",
    "href": "software/guides/venv.html#python-virtual-environments",
    "title": "Virtual Environments",
    "section": "Python Virtual Environments",
    "text": "Python Virtual Environments\nWe recommend using uv to manage Python virtual environments as it provides an overarching framework for managing Python installations and virtual environments. See information on uv in the uv documentation.",
    "crumbs": [
      "Software Guides",
      "Coding Guides",
      "Virtual Environments"
    ]
  },
  {
    "objectID": "software/guides/venv.html#r-virtual-environments",
    "href": "software/guides/venv.html#r-virtual-environments",
    "title": "Virtual Environments",
    "section": "R Virtual Environments",
    "text": "R Virtual Environments\nR virtual environments can be created using the renv package. See documentation for more information about how to use renv.",
    "crumbs": [
      "Software Guides",
      "Coding Guides",
      "Virtual Environments"
    ]
  },
  {
    "objectID": "software/guides/venv.html#docker",
    "href": "software/guides/venv.html#docker",
    "title": "Virtual Environments",
    "section": "Docker",
    "text": "Docker\nDocker is a tool that allows you to create, deploy, and run applications using containers. In some instances, it may be more appropriate to use Docker containers to manage your project environment, especially when there is a project environment that needs to be deployed to cloud computing services.",
    "crumbs": [
      "Software Guides",
      "Coding Guides",
      "Virtual Environments"
    ]
  },
  {
    "objectID": "software/guides/venv.html#learning-resources",
    "href": "software/guides/venv.html#learning-resources",
    "title": "Virtual Environments",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nA Complete Guide to Python Virtual Environments\nReal Python, Python Virtual Environments\nPython Virtual Environments\nR Virtual Environments",
    "crumbs": [
      "Software Guides",
      "Coding Guides",
      "Virtual Environments"
    ]
  },
  {
    "objectID": "software/git/index.html",
    "href": "software/git/index.html",
    "title": "Git",
    "section": "",
    "text": "Click on the image below to watch a video with an introduction to Git for beginners:",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "Git"
    ]
  },
  {
    "objectID": "software/git/index.html#how-to-install-git",
    "href": "software/git/index.html#how-to-install-git",
    "title": "Git",
    "section": "How to install Git?",
    "text": "How to install Git?\nInstall Git for Windows via winget. Git comes pre-installed with MacOS and Linux, if you can’t find it, try installing with Homebrew.\n\nWindowsMacOSLinux\n\n\nwinget install Git.Git\n\n\n# Git comes pre-installed with most MacOS distributions.\ngit --version\n\n\n# Git comes pre-installed with most Linux distributions.\ngit --version",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "Git"
    ]
  },
  {
    "objectID": "software/git/index.html#using-git",
    "href": "software/git/index.html#using-git",
    "title": "Git",
    "section": "Using Git",
    "text": "Using Git\nGit can be confusing and overwhelming. We recommend starting with a graphical user interface (GUI) to help you understand the basics of Git. GitHub Desktop is a good option or, if you use VS Code, you can use the built-in Git functionality (See VS Code documentation).\nClick on the image below to watch a video on basic Git commands:\n\n\n\nBasic Git Commands\n\n\nHere are the basic commands you need to know to get started with Git:\n\ngit init\nCreate a new Git repository\ngit init\n\n\ngit clone\nClone a repository into a new directory For example, to clone the IPA handbook repository:\n# If using HTTPS\ngit clone https://github.com/PovertyAction/ipa-data-tech-handbook.git\n\n# If using SSH\ngit clone git@github.com:PovertyAction/ipa-data-tech-handbook.git\n\n\ngit checkout\nBranches are used to develop new code or modify existing code such that the “main” code is not affected until the new code is ready. To create a new branch, use:\ngit checkout -b new-branch-name\nThis checks out a new branch called new-branch-name. To switch back to the main branch, use:\ngit checkout main\nTo checkout a branch from the remote repository, use:\ngit fetch origin\ngit checkout --track origin/remote-branch-name\nTo push a branch to the remote repository, use:\ngit push origin new-branch-name\nTo delete a branch, use:\ngit branch -d new-branch-name\nList all local branches:\ngit branch --list\n\n\ngit add\nAdd files that have changed and are ready to be committed to the staging area. To add a file, file_name.md, use:\ngit add file_name.md\n\n\ngit commit\nCommit changes to the checked out branch.\nGood commit messages follow the following format:\ngit commit -m \"&lt;type&gt;: &lt;description&gt;\"\nTo commit changes with a message, use:\ngit commit -m \"feat: adding new feature to the codebase\"\n\n\ngit push\nSend changes to the remote repository. To push any commits to remote use the following:\ngit push origin new-branch-name\nIf you are pushing a new branch to the remote repository, use:\ngit push --set-upstream origin new-branch-name\nConsider adding the Conventional Commits extension to your VS Code to help you write good commit messages.",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "Git"
    ]
  },
  {
    "objectID": "software/git/index.html#best-practices",
    "href": "software/git/index.html#best-practices",
    "title": "Git",
    "section": "Best Practices",
    "text": "Best Practices\n\nAlways include a README file in your repository and keep it up to date with key information that anyone who visits your repository should know for using, replicating, or contributing to code in the repository.\nUse branches to develop new features or fix bugs. This helps to keep the main branch clean and stable.\nWrite clear and concise commit messages. A good commit message should describe what changes were made and why they were made. Refer to Conventional Commits for good practice in writing commit messages.\nPush changes to the remote repository frequently. This helps to keep your codebase up to date and allows others to collaborate with you.\nUse pull requests to propose changes to the main branch. Try to keep the pull request small such that there is a manageable amount of code to review.",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "Git"
    ]
  },
  {
    "objectID": "software/git/index.html#learning-resources",
    "href": "software/git/index.html#learning-resources",
    "title": "Git",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nGitHub’s YouTube Git for Beginners\nGitHub’s Git Cheat Sheet\ngit - the simple guide\nGit Best Practices\nHappy Git with R\nVisual Git Guide\nVisualizing Git with D3",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "Git"
    ]
  },
  {
    "objectID": "research-design/measurement.html#what-is-stata",
    "href": "research-design/measurement.html#what-is-stata",
    "title": "Research Design",
    "section": "What is Stata?",
    "text": "What is Stata?\nStata is a statistical software package that is commonly used in the social sciences and economics. It is widely used at IPA for data analysis and management. It offers a comprehensive library of methods for data cleaning, descriptive statistics, and econometric analysis. Stata is very well suited for research data workflows and research design tasks, including power calculations, sample design adjustments, panel data analysis, time series analysis, etc. See Stata Features for a full list of what Stata makes available."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Welcome to IPA’s central research hub - your gateway to open-source tools, methodological resources, and collaborative projects driving evidence-based policymaking worldwide."
  },
  {
    "objectID": "index.html#research-and-data-science-hub",
    "href": "index.html#research-and-data-science-hub",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Welcome to IPA’s central research hub - your gateway to open-source tools, methodological resources, and collaborative projects driving evidence-based policymaking worldwide."
  },
  {
    "objectID": "index.html#about-the-hub",
    "href": "index.html#about-the-hub",
    "title": "Research & Data Science Hub",
    "section": "About the Hub",
    "text": "About the Hub\nThe IPA Research Data Science Hub serves as the nexus for:\n\nData Cleaning: Best practices and tools for data validation and cleaning\nData Collection: Guidelines for field data collection and digital tools\nData Security: Protocols and tools for secure data handling\nIRB and Ethics: Research ethics guidelines and IRB processes\nResearch Design: RCT design, sampling, and implementation methods\nSoftware: Open-source tools and code repositories for research\n\n\n\n\n\n\n\nTip\n\n\n\nGet Involved\n📧 researchsupport@poverty-action.org 🔗 Contribution Guidelines"
  },
  {
    "objectID": "ethics-irb/irb-lifecycle.html#initial-application",
    "href": "ethics-irb/irb-lifecycle.html#initial-application",
    "title": "The IRB Lifecycle",
    "section": "Initial Application",
    "text": "Initial Application\nThe IRB project lifecycle starts with the online submission of the initial application. An initial application is submitted to formally apply for IRB review and approval should be secured prior to implementation of a new research study. In this process, the IRB determines the level (expedited or full board) and frequency of continuing review (1 or 3 years).\nThe submission should include the following documents:\n\nIPA IRB Initial Application Form (once approved, it becomes the study’s protocol)\nInstruments (e.g, surveys, interview/focus group discussion guides, observation forms)\nInformed consent forms (IPA IRB consent checklist and template can be used to ensure all required and assessed elements are included)\nHuman Subjects Certificates for all Principal Investigators (PIs) and research personnel. Human Subjects training certification must be renewed every 3 years to be considered valid for approval\nIRB approval from local IRBs and/or other institutions\nData Sharing Agreements\nAny other supporting documents",
    "crumbs": [
      "Ethics and IPA IRB",
      "The IRB Lifecycle"
    ]
  },
  {
    "objectID": "ethics-irb/irb-lifecycle.html#amendments",
    "href": "ethics-irb/irb-lifecycle.html#amendments",
    "title": "The IRB Lifecycle",
    "section": "Amendments",
    "text": "Amendments\nAmendments are modifications to the previously approved study protocol or documents. These modifications should be IRB-reviewed and approved prior to implementation to ensure that the regulatory criteria for IRB approval are still met and that the risk/benefit ratio remains reasonable. Amendments must be submitted via online submission and should include the following documents:\n\nIPA IRB Amendment Form\nUpdated protocol\nUpdated instruments (if proposing changes)\nUpdated informed consent forms (if proposing changes)\nUpdated Human Subjects Certificates (if expired or proposing changes to PIs and/or research personnel)\nAny other supporting documents",
    "crumbs": [
      "Ethics and IPA IRB",
      "The IRB Lifecycle"
    ]
  },
  {
    "objectID": "ethics-irb/irb-lifecycle.html#renewals",
    "href": "ethics-irb/irb-lifecycle.html#renewals",
    "title": "The IRB Lifecycle",
    "section": "Renewals",
    "text": "Renewals\nRenewals allow the IRB to provide continuing oversight of a research study by reviewing its progress and determining whether it continues to meet the regulatory criteria for approval. The renewal frequency is determined in the initial application review, can be found in the approval letter and depends on risk level, funding and start date. The renewal frequency is every 3 years for studies that meet the following requirements:\n\nMinimal risk\nNot federally funded\nDon’t include vulnerable populations\nDon’t include sensitive questions\nStarted after October 2022\n\nAll other studies should be renewed annually. Renewals must be submitted via online submission and should include the following documents:\n\nIPA IRB Renewal Form\nUpdated protocol (if also proposing changes)\nUpdated instruments (if also proposing changes)\nUpdated informed consent forms (if also proposing changes)\nUpdated Human Subjects Certificates (if expired or proposing changes to PIs and/or research personnel)\nAny other supporting documents\n\n\n\n\n\n\n\nAvoid delays or other issues by following IRB dates\n\n\n\nRenewals should be submitted well in advance of the expiration date to avoid lapses in IRB approval. If a study’s approval expires, all research activities involving human subjects (e.g., data collection, contact with subjects, analysis of personally identifiable data (PII)) must stop until renewal is granted. If the renewal includes modifications, these proposed changes should be reviewed and approved prior to implementation.",
    "crumbs": [
      "Ethics and IPA IRB",
      "The IRB Lifecycle"
    ]
  },
  {
    "objectID": "ethics-irb/irb-lifecycle.html#unexpected-events",
    "href": "ethics-irb/irb-lifecycle.html#unexpected-events",
    "title": "The IRB Lifecycle",
    "section": "Unexpected Events",
    "text": "Unexpected Events\nUnexpected events are events that are not listed as risks in the protocol and/or informed consent forms like deviations or adverse events that result in harm to subjects. They must be reported to the IRB via online submission within 5 days and should include the following documents:\n\nIPA IRB Unexpected Event Form\nUpdated protocol (if needed)\nAny other supporting documents\n\n\n\n\n\n\n\nTip\n\n\n\nOnce submitted, the IRB may require a corrective action plan to address the problem and, depending on the findings, additional reporting (e.g., to donor) may be required.",
    "crumbs": [
      "Ethics and IPA IRB",
      "The IRB Lifecycle"
    ]
  },
  {
    "objectID": "ethics-irb/irb-lifecycle.html#closure",
    "href": "ethics-irb/irb-lifecycle.html#closure",
    "title": "The IRB Lifecycle",
    "section": "Closure",
    "text": "Closure\nA closure submission notifies the IRB the study is complete and ends the study team’s obligation to provide updates, resulting in the end of the IRB oversight. Closures must be submitted via online submission and should include the following documents:\n\nIPA IRB Closure Form\nAny other supporting documents\n\nStudies can be closed when data collection or interaction with subjects is done AND data analysis with PII is done",
    "crumbs": [
      "Ethics and IPA IRB",
      "The IRB Lifecycle"
    ]
  },
  {
    "objectID": "ethics-irb/irb-docs.html",
    "href": "ethics-irb/irb-docs.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Ethics and IPA IRB",
      "IRB Documentation 🚧"
    ]
  },
  {
    "objectID": "data-quality/survey-plan.html#developing-a-survey-plan",
    "href": "data-quality/survey-plan.html#developing-a-survey-plan",
    "title": "Survey Planning",
    "section": "Developing a Survey Plan",
    "text": "Developing a Survey Plan\nA survey plan needs to be written as you design your questionnaire and make decisions on whether it should be an electronic or paper survey. You will need to share your survey plan with others working with you like the Country Director, PI’s, country level and HQ survey support staff. For paper surveys, as early as possible give a heads up to the in-house data entry staff, if you have a data entry unit in your country or a data entry company so you can make sure your timeline fits their schedule and you can get the data as quickly as possible after fieldwork finishes. The same applies for dedicated programming staff if your survey is digital. Your survey plan can work as a running document where you fill details as you figure them out. It should include the following:\n\nQuestionnaire Development: piloting questionnaires, translation, back translation, who will be involved at these stages, where will you pilot the survey - keep in mind not to go to actual survey respondents but find people similar – and how will you analyze the data.\nManpower: who do you need to hire for surveying and quality control and what are the payment structures for staff. When will you hire people – think about the structure and composition you want for your team. You might want to hire some senior people to help you with piloting the questionnaire and hiring other surveyors who will serve as team leaders/field managers when you start actual surveying. You might decide to go with a survey company. If you do, consider what they will take care of and what you will. Read the guide to deciding between a survey company and hiring your own team, and the quality control guide.\nTimeline for data collection: when will piloting the questionnaire happen, when will training happen, when will surveying start and finish. Read the section on timeline below.\nLogistics: how will you move teams across survey regions, transportation, accommodation, food etc. If you’re surveying electronically, how you will charge, store and secure your devices. Read the section on logistics below.\nSurvey Tracking: how will you stay on top of the progress made in surveying, how many surveys should be completed per day, monitor data collection and keep track of which surveys are being checked.\nRespondent tracking: what information do you want to collect, who tracks hard to find respondents, how much time do you devote, how do you decide when to drop a respondent, what’s your replacement plan. Read the guideline on tracking respondents.\nStorage: where will surveys or electronic devices be stored – Do you need a field office?\nTraining Surveyors: where will training happen, how long will it go on for, what should be on the training agenda, how will you incorporate as much field training as possible, how many surveyors do you want to recruit. Read the materials on training surveyors and creating a survey manual.\nWhat equipment and other items do you need to buy: gifts for respondents, any equipment for taking anthropometric measurements, other survey material (e.g., stationery) for surveyors. Read the section on survey materials below.\nYour time: You are responsible for the whole survey and there are a number of things happening simultaneously that require your attention. It might be a good idea to designate time for things- e.g., Friday look at back check data, Monday go out to the field – so that you don’t forget anything during data collection.\n\n\nTimeline\nWhile estimating when the survey will be complete is an inexact art, it is essential to do it well because data is often time-sensitive and must be collected while a program is running. Data collection must occur within a specific period to be comparable to others in the same survey or your budget restricts you to a long or short survey period. That means you need to plan realistically what your team can accomplish, learn immediately if you are falling behind your timeline and adapt quickly with a revised plan.\nSpecific plans vary according to the programs being evaluated, the survey, team structures, and geography. The core of your plan is deciding how many surveys you expect each person to complete each day. The following are some general principles that should guide this calculation:\n\nTraveling to Respondents: You need to develop a good sense of how long it’ll take to find a specific respondent. This may vary across the regions, districts or neighborhoods in your sample. Before fielding the survey, figure out which areas will be the most difficult to find respondents and which will be relatively easier. Consult maps with roads and anyone with local knowledge, from local partners to shop owners. Also, think about how long it’ll take surveyors to get to the survey area from their accommodation and include this in your calculation of the working day. It’s tempting to not include travel time in your work day, but you do this at your own peril. Travel time is one of the most common factors that delay a survey.\nFinding Hard to Find Respondents: Finding all respondents in a cluster often requires several attempts and needs to be factored into your expectations of how many surveys your team will perform each day. Identify what is the best time to find respondents in your survey sample- e.g., if it’s a period of heavy agricultural activity most people may be at their farms for some duration of the day and try to find out what time this might be. Finding respondents in the follow-up/endline survey will take more time than the baseline as some respondents may have moved and your team will need to sleuth out additional information to find them. Read the guide on Respondent Tracking.\nSurvey Time: From the piloting of the questionnaire, you should have a sense of how long it takes to complete a single questionnaire. Based on this estimate as well as travel and tracking time, set a target number of surveys to be completed per day by each surveyor. Keep in mind that during the initial days of the survey, most surveyors will not reach their target. However, it is advisable that this only be factored into your timeline and average daily return calculations, but not into the daily target you set for your team. Surveyors should be given target estimates based on what is expected to be completed per day after the initial slowness of data collection is over.\nHolidays: Be sure to factor in national and local holidays. Consult with partner staff about which holidays they follow and could affect respondent availability. Some locations have so many holidays it may seem impossible to work!\nTreatment/Control Balance: Finally, be sure that treatment and control respondents/areas are surveyed in a balanced manner. Don’t survey all the controls and then all the treatment, but rather try to survey them simultaneously and as evenly as possible over the survey period.\n\n\n\nLogistics\nAs a field RA, your job is to make sure everything happens when it is supposed to, which means you need to be a mean multitasker and be able to inspire the best out of your survey team. Delegating the logistics in large surveys to a survey company or in-country management teams reduces some of the management burden, but you will still need to verify proper planning and timely execution. If surveying is considered a low paying, low skilled job in your area it might not attract people who take the initiative to recognize whether they have everything they need to do their job. Think about building in accountability systems into your field plan to incentivize people to meet targets and tell you when they hit a roadblock in the field.\nIn general, when planning the movement of teams, start with easy places to survey. Surveyors generally take more time in the early days to reach their target number of respondents and working in villages that are close by or where you’ll be able to find respondents easily reduces stress on you and your team. If the survey launches in several regions of the country simultaneously, consider a phased start of surveying so you can spend time with each team as they launch to be able to put out fires and improve practices before the whole team starts surveying.\nHere are some things to consider when planning logistics:\n\nTransportation Methods: How will the teams travel to villages and sometimes even within villages? Will you give them a travel allowance and they organize their own transportation or will you need to organize a communal method? If you’re organizing, how many teams can fit in a minivan? Does every team need their own vehicle?\nDirections to survey locations: Maps may not always give you the most accurate directions to a village. How will you find villages? How will you make sure that it is the right village? Who is responsible for making sure the team is in the right location?\nAccommodation: Where will teams stay? Will they find their own accommodation or will you need to organize? Are there convenient accommodation options close to the villages you survey? If not, should you think about teams staying in villages? In this case, arrangements (mattresses, cooking equipment) will need to be organized. It is advisable for teams to stay together when they need to stay outside their home base. This allows you to make sure everyone arrives on time and coordinate evening meetings when the team comes back. If they make their own accommodation arrangements, consider imposing penalties for late arrivals because it slows down the whole team.\nFood: Where will people have their lunch? How long are they allowed to break on the field? Are there options in the village or will they need to travel far to find food? Encourage teams to pack their own food if this is the case.\nCommunicating with Local Authorities: You may need to get permission to survey from district officials. Print letters that can be given to officials- decide who will go meet them.\nFinding the right respondent: How will the surveyors a) find the respondent and b) make sure it’s the right respondent? One option is to send mobilizers (well-informed and trusted community members or leaders) before the survey team to find respondents and slot interview appointments so that the surveyors don’t waste time finding respondents.\nEquipment: how are you printing all survey materials? How will you distribute them to staff? For phone surveys, how are you distributing SIM cards? How are you managing the sign-in and sign-out of devices/tablets/phones? Is there any other equipment that enumerators need to complete surveys?\nProductivity: How many surveys should each enumerator strive to complete per day? How will they know which respondents to attempt on each working day?\nInternet access: For digital data collection in particular, you should consider what speed of internet is available and how reliable it is. You also need to think about whether the internet is sufficient for uploading the types of files that you have. For example, audio files require much more bandwidth than survey data. For remote areas, consider setting up a local area network at your field office, to enable analysis of collected data without connecting to the internet. SurveyCTO offline sync simplifies this process. Be sure that you have a plan for sending airtime to enumerators to conduct and send in surveys once they are completed. If you are offering airtime as a respondent gift, you should set up the system for sending to specific phone numbers.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Survey Planning"
    ]
  },
  {
    "objectID": "data-quality/survey-plan.html#financial-plan",
    "href": "data-quality/survey-plan.html#financial-plan",
    "title": "Survey Planning",
    "section": "Financial Plan",
    "text": "Financial Plan\nManaging your finances is one of the biggest, hidden headaches of keeping your field team moving. How you’re going to get money to the team, when they will be paid and how much should definitely be part of your field plan. Here are a few things to consider when creating your financial plan:\n\nPayment Lag: Keep in mind that there is often a lag between when surveyors start work and they get paid. If you are paying surveyors per diems and transport allowance, this can be a problem if they are required to buy their own transportation fuel or food upfront. Consider providing these until they are paid, giving a start of project bonus or loan (which can be automatically deducted from their first payment). Failing to plan for this can slow the launch of a survey.\nPaying in Cash vs. Direct Deposit: Definitely discuss this decision with your in-country management team. In countries where you can deposit funds into bank accounts, remember that it can take a significant amount of time to withdraw money from a bank. If you’re paying per diems this way, it can lead to field delays and needs to be accounted for in your timeline. While cash may be easier to make happen logistically and result in few delays, it is also a major security risk. Make sure you have procedures in place to get the money safely from the bank and then hold your team accountable so you can de-incentivize them from embezzling funds and catch any money problems early.\nSending Airtime/Internet to Enumerators and Respondents: Create a system for sending internet to respondents if you are offering airtime as a respondent gift. Ideally, you should have someone in your office or give enumerators the ability to send airtime directly to a phone number. Enumerators must have enough internet to send in surveys or airtime to conduct surveys if they are conducting phone surveys.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Survey Planning"
    ]
  },
  {
    "objectID": "data-quality/survey-plan.html#survey-materials",
    "href": "data-quality/survey-plan.html#survey-materials",
    "title": "Survey Planning",
    "section": "Survey Materials",
    "text": "Survey Materials\nMake field departure and return checklists of things people need to do before they go out into the field and close for the day. Consider pasting these procedures to your office on the door so people can check if they have everything they need before they head out.\nThe field leadership team, i.e. Team Leader, Field Managers, is responsible for making sure this is followed. You may want to consider creating tracking forms, sign in/out sheets to help hold them and the team accountable. This is especially important in electronic surveying as you want to be sure that equipment like phones, PDAs, and netbooks are well-taken care of and you can hold the right person accountable if one is lost.\n\nEquipment\nMany projects need to purchase equipment for the field office or to collect anthropomorphic measures such as height, weight, or health indicators. Many institutions require getting price quotes from three or more vendors, which is a good practice, and will help you develop your negotiating skills. You should take an inventory of your office equipment, including the condition, at the beginning and end of the survey period to make sure nothing is lost or damaged.\nFor all equipment going to the field, it is highly recommended to put serial numbers on each piece and have surveyors check them out and check them in regularly for inspection. These machines are often subjected to rough conditions, and depreciate quickly. One way to improve your data is to have surveyors record the serial number of the machine used for each survey. That will help you identify systematic errors in machines.\n\n\nGPS Units\nSome surveys use GPS units to record GPS readings to aid in locating and verifying the right household in subsequent surveys. Often team leaders or people doing the census exercise are responsible for taking GPS readings to minimize the number of units required. Make sure you send them with additional batteries and budget for a few more GPS units than the people taking GPS readings to allow for units breaking on the field. Be sure to set the same coordinate format on all units before sending them to the field so you don’t have to convert them later.\nOne point to note about GPS readings is that they are helpful in finding respondents in subsequent surveys but may not be sufficient. Unless you have GPS units that are accurate to within 5 meters there is bound to be some confusion in subsequent surveys. Traditional tracking methods – such as hand-drawn maps, collecting phone numbers and contacts – should be used to complement the GPS readings and provide a secondary method to find respondents. These methods should not be abandoned simply because GPS readings are taken.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Survey Planning"
    ]
  },
  {
    "objectID": "data-quality/survey-plan.html#tablets-and-phones",
    "href": "data-quality/survey-plan.html#tablets-and-phones",
    "title": "Survey Planning",
    "section": "Tablets and phones",
    "text": "Tablets and phones\nIPA recommends buying devices from trusted brands such as Samsung or Google. It is important to buy sturdy cases to avoid breaking your devices. Many projects will find that extra battery packs are a necessity in the field. You should do field piloting of your devices to work out the kinks early on so you can budget for the necessary equipment when making your survey plan. You should also consider buying a gasoline or diesel generator if power is unreliable.\nIf you are conducting a phone survey, be sure that enumerators also have headphones, battery packs, and charger cables. If you are asking enumerators to use their own phones, SIM cards should be provided so enumerators are not using their own phone numbers.\n\nEquipment for surveyors\nYou will need to make sure that your team has all the basic equipment it needs for the field. This includes: - Bags and Folders: for surveyors to organize their questionnaire. Consider getting something durable and rain proof to protect equipment and/or questionnaires. - Umbrellas/Rain Coats: If you’re asking your team to work through rainy season, this can help them persevere through a drizzle. - Stationery Items: include pencils, sharpeners and erasers and, potentially, a stapler per team. - ID cards for surveyors: This helps surveyors establish credibility when surveying. T-shirts and hats with the IPA logo can also help.\n\n\nRespondent gifts/ incentives\n\nChoosing gifts\nOften surveys give the respondent gifts or incentives to compensate them for their time. Some surveys have given money but it is recommended that it be used rarely and preferably only when you’re taking someone’s time when they would otherwise be working. Sometimes the money for respondent gifts is used to play games eliciting risk aversion, however, this runs the risk of some respondents feeling under-compensated and moreover surveyors might like to be nice to respondents and let them “win” coin tosses.\nGenerally, you do not want to choose a gift that is extremely valuable to the survey respondent. This can run into issues with ethics since it is important to avoid having undue influence when a respondent feels they have no choice but to be interviewed because of the incentive involved. Because of this, survey gifts must be approved by your IRB.\nSome of the items that have been given by past IPA projects include sugar, cooking oil, washing soap bars, pencils, and sharpeners for school kids. Some projects have also given IPA T-shirts and IPA key chains but be careful with these. In a project in Ghana, farmers were given IPA T-shirts and some farmers wanted to form an association of IPA respondents in a village!\nItems for the household are a safe bet because they’re useful no matter which respondent receives the gift. Some of these items could be bulky, making it a struggle to carry them on the field. You need to factor in how the team will carry these items on the field, since spillage or leaking may damage surveys or expensive equipment if they’re carried in the same bag. One common gift phone cards since are easy to cart around, and they facilitate phone back checks or tracking later on. With all gifts, and phone cards in particular, the challenge is to set up a system to verify that respondents received their gifts and they were not taken by the surveyors. Consider including a question in your back check survey about receiving the gift or a shorter phone follow up.\n\n\nTreatment v. Control Gifts\nIf you’re working on a project where a loan or capital is given as one of the treatments, you may want to consider a) how you present the cash to the respondents and b) a nice gift for the control group as well to maintain good relations. It can be hard to maintain a good relationship with control respondents when they hear that others participating in the study received 100GHC and they didn’t. No matter how many times you explain it’s random, like winning the lottery, you will still have some disgruntled respondents. Projects have given control groups nicer gifts from flashlights to nice sets of stationery to compensate for the disappointment of not receiving a big prize. Another thing to consider is how the gift is presented. You may want to allow respondents to rip open an envelope or scratch off a scratch card to heighten the feeling of winning a prize, rather than simply being given a gift for their time.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Survey Planning"
    ]
  },
  {
    "objectID": "data-quality/ipa-research-protocols.html",
    "href": "data-quality/ipa-research-protocols.html",
    "title": "IPA Research Protocols",
    "section": "",
    "text": "Every research project at IPA is required to follow research protocols, or “Minimum Must Dos” to ensure that IPA produces high-quality research.\n\n\n\n\nIPA Research Protocols for High-Quality Research (® David Torres)\n\n\nIPA’s Research Protocols are organized into three main categories. Click on each protocol below to learn more.\n\n\n\n\n\n\nData Management System - DMS\n\n\n\n\nIPA Data Management System (IPA-DMS)\n\nThe IPA Data Management System (IPA-DMS) is a fundamental tool that standardizes data quality practices across IPA projects. It provides a structured framework for data cleaning, documentation, and quality control throughout the research lifecycle.\n\n\n\n\n\n\n\n\nData Quality\n\n\n\n\nSurvey Plan\nData Quality Action Plan\nBench Test\nPilot Survey\nAccompany Surveyors\nHigh Frequency Checks\nBackchecks\nDouble Entry\n\n\n\n\n\n\n\n\n\nData Security and Research Ethics\n\n\n\n\nMaintain active IRB approval\nCreate data security protocols\nFollow data security protocols\nData anonymization\nComplete IRB closeout process\n\n\n\n\n\n\n\n\n\nKnowledge Management and Transparency\n\n\n\n\nMaintain data backups\nStore all files on Box\nRegister with AEA\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Quality",
      "About Data Quality"
    ]
  },
  {
    "objectID": "data-quality/hfcs.html#what-are-high-frequency-checks",
    "href": "data-quality/hfcs.html#what-are-high-frequency-checks",
    "title": "High Frequency Checks",
    "section": "What are High Frequency Checks?",
    "text": "What are High Frequency Checks?\nHigh Frequency Checks (HFCs) are systematic checks performed on survey data at regular intervals, such as daily or weekly, during data collection. These checks help identify and correct issues or mistakes in the survey process promptly, ensuring the data collected is of high quality. By catching errors early, teams can make necessary adjustments to the survey or data collection methods, leading to more reliable and accurate data.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "High-Frequency Checks"
    ]
  },
  {
    "objectID": "data-quality/hfcs.html#why-is-important-to-implement-high-frequency-checks",
    "href": "data-quality/hfcs.html#why-is-important-to-implement-high-frequency-checks",
    "title": "High Frequency Checks",
    "section": "Why is important to implement High Frequency Checks?",
    "text": "Why is important to implement High Frequency Checks?\nHigh-frequency checks (HFCs) evaluate different aspects of the data collection process and are completed regularly as new data is collected. At IPA/J-PAL, HFCs are typically implemented in Stata after the data flow is complete. These checks provide insights into:\n\nThe quality of the data\nEnumerator performance\nErrors in the electronic survey program\nSystematic flaws in the data flow\n\nGiven their importance, high-frequency checks are one of the major benefits of Computer-Assisted Interviewing (CAI). Unlike CAI logic checks, which are pre-programmed into the survey tool, HFCs are conducted post-data collection to identify trends across surveys.\n\nTypes of High Frequency Checks\n\nDaily Logic Checks\n\nVerify the survey form version\nDetect duplicate observations and unique variable duplicates (e.g., GPS, phone number)\nEnsure critical variables are not missing\nIdentify variables with all missing values\nReview “Other specify” values\nDetect outliers in numeric variables\nReview field comments\nTrack survey progress\n\n\n\nEnumerator Performance Checks (Dashboard)\n\nPercentage of “Don’t know” and “Refuse to answer”\n“Yes” percentage for filter questions\nEnumerator productivity\nAverage interview duration\nActive hours\nStatistics for numeric variables\n\n\n\nSurvey Dashboard Checks\n\nSurvey consent rate\nPercentage of missing survey values\nPercentage of “Don’t know” & “Refuse to Answer”\nNumber and percentage of “Other specify” values\nVariables with all missing values\nSurvey productivity",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "High-Frequency Checks"
    ]
  },
  {
    "objectID": "data-quality/hfcs.html#introduction-to-ipas-hfcs-package",
    "href": "data-quality/hfcs.html#introduction-to-ipas-hfcs-package",
    "title": "High Frequency Checks",
    "section": "Introduction to IPA’s HFCs Package",
    "text": "Introduction to IPA’s HFCs Package\nThe Stata program ipacheck is a set of user-written commands developed and maintained by IPA. It consists of three types of files: an input file, a do-file, and output files. These files can be modified to fit your project’s needs. Each check produces either a standalone workbook or a dedicated sheet in the HFC output workbook, displaying respondent IDs, enumerator details, and relevant flagged variables.\n\nHow are High Frequency Checks different from the Data Management System?\nThe Data Management System (DMS) provides a structured approach to managing research data, assisting with:\n\nCreating project folder structures\nManaging data flow\nRunning high-frequency checks\nDe-duplicating and replacing data\nTracking survey progress\nRunning back checks\nGenerating logs for project closure\n\nHigh-frequency checks are just one component of the broader capabilities of the DMS, running alongside other project management tools.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "High-Frequency Checks"
    ]
  },
  {
    "objectID": "data-quality/hfcs.html#installation",
    "href": "data-quality/hfcs.html#installation",
    "title": "High Frequency Checks",
    "section": "Installation",
    "text": "Installation\nipacheck is IPA’s Stata package for running high-frequency checks. The package includes various programs categorized as main or ancillary.\n\nMain Programs\n\nipacheckcorrections - Make corrections to data.\nipacheckspecifyrecode - Recode “Other specify” values.\nipacheckversions - Export survey form version statistics & flag outdated submissions.\nipacheckids - Identify duplicate survey IDs.\nipacheckdups - Detect duplicates in non-ID variables.\nipacheckmissing - Generate missingness & distinctness statistics.\nipacheckoutliers - Identify outliers in numeric variables.\nipacheckspecify - Extract “Other specify” values.\nipacheckcomments - Export field comments from SurveyCTO.\nipachecktextaudit - Analyze survey duration using SurveyCTO text audit files.\nipachecktimeuse - Export engagement statistics from SurveyCTO audit files.\nipachecksurveydb - Generate general dataset statistics.\nipacheckenumdb - Evaluate enumerator performance.\nipatracksurvey - Generate a dashboard for tracking survey progress.\nipabcstats - Compare survey data with back check data.\n\n\n\nAncillary Programs\n\nipacodebook - Export a codebook to Excel with labeled variable notes.\n\nipacheck comes with a structured project folder setup, including a master do-file, global variables file, preparation do-file, and Excel-based input sheets. Outputs are generated as well-formatted Excel spreadsheets for field team distribution. Since version 4.2.0, ipacheck now incorporates programs from the ipahelper package.\n\n\nInstallation Steps\n* Install ipacheck from GitHub\nnet install ipacheck, all replace from(\"https://raw.githubusercontent.com/PovertyAction/high-frequency-checks/master\")\n\n* Update ipacheck anytime\nipacheck update\n\n* Create a new project with folder structure and input files\nipacheck new, surveys(\"SURVEY_NAME_1\") folder(\"path/to/project\")\n\n* Create a project with multiple surveys using subfolders\nipacheck new, surveys(\"SURVEY_NAME_1\" \"SURVEY_NAME_2\") folder(\"path/to/project\") subfolders\n\n* Obtain fresh copies of the master do-file and Excel inputs\nipacheck new, filesonly\n\n* Access IPA's training exercise (includes sample data and instructions)\nipacheck new, exercise\n\n* Verify the installed version\nipacheck version\n\n\n\n\n\n\nHFCs in practice\n\n\n\nCheck out the IPA High Frequency Check Exercise! These exercises are designed to help familiarize users with the setup and use of IPA’s Data Management System, which includes High-Frequency Checks (HFCs), Survey Tracking, and Back Check comparison. Learn more",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "High-Frequency Checks"
    ]
  },
  {
    "objectID": "data-quality/hfcs.html#conclusion",
    "href": "data-quality/hfcs.html#conclusion",
    "title": "High Frequency Checks",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, High Frequency Checks (HFCs) are an essential component of IPA’s data quality assurance framework. By implementing systematic and regular checks on survey data, HFCs help ensure the accuracy, reliability, and overall quality of the data collected. The ipacheck Stata package provides a comprehensive set of tools to facilitate these checks, making it easier for research teams to identify and address issues promptly. By integrating HFCs into your data collection process, you can significantly enhance the integrity of your research findings and contribute to the overall success of your projects.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "High-Frequency Checks"
    ]
  },
  {
    "objectID": "data-quality/data-security-protocol.html#what-is-the-data-security-protocol",
    "href": "data-quality/data-security-protocol.html#what-is-the-data-security-protocol",
    "title": "Data Security Protocol",
    "section": "What is the Data Security Protocol?",
    "text": "What is the Data Security Protocol?\nThe data security protocol is a set of guidelines and practices designed to protect data from unauthorized access, corruption, or loss."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#personally-identifiable-information-pii",
    "href": "data-quality/data-security-protocol.html#personally-identifiable-information-pii",
    "title": "Data Security Protocol",
    "section": "Personally Identifiable Information (PII)",
    "text": "Personally Identifiable Information (PII)\nPII refers to any data point or combination of data points that can identify an individual or household with reasonable certainty. Examples of PII can include:\n\nName\nGPS coordinates\nAddress\nCombinations of demographic data (e.g., village name, birth date, gender, occupation in small communities)\n\n\n\n\n\n\n\nData Protection Requirements\n\n\n\n\n\nPII must be protected using the following protocols:\n\nEncryption: Apply encryption at every stage of the data lifecycle (collection, transmission, storage).\nSeparation: Separate PII from research data as soon as possible.\nOngoing Protection: Protect PII retained after study closure.\nExclusion: Exclude PII from microdata publications (e.g., AEA registry).\n\n\n\n\nIn terms of sharing PII, this kind of information may only be shared under the following conditions:\n\nThe recipient is named or referenced in the informed consent (e.g., researchers, partners).\nThe recipient is included in the approved research protocol.\nSecure methods are used for sharing.\n\n\nImportance of Data Security\n\nCompliance: Required by Institutional Review Boards (IRBs) and donors.\nPrevention of Data Loss: Avoid costly data breaches or losses.\nRespect for Respondents: Protect respondents’ privacy and confidentiality.\nData Integrity: Ensure data quality for sharing and publication.\n\n\n\nSensitive Data\nSensitive data is information where a loss of confidentiality, integrity, or availability could result in serious, severe, or catastrophic consequences.\n\n\nSensitivity Levels\n\nLevel 1: Not confidential.\nLevel 2: Contains PII, but no material harm.\nLevel 3: Contains PII and could cause material harm.\nLevel 4: High-risk confidential data.\n\n\n\n\n\n\n\nExamples of PII (Based on 45 CFR 164.514 - HIPAA Standard)\n\n\n\n\n\nBased on 45 CFR 164.514 - HIPAA Standard, some examples of PII may include: - Names - Geographic subdivisions smaller than a state/province - Dates directly related to an individual (except year) - Telephone numbers, fax numbers, email addresses - Social security numbers, medical record numbers, health plan beneficiary numbers - Account numbers, certificate or license numbers, vehicle identifiers, device identifiers - Web URLs, IP addresses, biometric identifiers (e.g., fingerprints, voice prints) - Full-face photos or any other unique identifying number, characteristic, or code"
  },
  {
    "objectID": "data-quality/data-security-protocol.html#access-to-pii",
    "href": "data-quality/data-security-protocol.html#access-to-pii",
    "title": "Data Security Protocol",
    "section": "Access to PII",
    "text": "Access to PII\n\nOnly individuals approved in the IRB submission can access PII.\nApproved individuals must complete human subjects protection training (e.g., CITI Program certification)."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#password-security",
    "href": "data-quality/data-security-protocol.html#password-security",
    "title": "Data Security Protocol",
    "section": "Password Security",
    "text": "Password Security\n\nCreating a Strong Password\n\nAt least 10 characters.\nUse a mix of numbers, symbols, uppercase, and lowercase letters.\nAvoid repetition, dictionary words, usernames, pronouns, IDs, and predefined sequences.\n\n\n\nPassword Best Practices\n\nNever share passwords via email.\nUse a secure password manager.\nUse a complex password consistently across the project.\n\nExample: The New Hampshire training was awesome because of the data security presentation → TnhtwabotDSP_13"
  },
  {
    "objectID": "data-quality/data-security-protocol.html#data-protection-summary",
    "href": "data-quality/data-security-protocol.html#data-protection-summary",
    "title": "Data Security Protocol",
    "section": "Data Protection Summary",
    "text": "Data Protection Summary\nEnsure your data is always:\n\nProduced through a clear step in your data flow.\nSaved to a logical and secure location.\nPassword-protected with a strong password.\nEncrypted if it contains PII or sensitive data.\nBacked up regularly in multiple locations."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#data-flow-faq",
    "href": "data-quality/data-security-protocol.html#data-flow-faq",
    "title": "Data Security Protocol",
    "section": "Data Flow FAQ",
    "text": "Data Flow FAQ\n\nWhen to Keep Data Secure\nSecure data whenever sensitive information is linked to PII. Raw data containing PII must be encrypted and stored securely.\n\n\nWhen and How to Remove PII\n\nRemove PII as soon as possible.\nCollaborate with your team to determine who will remove PII and when.\nStata Tip: Use the lookfor command to identify PII."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#device-security",
    "href": "data-quality/data-security-protocol.html#device-security",
    "title": "Data Security Protocol",
    "section": "Device Security",
    "text": "Device Security\n\nGeneral Device Security\n\nConsult the Data Coordinator for recommended devices.\nEncrypt all sensitive data.\nPassword-protect devices.\nPhysically secure and label devices.\n\n\n\nField Device Management\n\nImplement check-in/out systems for devices.\nTrain staff not to broadcast locations or activities.\nEnsure signed device liability forms.\nMaintain charging schedules and fire safety precautions.\nAssign responsibility for nightly device checks.\nLabel devices with QR code stickers.\nStore netbooks in protective casings.\n\n\n\nLaptop & Personal Device Security\n\nUse IPA’s encryption software for PII.\nAvoid unapproved programs.\nRun antivirus scans regularly.\nBackup data securely (e.g., Box).\nWork computers only: No personal files.\n\n\n\nLaptop/Netbook Security in the Field\n\nUser Accounts\n\nCreate two accounts:\nAdmin account: Full rights.\nEnumerator account: Limited access.\n\n\n\nFunctionality Restrictions\n\nSet accurate date and time.\nDisable internet access if unnecessary.\nDisable audio, video, and USB ports unless required for data extraction.\n\n\n\nSoftware & Protection\n\nInstall antivirus software (e.g., Avira, Avast!).\nEncrypt sensitive survey data (e.g., Cryptomator).\nRegularly update and back up data."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#data-backup-storage",
    "href": "data-quality/data-security-protocol.html#data-backup-storage",
    "title": "Data Security Protocol",
    "section": "Data Backup & Storage",
    "text": "Data Backup & Storage\n\nUse central/supervisor computer backups.\nLocal backups: External hard drives with automated backup software (e.g., CrashPlan).\nCloud backups: IPA’s encrypted cloud storage (Box) with additional encryption (Cryptomator)."
  },
  {
    "objectID": "data-quality/data-security-protocol.html#conclusion",
    "href": "data-quality/data-security-protocol.html#conclusion",
    "title": "Data Security Protocol",
    "section": "Conclusion",
    "text": "Conclusion\nBy adhering to these data security protocols, we ensure compliance, safeguard respondent privacy, and maintain the integrity of research data."
  },
  {
    "objectID": "data-quality/data-anonymization.html#what-is-data-anonymization",
    "href": "data-quality/data-anonymization.html#what-is-data-anonymization",
    "title": "Data Anonymization",
    "section": "What is Data Anonymization?",
    "text": "What is Data Anonymization?\nData anonymization is the act of removing Personally Identifiable Information (PII) from study materials. Before starting any analyses, consider carefully whether you will need PII. Most analyses will not require PII. Typically, the only use for PII is to link data from different sources, as well as analyses reliant on geographic data, which will be addressed below.\nIf PII is not necessary for the analysis, then it should be split from the data immediately. In most cases, there is no reason to share PII with PIs. Instead, anonymize the data immediately using the split_pii Stata program and share only the anonymized data with PIs, which can be downloaded through SSC.\nPII includes information that can be used to specifically identify an individual. Due to the nature of the research we conduct, we are entrusted with the management of PII of the participants of our research studies. This information should not be released to external individuals, including in most cases PIs and users who access publicly accessible materials, such as from IPA’s Data Repository. Therefore, it is vital that staff have access to strategies to remove this data to ensure the safety of research subjects.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Anonymization"
    ]
  },
  {
    "objectID": "data-quality/data-anonymization.html#what-data-count-as-personally-identifiable-information",
    "href": "data-quality/data-anonymization.html#what-data-count-as-personally-identifiable-information",
    "title": "Data Anonymization",
    "section": "What data count as Personally Identifiable Information?",
    "text": "What data count as Personally Identifiable Information?\nIPA conforms to the HIPAA guidelines for what data count as PII. Included in the list are: - Names - Geographic areas with a population of 20,000 or fewer - Birth date - Contact information such as phone numbers - License numbers - Indirect identifiers that, in combination with several sets of information, can uniquely identify an individual\nBecause IPA conducts studies in countries outside of the US, the list of PII should be adapted to the relevant country context.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Anonymization"
    ]
  },
  {
    "objectID": "data-quality/data-anonymization.html#what-materials-should-be-anonymized",
    "href": "data-quality/data-anonymization.html#what-materials-should-be-anonymized",
    "title": "Data Anonymization",
    "section": "What materials should be anonymized?",
    "text": "What materials should be anonymized?\nAside from the names of PIs and, in some cases, current project staff, ensure that PII is removed from: - Data - Code - Survey instruments - Any other documentation that will be shared with non-IRB-approved staff and external users\nData and code should be prioritized because most PII will be found in those two sets of files. However, review all other documents that will be shared as well.\nAutomated searches for PII in Stata datasets are discussed below, but for code, surveys, and other documentation, manual review is typically required.\nFor users with advanced programming skills, Python can skim documents for relevant information. However, a manual check is still recommended in case certain keywords are missed.\nIPA is currently testing a PII treatment application. Learn more about it here: IPA’s Personally Identifiable Information Treatment Application.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Anonymization"
    ]
  },
  {
    "objectID": "data-quality/data-anonymization.html#how-to-search-datasets-for-personally-identifiable-information",
    "href": "data-quality/data-anonymization.html#how-to-search-datasets-for-personally-identifiable-information",
    "title": "Data Anonymization",
    "section": "How to Search Datasets for Personally Identifiable Information",
    "text": "How to Search Datasets for Personally Identifiable Information\nTo ensure a Stata dataset does not contain PII, carefully review the variables it contains. It may not be immediately clear that a variable contains PII. Conduct at least two sweeps of one or more datasets for clear instances of PII. Sweeps can be done either using Stata code or manually.\n\nUsing Stata\nA quick way to screen for PII in Stata is the lookfor command. It searches all variable names and labels in a dataset for one or more keywords.\nlookfor name\nThis command lists all variables whose name or variable label contains the string “name.” For example, a variable named fname (for “first name”) would be listed because “name” is a substring of fname. lookfor also stores the list of variables in the saved result r(varlist).\nTo quickly search more than one dataset, use the lookfor_all command, available on SSC. To install, type:\nssc install lookfor_all\n\n\nKeywords to Search For\nBelow is a list of keywords to consider searching for (not exhaustive):\n\nname\nbirth (to find variables related to the respondent’s birthdate)\nphone\ndistrict\ncounty\nsubcounty\nparish\nlc (to find variables related to the respondent’s “local council,” a geographical unit in some countries)\nvillage\ncommunity\naddress or gps\nlat (to find variables related to latitude)\nlon (to find variables related to longitude)\ncoord (to find variables related to GPS coordinates)\nlocation\nhouse\ncompound\nschool\nsocial\nnetwork\ncensus\ngender (in limited cases)\nsex (in limited cases)\nfax or email\nip (for IP addresses)\nurl (for Web addresses)\nspecify or comment\n\n\n\nSearching Through String Variables\nSearch through string variables and their values to screen for PII. Field officers may collect non-uniform answers in string variables, which can contain PII such as names, small locations, and contact information.\nTo display the full length of string values:\nlevels of varname\nIf PII is contained in strings with standardized values, recode them using:\nreplace varname = subinstr(varname, \"PII VALUE\", \"ANONYMIZED VALUE\", .)\nIf PII is contained in strings but the values are irregular, manually recode them:\nreplace varname = \"STRING VALUE WITHOUT PII\" if varname == \"STRING VALUE WITH PII\"\nIn both cases, maintain the integrity of the string value if it contains useful information. Otherwise, create a blank or “other” value based on the variable’s structure.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Anonymization"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#what-are-backchecks",
    "href": "data-quality/backchecks.html#what-are-backchecks",
    "title": "Back Checks",
    "section": "What are Backchecks?",
    "text": "What are Backchecks?\nBackchecks, also known as field audits or reinterviews, are a quality control process in survey data collection to ensure accuracy and reliability. They involve re-contacting a subset of respondents to administer a mini-survey with selected questions from the original questionnaire. The responses are then compared to the initial survey to identify discrepancies, assess surveyor performance, and evaluate the robustness of the survey instrument. Backchecks help hold surveyors accountable and improve data quality by verifying how questions are asked and detecting potential errors in data collection.\nThis critical step in data quality enables us to monitor both the performance of the survey team and the questionnaire in the field. Back checks are just as critical to producing high-quality data as double entry of data is to ensuring data entry accuracy. Well-done back checks can lead to:\n\nQuestionnaire revisions.\nImproved training.\nAdditional rounds of surveying.\nChanges to the survey team.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#why-is-important-to-backcheck",
    "href": "data-quality/backchecks.html#why-is-important-to-backcheck",
    "title": "Back Checks",
    "section": "Why is important to Backcheck?",
    "text": "Why is important to Backcheck?\nLet’s be honest, surveying can be hard and boring. To get out of the heat and back to the office, surveyors are tempted to cut corners in the field. The most common shortcuts are:\n\nSkipping sections or entire surveys.\nFailing to prompt properly.\nModifying examples or informed consent scripts.\nPrematurely classifying respondents as missing or away.\n\nIn your mission to collect high-quality data, you need to develop a systematic way to detect poor surveying and incentivize high-quality fieldwork. In a nutshell, you need a disincentive for surveyors to take shortcuts and falsify data.\nBeyond poor administration, you also want to methodically monitor how well your questionnaire is performing in the field. You want to figure out\n\nAre respondents changing their answers to questions that shouldn’t change?\nDo key outcomes vary significantly?\n\nTo understand whether your questionnaire accurately captures the key outcomes of your study, you need a tool that measures the quality of your measures.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#ipa-sample-selection-protocols",
    "href": "data-quality/backchecks.html#ipa-sample-selection-protocols",
    "title": "Back Checks",
    "section": "IPA Sample Selection Protocols",
    "text": "IPA Sample Selection Protocols\n\nRecommended Best Practices\nThe following guidelines are recommended as best practices by IPA:\n\nSample Size: Back check questionnaires should be administered to at least 10% of surveys, or 40 surveys per week, whichever is higher. Larger surveys may back check less than 10%, while smaller surveys may need to back check between 15-20%.\nProportional Coverage: Ensure you are back checking a similar proportion of surveys for enumerators and geographic areas. For CATI surveys, back check more than 10%.\nTiming: Every team and every surveyor should be back checked as soon as possible, ideally within the first week of surveying, and regularly after that. Aggressively back check during the first few weeks, then reduce to 10% for the rest of the surveying phase.\nFrequency: Each enumerator should be checked at least once per week throughout the survey.\nMissing and Replacement Respondents: Include a proportional number of missing and replacement respondents in the back check sample.\nRandom Selection: The selection of households for back checks must be random. Stratify the sampling when appropriate.\nMultiple Versions: Use multiple versions of the back check questionnaire, covering the entire survey. Each version should include a minimum of 10 questions or 10% of the total survey instrument.\nSurvey Length: Keep the back check survey significantly shorter than the main survey. Phone back checks should be no longer than 10 minutes.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#making-it-happen-how-to-design-the-back-check-survey",
    "href": "data-quality/backchecks.html#making-it-happen-how-to-design-the-back-check-survey",
    "title": "Back Checks",
    "section": "Making it Happen: How to Design the Back Check Survey",
    "text": "Making it Happen: How to Design the Back Check Survey\n\nDevelop Your Plan Before You Start Surveying\nThe key to a quality back check is planning. Multiple analyses conducted by IPA staff have shown that the time elapsed since the original survey is the most common statistically significant predictor of the number of errors in back checks across projects and contexts. You want your back check team to be ready to hit the field on day one of the survey period.\nCraft your back check plan at the same time as your survey work plan and maintain it as a running document, updating details as the survey work plan evolves. This ensures that at the end of the survey, you have an accurate description of how the back checks were carried out and any actions taken.\nWhen developing your plan, address the following questions:\n\n\n\n\n\n\nDesign\n\n\n\n\n\n\nHow will you conduct your back checks? Can you do them in person?\nHow many surveys will you back check? 10% or more? Will you change the percentage during the survey period?\nHow will you spread them across your enumeration areas, surveyors, and survey period?\nHow many questionnaires will you use? Multiple questionnaires are optimal, especially for longer, more complex surveys.\n\n\n\n\n\n\n\n\n\n\nBudget\n\n\n\n\n\n\nHow much money do you have for your back check? Note: Back checks should be budgeted during the project development stage.\nIf your budget is tight, can you implement phone back checks or other low-cost strategies?\n\n\n\n\n\n\n\n\n\n\nLogistics & Team Structure\n\n\n\n\n\n\nWhen will the back checks be done? Ideally, within 1-2 days. One week is the maximum.\nHow big will your back check team be, and how will you train them?\nAre there enough back checkers to check all enumerators each week? Do you need to hire more back checkers during the first few weeks of surveying?\nHow will the team get to the field? If conducting back checks by phone, do you have enough phones?\n\n\n\n\n\n\n\n\n\n\nAnalysis & Action\n\n\n\n\n\n\nHow will you define and calculate errors?\nHow will you deal with discrepancies? Create a plan with your field management team.\nHow will you log back check errors? Aim to integrate this into your master tracking system.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#selecting-and-managing-the-back-check-team",
    "href": "data-quality/backchecks.html#selecting-and-managing-the-back-check-team",
    "title": "Back Checks",
    "section": "Selecting and Managing the Back Check Team",
    "text": "Selecting and Managing the Back Check Team\n\nSelecting the Right Team\nA back check team member should be more qualified than your regular surveyors. In detail, a member of the back check team should be:\n\nExperienced: Consider retaining the team of surveyors used during the pilot as the back check team.\nTrustworthy: Prefer someone you’ve worked with before.\nIndependent and Enterprising: Members may have to travel to villages separately and alone.\n\n\n\nTraining\nThe back check team should attend the main training with the entire team to ensure everyone understands the questions in the same way. Consider using them as leaders at the training of the main survey team.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#executing-the-back-check",
    "href": "data-quality/backchecks.html#executing-the-back-check",
    "title": "Back Checks",
    "section": "Executing the Back Check",
    "text": "Executing the Back Check\n\nTiming & Revisits\n\nAim to complete back checks within 1-2 days of the original survey.\nDecide on the number of revisits the back check team should aim to do. Ideally, the team will do the same number of revisits as the original surveyors.\n\n\n\nSelecting Respondents\n\nThe back check team should never select the households. Use Stata or Excel to randomly select respondents to back check, stratified by surveyor.\nIf your project requires replicable randomization for back checks, use Stata. Otherwise, use SurveyCTO randomization.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#producing-acting-on-results",
    "href": "data-quality/backchecks.html#producing-acting-on-results",
    "title": "Back Checks",
    "section": "Producing & Acting on Results",
    "text": "Producing & Acting on Results\n\nAnalysis Framework\n\nDuring questionnaire design, create your analysis framework and define what you consider an error.\nUse IPA’s user-written Stata command bcstats to compare survey data and back check data.\n\n\n\nAcceptable Range of Deviation\n\nEstablish a range of acceptable deviation for every back check question. For example, age +/-5 years.\n\n\n\nAnalysis for Type 1, Type 2, Type 3\n\nType 1: Look at the overall error rate. If it’s &gt;10%, this is a red flag.\nType 2: Perform the same analysis as Type 1, but examine these variables separately.\nType 3: Examine the overall error rates by question and perform stability checks.\n\n\n\nWhen & How to Take Action on Results\n\nResults of the back check comparison should be discussed with the field leadership team.\nSet clear standards for when to fire surveyors, when to follow up with respondents, and when to re-do surveys.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#digital-back-checks",
    "href": "data-quality/backchecks.html#digital-back-checks",
    "title": "Back Checks",
    "section": "Digital Back Checks",
    "text": "Digital Back Checks\nFor CATI surveys, audio audits can be used to monitor enumerator performance. However, audio audits will not fulfill the back check’s function of testing the reliability of a survey question. If your PI is concerned with the stability and quality of the survey questions, a back check is required.\n\n\n\n\n\n\nBack Checks in practice\n\n\n\nCheck out the IPA High Frequency Check Exercise! These exercises are designed to help familiarize users with the setup and use of IPA’s Data Management System, which includes High-Frequency Checks (HFCs), Survey Tracking, and Back Check comparison. Learn more",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/backchecks.html#conclusion",
    "href": "data-quality/backchecks.html#conclusion",
    "title": "Back Checks",
    "section": "Conclusion",
    "text": "Conclusion\nBack checks are a critical component of ensuring high-quality data collection. By following the guidelines outlined in this manual, you can effectively implement back checks, analyze the results, and take appropriate actions to improve your survey process.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Backchecks"
    ]
  },
  {
    "objectID": "data-quality/accompany-surveyors.html#why-we-accompany-surveyors",
    "href": "data-quality/accompany-surveyors.html#why-we-accompany-surveyors",
    "title": "Accompany Surveyors",
    "section": "Why We Accompany Surveyors",
    "text": "Why We Accompany Surveyors\nAccompanying surveyors is a key step in ensuring high-quality data collection. It allows us to monitor data quality, provide feedback, and detect any issues early in the survey process. By demonstrating our commitment to accuracy, we also set expectations for the team and reinforce the importance of ethical and accurate data collection.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Accompany Surveyors"
    ]
  },
  {
    "objectID": "data-quality/accompany-surveyors.html#motivations-for-accompanying-surveyors",
    "href": "data-quality/accompany-surveyors.html#motivations-for-accompanying-surveyors",
    "title": "Accompany Surveyors",
    "section": "Motivations for Accompanying Surveyors",
    "text": "Motivations for Accompanying Surveyors\n\nEnsuring Accuracy: Observing surveyors helps verify that questions are asked correctly and consistently.\nUnderstanding Respondent Reactions: We can identify whether respondents interpret questions as intended.\nDetecting Issues Early: Mistakes or inconsistencies can be caught and corrected before they affect the dataset.\nImproving Surveyor Performance: Providing targeted feedback helps surveyors improve their skills.\nBuilding Accountability: Regular monitoring discourages falsification and reinforces ethical data collection.\nStrengthening Relationships: Engaging with surveyors shows we value their work and experience their challenges firsthand.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Accompany Surveyors"
    ]
  },
  {
    "objectID": "data-quality/accompany-surveyors.html#how-to-accompany-surveyors",
    "href": "data-quality/accompany-surveyors.html#how-to-accompany-surveyors",
    "title": "Accompany Surveyors",
    "section": "How to Accompany Surveyors",
    "text": "How to Accompany Surveyors\n\nFull Accompaniment at the Start:\n\nDuring the initial days of the survey, each surveyor should be observed for an entire interview to ensure they understand and apply the questionnaire correctly.\n\nOngoing Partial Accompaniment:\n\nAs the survey progresses, accompanying can be limited to key sections of the interview (e.g., 2-3 sections per visit).\n\nStructured Observation and Feedback:\n\nUse standardized forms to document observations and track surveyor performance.\nProvide immediate feedback and follow up on recurring mistakes.\n\nRandom and Scheduled Visits:\n\nMix planned and unannounced visits to get a realistic picture of surveyor performance.\n\nEscalation for Persistent Issues:\n\nAddress repeated mistakes with training or corrective actions.\nIf necessary, implement penalties or contract termination for continued poor performance.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Accompany Surveyors"
    ]
  },
  {
    "objectID": "data-quality/accompany-surveyors.html#monitoring-and-reporting",
    "href": "data-quality/accompany-surveyors.html#monitoring-and-reporting",
    "title": "Accompany Surveyors",
    "section": "Monitoring and Reporting",
    "text": "Monitoring and Reporting\n\nResearch Protocol: At least 10% of surveys must be accompanied to comply with best practices.\nSurvey Diary: Maintain a log of observations and feedback for continuous improvement.\nExternal Resources: See the paper version and SurveyCTO XLS form of IPA’s accompaniment template for documentation and reporting.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Accompany Surveyors"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-start.html",
    "href": "data-collection/whatsapp/whatsapp-start.html",
    "title": "WhatsApp Surveys: An Innovative and Low-Cost Solution for Remote Data Collection",
    "section": "",
    "text": "WhatsApp has become a powerful tool for data collection, offering a cost-effective, scalable, and user-friendly alternative to traditional survey methods. At IPA, WhatsApp surveys have been used to overcome challenges in reaching participants, especially during the COVID-19 pandemic. This page provides an introduction to WhatsApp surveys, their benefits, limitations, and best practices based on our experience.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "About WhatsApp Surveys"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-start.html#why-use-whatsapp-for-surveys",
    "href": "data-collection/whatsapp/whatsapp-start.html#why-use-whatsapp-for-surveys",
    "title": "WhatsApp Surveys: An Innovative and Low-Cost Solution for Remote Data Collection",
    "section": "Why Use WhatsApp for Surveys?",
    "text": "Why Use WhatsApp for Surveys?\n\n\n\n\n\n\nWide User Base\n\n\n\n\n\n\nWhatsApp has over 2 billion active users globally.\nIt is widely adopted across different demographics and regions.\n\n\n\n\n\n\n\n\n\n\nHigh Engagement and Familiarity\n\n\n\n\n\n\nPeople are already comfortable using WhatsApp for communication.\nSurveys can be completed easily on smartphones, anytime and anywhere.\n\n\n\n\n\n\n\n\n\n\nCost-Effective Solution\n\n\n\n\n\n\nWhatsApp reduces costs compared to traditional survey methods.\nSavings on printing, fieldwork, and call center expenses.\n\n\n\n\n\n\n\n\n\n\nRich Media Capabilities\n\n\n\n\n\n\nSupports images, videos, and audio files for interactive surveys.\nEnhances comprehension and engagement.\n\n\n\n\n\n\n\n\n\n\nReal-Time Responses\n\n\n\n\n\n\nData is collected instantly, allowing for real-time monitoring.\nEnables quick decision-making based on responses.\n\n\n\n\n\n\n\n\n\n\nHigher Response Rates\n\n\n\n\n\n\nFamiliarity with WhatsApp leads to increased participation.\nEvidence from IPA projects in Colombia, Senegal, and Guinea supports this.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "About WhatsApp Surveys"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-start.html#whatsapp-surveys-at-ipa",
    "href": "data-collection/whatsapp/whatsapp-start.html#whatsapp-surveys-at-ipa",
    "title": "WhatsApp Surveys: An Innovative and Low-Cost Solution for Remote Data Collection",
    "section": "WhatsApp Surveys at IPA",
    "text": "WhatsApp Surveys at IPA\nIPA has successfully implemented WhatsApp surveys in various projects across different regions. Some key examples include:\n\n\n\nWhatsApp Surveys: Temporary Statute of Protection for Venezuelans (ETPV)\n\n\n\nMonitoring Migration and Legal Status: A study by IPA Colombia on Colombia’s policy to grant legal status to Venezuelan migrants used WhatsApp surveys to reach a mobile population. Even when phone numbers changed, WhatsApp numbers remained stable, improving follow-up success.\nTracking Social Protection Interventions: WhatsApp was used to communicate project details and schedule phone surveys for studies on entrepreneurship training and social protection during COVID-19.\nAssessing Program Spillovers: A project on socio-emotional skills used WhatsApp surveys to track whether control group participants had received materials related to the intervention.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "About WhatsApp Surveys"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-start.html#advantages-and-limitations",
    "href": "data-collection/whatsapp/whatsapp-start.html#advantages-and-limitations",
    "title": "WhatsApp Surveys: An Innovative and Low-Cost Solution for Remote Data Collection",
    "section": "Advantages and Limitations",
    "text": "Advantages and Limitations\n\nKey Benefits\n\nVerified WhatsApp Business Account: We use a verified IPA account with our logo as a profile picture, improving participant recognition and trust. The verified account displays IPA’s name instead of an unknown number, potentially increasing response rates.\nMessage Tracking: WhatsApp’s double-check marks allow researchers to monitor survey progress by identifying:\n\nFailed deliveries due to inactive phone numbers.\nMessages that were received and read (subject to user privacy settings).\n\nScalability and Multi-Format Engagement: The ability to send images, voice messages, and documents makes communication more effective.\nReal-Time Data Collection: Responses arrive instantly, allowing researchers to adapt their approach or follow up as needed.\n\n\n\nChallenges and Considerations\n\nParticipant Requirements: WhatsApp surveys work best with populations that have internet access, smartphones, and some level of technological literacy. This may limit sampling to specific geographic, age, and socioeconomic groups.\nNo Enumerator Supervision: Without an enumerator present, verifying that participants understand survey questions can be difficult. To mitigate this, we designed surveys with clear, simple questions.\nPrivacy Limitations: Some WhatsApp privacy settings may prevent researchers from knowing whether messages have been read.\nManaging Expectations: In some cases, participants expected real-time human responses. Clarifying automated interactions upfront helped mitigate confusion.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "About WhatsApp Surveys"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-start.html#the-role-of-twilio-in-whatsapp-surveys",
    "href": "data-collection/whatsapp/whatsapp-start.html#the-role-of-twilio-in-whatsapp-surveys",
    "title": "WhatsApp Surveys: An Innovative and Low-Cost Solution for Remote Data Collection",
    "section": "The Role of Twilio in WhatsApp Surveys",
    "text": "The Role of Twilio in WhatsApp Surveys\nTwilio is a cloud communication platform that allows organizations to send automated WhatsApp messages and conduct surveys. At IPA, Twilio has been used for:\n\nWhatsApp and SMS surveys.\nInteractive Voice Response (IVR) surveys.\nAutomated reminders for data collection visits.\nVirtual call center support via WhatsApp, voice, and video.\n\nTwilio has been tested in multiple IPA projects, including PEP, Think Equal, UEPA, Ingreso Solidario, Play to Learn, ETPV, Sisbén, and Lego. Due to its success, other IPA regional offices have adopted it for data collection and participant engagement.\nGRDS provides support in planning and programming surveys or interventions via WhatsApp, SMS, and IVR through Twilio.\nEvery data collection method has its trade-offs, and we are not comparing all options here (we hope to publish a more detailed technical comparison in the future). However, for IPA—particularly during the disruptions of COVID-19—WhatsApp surveys have proven to be a versatile and effective tool. The more experience we gain, the better we become at using them. If you think WhatsApp surveys might be useful for your study, we encourage you to give them a try.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "About WhatsApp Surveys"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-deploy.html#setting-up-your-computer",
    "href": "data-collection/whatsapp/whatsapp-deploy.html#setting-up-your-computer",
    "title": "Deploying a WhatsApp Survey",
    "section": "Setting Up Your Computer",
    "text": "Setting Up Your Computer\nGet started with the IPA GitHub user guide to streamline your computer setup. Follow these steps to download and install the essential programs required for seamless functionality. This guide is your gateway to hassle-free preparation, ensuring your computer is equipped with the necessary tools for a smooth survey launch and data management process. Let’s dive into the user guide to initiate your computer setup successfully.\n\n IPA GitHub user guide\n\n\nOnce you have successfully completed the installation, please move to the section Creating a Cases File.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Deploying a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-deploy.html#creating-a-cases-file",
    "href": "data-collection/whatsapp/whatsapp-deploy.html#creating-a-cases-file",
    "title": "Deploying a WhatsApp Survey",
    "section": "Creating a Cases File",
    "text": "Creating a Cases File\nOnce you’ve completed the console setup and obtained the necessary approvals from WhatsApp, you’re ready to deploy a survey. It’s important to note that this method involves initiating communication from your profile, prompting user engagement. This method is different from waiting for user-initiated communication, where you will have an open chat and you don’t have a specific target sample.\nThe first step to start the process is creating a “cases file.” This file is a dataset with participants’ phone numbers and any additional information relevant to your survey. If you consider including personalized messages or details to populate survey fields, you should include this information as dataset variables. Another recommendation is to incorporate an identifier to keep track of submissions without using any PII for effective tracking.\nFollow these steps to construct your cases file:\n\nThe file should be in xlsx format. We recommend using Stata, R, or your preferred statistical software to create this document to reduce manual input errors.\nEnsure the Excel file includes a column or variable named “Number” (with a capital N), structured as “whatsapp:+” followed by the phone number and country identifier, as depicted in the image.\nOther variables can be named according to your preference. If numeric values are involved, store them as text to prevent Excel from altering them.\nStore the “cases” dataset in a secure and encrypted folder on your computer to ensure data security.\n\nYour cases file should look like this:\n\n\n\nCases file example",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Deploying a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-deploy.html#managing-data-with-google-sheets",
    "href": "data-collection/whatsapp/whatsapp-deploy.html#managing-data-with-google-sheets",
    "title": "Deploying a WhatsApp Survey",
    "section": "Managing Data with Google Sheets",
    "text": "Managing Data with Google Sheets\nA final step before launching a WhatsApp survey is to configure the Google Sheet, where you’ll collect data from your surveys and WhatsApp interactions. Follow these steps to ensure a smooth data collection setup:\n\nCreate a Google Sheet: Initiate the process by creating a Google Sheet to serve as the repository for collected data.\nConfigure Twilio Functions:\n\nAccess the Twilio console’s submenu labeled “Functions and Assets.”\nNavigate to “Functions (Classic)” and select “Configure.”\nIn the “Dependencies” section, ensure the specified fields are completed, as illustrated in the provided image.\n\n\n\n\n\nDependencies configuration snapshot\n\n\n\nCreate two environment variables:\n\nclient_email: twilio-data-connector-to-gsuit@twilio-gsuite-connection.iam.gserviceaccount.com\nsheetId: Retrieve this from the link of your Google Sheet. It is the alphanumeric group in the link after “/d/” and before the next “/.”\n\n\n\n\n\nEnvironment variables configuration snapshot\n\n\n\nCreate a New Function:\n\nProceed to the “List” submenu and generate a new function from a blank interface named “function_gsheets.”\nCopy the provided function code into the code section.\n\n\n\n publish gsheet code\n\n\n\nSave and Deploy: Save the function, and deployment will occur automatically.\nShare Google Sheet: Share your Google Sheet with the email from the client_email environment variable.\nIntegrate the Function into Your Flow:\n\nAdd the newly created function within your flow at the end, as it will compile answers from the entire flow.\nThe arguments from the function have a key (that will be the name of the variable) and value (that will be the way Twilio recognizes the answer inputted by a participant):\n\nIf you want to publish the answer to a question widget you have on your flow, you need to use the following value in the function: {widgets.name_of_the_widgets_variable.inbound.body}\nIf you want to publish data from your “cases” file, use the following value in the function: {flow.data.name_of_the_variable}, remember that you need to include this variable in the cases and the launch code\nIf you want to publish variables you created inside the Twilio flow, you need to use the following value in the function: {flow.variables.name_of_the_variable}\n\n\nHeader Alignment in Google Sheet: Align the variable names defined in Step 7 with the headers of your Google Sheet columns to let Twilio know how to populate the data in the document.\n\n\n\n\nGoogle Sheet example\n\n\nWith these steps completed, your survey is ready to be deployed.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Deploying a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-deploy.html#launching-code",
    "href": "data-collection/whatsapp/whatsapp-deploy.html#launching-code",
    "title": "Deploying a WhatsApp Survey",
    "section": "Launching Code",
    "text": "Launching Code\nTo launch your survey, you will use the following Python code. Follow these next steps:\n\nAccess Command Prompt or PowerShell: Open the command prompt (cmd) or PowerShell on your computer to start the process.\nRun the Python Script:\n\ncd requests_to_twilio\n\npython twilio_launcher.py --account_sid your_account_sid --account_token your_account_token --twilio_number your_twilio_number --flow_id flow_id --input_file full_path_to_input_file --batch_size batch_size --sec_between_batches sec_between_batches --columns_with_info_to_send caseid,name,city,gender,age\nEnsure you replace the placeholders; here is where you can find the information needed:\n\nyour_account_sid: In your Twilio’s console main page\nyour_account_token: In your Twilio’s console main page\nyour_twilio_number: In your Twilio’s console main page\nflow_id: In the flow menu in the console\nfull_path_to_input_file: In your computer directory where the “cases” file is located\nbatch_size: You must define how many surveys you will send. We recommend setting it at 20 per batch. You will need to replace it with just the number. This is a recommendation based on infield experience when deploying WhatsApp surveys. This number of messages prevents the API from overloading and won’t crash.\nsec_between_batches: You must define how many seconds you will wait between batches. We recommend 10 seconds. You will need to replace it with just the number.\nInclude Additional Information: If your file contains extra columns with pertinent information, specify them in the columns_with_info_to_send argument, separating column names by commas.\n\n\n\n\n\n\n\nTip\n\n\n\nIf you ever run into trouble running this code, please email:  researchsupport@poverty-action.org",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Deploying a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#what-is-an-observation",
    "href": "data-collection/qualitative-methods/observations.html#what-is-an-observation",
    "title": "Qualitative Observations",
    "section": "What is an observation?",
    "text": "What is an observation?\nObservations are a qualitative research data collection technique that identifies traits, behaviors, and interactions of individuals and their contexts through the senses and interpretations of the researcher.1 Typically, the results of observations are detailed descriptions of what the field researcher observed, heard, and interpreted during the research activities. Thus, observation is a subjective data collection technique that relies on observation, note-taking, and interpretation skills.2 Depending on how the fieldwork is conducted, observations can be classified as either participant or non-participant.\n\nParticipant Observation\nIn participant observation, researchers actively participate and interact in daily activities or specific contexts of the participants.3 This allows for a first-hand understanding of participants’ daily practices, perspectives, and relationships. For example, a researcher might join community leaders on journeys to identify transport needs for accessing a social program.\n\n\nNon-Participant Observation\nIn non-participant observation, the researcher analyzes the behavior and relationships of participants without intervening (or intervening as little as possible) in the context or activity. Observers position themselves in a suitable place to listen and observe interactions without making comments or participating. For example, a researcher might conduct asynchronous remote observations through video recordings to identify how public school teachers reinforce gender stereotypes among students.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#unstructured-vs.-structured-observations",
    "href": "data-collection/qualitative-methods/observations.html#unstructured-vs.-structured-observations",
    "title": "Qualitative Observations",
    "section": "Unstructured vs. structured observations",
    "text": "Unstructured vs. structured observations\nIn both participant and non-participant observations, the level of data structuring varies based on the fieldwork approach and the expected research outcomes:\n\nUnstructured Observations\nUnstructured observations use open-ended questions in data collection instruments to obtain highly descriptive and narrative information from the researcher. For example, researchers mapping the challenges of caring for children might attend a guided tour with facilitators who share their experiences and suggest improvements to support children’s well-being. This approach is suitable in certain context described below in Table 1.\n\n\n\nTable 1: When to consider unstructured observations 4\n\n\n\n\n\n\n\n\n\nContext\nDescription\n\n\n\n\nExploratory Research\nWhen the research topic is relatively unknown or when exploring a phenomenon without preconceived notions or rigid frameworks.\n\n\nComplex or Dynamic Settings\nIn environments where behaviors or interactions are complex and unpredictable, allowing the observer to capture a wide range of activities and interactions.\n\n\nContextual Understanding\nWhen aiming for a deep, holistic understanding of a setting, context, or culture without predefined categories.\n\n\nFlexibility Required\nWhen the researcher needs flexibility to follow interesting leads or unexpected occurrences during observation.\n\n\nDeep Immersion\nWhen deeply understanding the culture, practices, and perspectives of a group by experiencing them firsthand.\n\n\n*Hidden Behaviors\nWhen certain behaviors or interactions are not visible to outsiders, requiring the researcher to become part of the group.\n\n\nBuilding Trust\nWhen establishing trust and rapport with participants is essential for obtaining accurate data, best achieved through involvement.\n\n\nSensitive Topics\nWhen studying sensitive or private behaviors that participants may not openly share with an outsider.\n\n\n\n\n\n\n\n\nStructured Observations\nStructured observations use closed-ended questions to obtain specific information, resulting in short responses, counts, or responses on scales. For example, researchers might conduct asynchronous observations of recordings to identify how often teachers in public educational institutions reinforce gender stereotypes among young children. As with unstructured observations, structured ones are suitable in certain context described below in Table 2.\n\n\n\nTable 2: When to consider structured observations 5\n\n\n\n\n\n\n\n\n\nContext\nDescription\n\n\n\n\nFocused Research\nWhen the research aims to collect specific, consistent, and comparable data across different settings or subjects.\n\n\nQuantifiable Data Needed\nWhen the researcher needs to quantify behaviors or interactions, making it easier to analyze and compare results.\n\n\nPredefined Variables\nWhen the study has clear research questions or hypotheses, and the researcher knows exactly what behaviors or events to observe and record.\n\n\nConsistency Across Observers\nWhen multiple observers are involved, ensuring consistency in data collection to maintain reliability.\n\n\nObjectivity\nWhen maintaining a level of detachment is important to avoid influencing participants’ behavior.\n\n\nEthical Concerns\nWhen participation might raise ethical issues, such as situations where the researcher’s involvement could affect the outcome.\n\n\nNatural Behavior\nWhen observing natural, unaltered behavior is critical, and the presence of a participant observer might alter how people act.\n\n\nLarge Groups\nWhen studying large groups or public behaviors where direct participation isn’t feasible or necessary.\n\n\nComparative Studies\nWhen comparing behaviors across different groups or settings, requiring a consistent, detached observational stance.\n\n\n\n\n\n\n\n\nChoosing Between Structured and Unstructured Approaches\nParticipant observations often align with an unstructured approach, as the richness of these activities typically relies on the events, topics, and places that emerge during fieldwork. In contrast, structured observations often align with a non-participant approach, allowing research teams to standardize observations and minimize interference with the context. The choice between structured, unstructured, or mixed approaches depends on the specific needs of the study and its research design. In practice, these approaches are not mutually exclusive, and research teams can combine both during fieldwork.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#planning-an-observation",
    "href": "data-collection/qualitative-methods/observations.html#planning-an-observation",
    "title": "Qualitative Observations",
    "section": "Planning an observation",
    "text": "Planning an observation\nPreparing for an observation involves several key steps: i) planning logistical aspects for the development of the observations, ii) structuring the team that will carry out the observation, iii) knowing the objectives of the research and becoming familiar with the observation instruments, and iv) taking into account recommendations for carrying out the observation. The logistical elements and resources that you need to keep in mind when planning for an observation are the following:\n\n\n\n\n\n\nUnderstand What You Will Observe\n\n\n\n\n\nThe first step is to review the observation matrix or other relevant study materials, paying attention to the following aspects:\n\nObjectives of the observation.\nType of observation to be conducted (e.g., unstructured participant).\nActivities to be carried out.\nPeople, places, and territories involved in the observation context.\nTiming and extent of the fieldwork.\n\n\n\n\n\n\n\n\n\n\nContact Allies, Leaders, and Key Actors\n\n\n\n\n\nFor participant observations, it is recommended to contact local people who will accompany the observations, provide context, and facilitate the activities. For non-participant observations, allies or leaders can assist with logistics and offer valuable recommendations to the research team.\n\n\n\n\n\n\n\n\n\nReview Research Ethics and Safe Data Handling Protocols\n\n\n\n\n\nTwo aspects must be taken into account when approaching an observation ethically:\n\nEnsure that all necessary permissions have been obtained from communities and partners involved to conduct observations.\nObtain informed consent from participants, particularly when collecting audio, image, or video records.\n\n\n\n\n\n\n\n\n\n\nEnsure You Have an Observation Guide and Note-Taking Format\n\n\n\n\n\nDuring the planning phase, you should make sure that:\n\nYou understand how the observation will be conducted.\nYou have adapted the note-taking strategy to the context of the observation (digital, paper).\nYou are clear on the expected outputs at the end of the field activities.\n\n\n\n\n\n\n\n\n\n\nVerify the Location and Conditions of the Observation Site\n\n\n\n\n\nSince observations often take place in participants’ everyday environments, it’s essential to ensure that the site is comfortable and suitable for the observation.\n\n\n\n\nStructuring your team\nThe team members who develop the observations vary considerably according to the scope of the research and the resources available to achieve these objectives.\nObservation teams should ideally consist of at least two members who conduct observations together. Having multiple observers broadens the perspectives on the observed contexts and enhances the collection of resources, such as audiovisual material. However, if budget constraints limit the number of observers, this could potentially affect the quality of the activity and the data collected. Additional participants might be necessary, especially in sensitive or high-security contexts. When structuring your team, consider how individual observer characteristics might influence data collection. The team should reflect on which aspects might introduce bias or cause resistance from the population being studied. Understanding the context and the population is crucial for this exercise.\n\n\nUnderstanding the Desirable Skills of the Field Team\nThe quality of data produced during qualitative research activities is closely related to the skills of the moderator and facilitator.6 These competencies, outlined in Table 3, enable teams to recognize and adequately represent the diversity within qualitative data. While these skills are typically developed through years of study and practice, field teams often consist of individuals from multidisciplinary backgrounds with varying levels of experience. Regardless of experience level, it is important to review and discuss these skills with your team to identify possible gaps and opportunities for improvement.\nCurrently, there are no standardized metrics to measure the prevalence of these skills among qualitative fieldwork moderators. Therefore, the skills below should be viewed as a resource for reference and reflection for teams. Ensuring that everyone on the team understands how these competencies contribute to effectively engaging with the population is essential for collecting high-quality information.\n\n\n\nTable 3: Desirable skills in the field team\n\n\n\n\n\n\n\n\n\n\nAbility\nDescription\nWhy is this skill important?\n\n\n\n\nCognitive empathy\nThe field team’s ability to understand and communicate participants’ situations from their perspectives, understanding how they see the world and their roles within it.\nAllows researchers to connect more deeply with participant’s realities and experiences. Helps to create a relationship of trust and respect with the participants. Seeks to avoid generalizations and stereotypes that may arise from preconceptions or external influences such as previous studies. Enhances understanding of participants’ situations without resorting to pity.\n\n\nFollow-up\nThe field team’s ability to recognize when additional information is needed to answer the questions initially posed and those that arise during the research process. This ability implies curiosity and a willingness to explore new issues or doubts that emerge as data collection progresses.\nIncreases the quality and robustness of data by allowing a more detailed exploration of the studied phenomenon. Contributes to obtaining deeper responses from participants. Enables exploration of emerging themes during data collection. Helps detect and validate patterns observed in the field.\n\n\nSelf-awareness and reflexivity\nThe field team’s ability to continuously reflect on how their presence, background, and assumptions influence data collection, interpretation, and analysis. This ongoing self-reflection ensures that the qualitative field team is mindful of its impact on the research process and the participants.\nHelps maintain ethics in the researcher-participant relationship. Facilitates understanding of personal limitations in connecting with participants. Aids in developing strategies to overcome communication barriers and create an environment where participants feel comfortable sharing sensitive information.\n\n\nHeterogeneity\nThe field team’s ability to represent and reflect the diversity within the group being studied. This skill involves recognizing and documenting the differences and variations among individuals or subgroups during qualitative research, typically applied during the data analysis phase.\nContributes to challenging generalized and simplistic patterns. Ensures that data reflect both common and atypical experiences. Demonstrates the field team’s ability to identify, recognize, and document heterogeneity in the population studied.\n\n\nPalpability\nThe field team’s ability to provide detailed descriptions in their field notes or diaries, making the data tangible and clear. This involves avoiding abstract descriptions and, instead, offering vivid accounts that allow the research team to visualize and understand participants’ experiences and contexts.\nReliable findings are supported by specific details that clearly depict the events and situations studied. Helps to avoid abstraction in the data, grounding conclusions in concrete evidence.\n\n\n\n\n\n\n\n\nStudy the observation guide\nThe resources designed for observation help guide the observer, with varying degrees of structure depending on the research design. Observation guides are characterized by:\n\nAlignment with Research Objectives: The guide should directly relate to the goals of the research.\nIdentification of Key Characteristics: It should clearly identify the characteristics that need to be observed.\nAppropriate Scope: The guide should contain a manageable number of statements for the characteristics being observed, ensuring it is comprehensive but not overwhelming.\n\n\n\n\n\n\n\nTip for note-taking\n\n\n\nYou can use narrative resources, photographs, drawings, or examples to describe participants’ interactions and reactions, as appropriate.\n\n\nFamiliarize yourself with the characteristics of the instruments and the type of information expected to be generated (e.g., field notes, diaries, or activity logs). If the observation is conducted in a group, it is advisable to study the instruments together and agree on the general criteria you wish to observe.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#conducting-an-observation",
    "href": "data-collection/qualitative-methods/observations.html#conducting-an-observation",
    "title": "Qualitative Observations",
    "section": "Conducting an observation",
    "text": "Conducting an observation\nBegin by introducing yourself and clearly explaining each team member’s role and the session’s general dynamics. If appropriate, read the informed consent, ensuring that all participants clearly understand the purpose of the activity and the potential risks and benefits of their involvement. Given the variety of formats collected (e.g., audio, video, images), informed consent must cover the full scope of the activity. Beyond the formal process of informed consent, make sure that the people, group, or community being observed know about the study and its aims.\nWhether it’s participant or non-participant observation, it’s crucial to create a comfortable and calm atmosphere to avoid discomfort and encourage spontaneity. Show interest, friendliness, and respect for all contributions, and maintain a curious and open-minded attitude, even when discussions are lengthy or opinions differ from your own. Finally, take notes on your observations or make audiovisual records according to your study’s requirements.\n\n\n\n\n\n\nTip for long-term observations\n\n\n\nIn prolonged observations, it is strongly recommended to supplement the notes of the research activities with field diaries.\n\n\n\nPotential challenges in a qualitative oobservation\nThere are situations that could take place during a qualitative interview that you should be prepared for. Here are some examples:\n\n\n\n\n\n\nDistrust on the part of the participants\n\n\n\n\n\nWhile the presence of observers inherently alters the participants’ daily routine, it can also lead to increased distrust among some individuals. Provide a detailed introduction, clearly explaining the purpose of your visit and the activities involved. Reassure participants that they are not being evaluated or judged. Use electronic devices like a computer or cell phone to record key ideas, which may make participants feel less directly observed. If the observation was planned as non-participant, consider engaging in the activities to create a more comfortable environment.\n\n\n\n\n\n\n\n\n\nDifficulty in documenting all data\n\n\n\n\n\nBalancing observation with participation can make it challenging to document all relevant information that arises during the activity. Prioritize information that is most relevant to your research. Focus on the research objectives and follow the observation guide to maintain attention on key aspects. Take quick notes during the observation, using keywords or key concepts to capture essential details.\n\n\n\n\n\n\n\n\n\nObjectivity vs. subjectivity\n\n\n\n\n\nSince observation is a subjective technique, it is crucial to differentiate between your interpretations and the descriptive elements of the environment. Write your diary or field note in three stages: Describe the environment and the participants’ interactions. Detail your own participation in the space. Record reflections and interpretations that emerge from the observation. Remember that it is essential to keep a distance from the observation activities. You should participate in the spaces while maintaining an objective view from a distance.7\n\n\n\n\n\n\n\n\n\nGenerating agreement on assigned values\n\n\n\n\n\nUsing quantitative scales in observations can be challenging, as it requires consensus on what each observer should record in each response box. Establish clear observation agreements or use standardized rating rubrics to ensure consistency across observers. Start with an unstructured observation to identify any biases or concerns, then proceed to a structured observation based on those insights. When assigning values on a scale, provide a rationale in additional comments to clarify why a particular category was selected.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#after-the-observation",
    "href": "data-collection/qualitative-methods/observations.html#after-the-observation",
    "title": "Qualitative Observations",
    "section": "After the observation",
    "text": "After the observation\nThe observation exercise concludes when you leave the participants’ environment and return to a private space for reflection. Upon returning:\n\nReview Notes: Revisit your notes and elaborate on key observations.\nWrite Observation Notes: Include descriptions of the environment, participant interactions, your participation, and any reflections or interpretations that arise.\nSupplement Your Notes: Add photographs, drawings, or maps as necessary.\nDocument Preliminary Findings: In cases of extensive fieldwork, summarize preliminary findings in field diaries based on the various collection techniques used.\n\n\nPotential errors to avoid during data closure\nThe quality of note-taking is critical to the success of the collection technique; errors to avoid are:\n\nNeglecting Note-Taking: Avoid delaying note-taking; it should be done during or immediately after the research activity.\nInadequate Refinement: Ensure that notes are refined and completed within 24 hours of the observation to capture accurate details and reflections.\nEthical Practices: Always adhere to ethical practices in data closure, particularly in protecting research subjects.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#online-observations",
    "href": "data-collection/qualitative-methods/observations.html#online-observations",
    "title": "Qualitative Observations",
    "section": "Online observations",
    "text": "Online observations\nDigitally mediated observations can be conducted in two primary ways:\n\nVideo Conferencing: An observer connects remotely via a video conferencing platform, supported by an in-situ facilitator.\nAsynchronous Review: Observers analyze recordings of activities at a later time.\n\nBoth methods involve non-participant observation with a significant physical distance from the context being studied. This distance can lead to a disconnect between the observer and the participants’ reality, potentially limiting the depth of reflections and interpretations. Despite these limitations, virtual observations can provide valuable insights, particularly in evaluating specific aspects of social programs. For instance, quantitative data can be collected by observing recorded class sessions, contributing to assessments of program impact.\nVirtual observations can also serve as an alternative when constraints arise in the following resources:\n\nTime: When scheduling conflicts or time zone differences make in-person observations impractical.\nBudget: When financial limitations restrict travel and accommodation expenses.\nAccessibility: When physical access to the observation site is challenging due to geographical or logistical barriers.\nHealth and Safety: When health risks, such as during a pandemic, prevent in-person interactions.\nEthical Concerns: When the presence of an observer might influence participants’ behavior or when anonymity is crucial.\n\nBy leveraging digital tools and platforms, researchers can continue to gather valuable data while adapting to various constraints and ensuring the safety and well-being of both observers and participants.\n\n\n\nTable 4: Considerations and challenges in virtual observations\n\n\n\n\n\n\n\n\n\n\nChallenges\nDescription\nPossible solutions\n\n\n\n\nVolume of observations\nConducting around 500 observations posed significant logistical challenges, requiring large teams and extensive resources.\nUse audiovisual recordings to capture information, which the designated team can then review.\n\n\nObserver profile\nIf the project’s focus on socio-emotional skills necessitates observers with specific professional expertise.\nIdentify the appropriate observer profile, both professionally and personally. For example, psychologists with experience in emotional intelligence and observation were selected.\n\n\nObserver out of context\nRemote observations can detach observers from the context, particularly when others collect the data, leading to a lack of crucial contextual understanding.\nDevelop critical questions for the collection team, focusing on specific aspects like site characteristics, time of observation, participant attitudes, and unrecorded comments to help the observer understand the context. Promote dialogue between the collection team and the observers to bridge contextual gaps.\n\n\nMultiple observers\nAsynchronous observation on a large scale often involves multiple observers with varying personal and professional backgrounds, potentially influencing the observation outcomes.\nCreate a structured observation guide that includes item descriptions and relevant examples to ensure consistency. For instance, provide examples of teacher actions related to emotional recognition, regulation, and validation. Conduct group observation exercises to align and verify observation standards.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#a-practical-guide-for-conducting-observations",
    "href": "data-collection/qualitative-methods/observations.html#a-practical-guide-for-conducting-observations",
    "title": "Qualitative Observations",
    "section": "A Practical Guide for Conducting Observations",
    "text": "A Practical Guide for Conducting Observations\nThe content in this resource was adapted from IPA Colombia’s “Practical Guide for Conducting Observations” (see PDF document below). This practical guide provides guidance to conduct observations to gather qualitative information in the context of public policy design and evaluation of social programs. The guide includes i) a definition of the technique and types of the collection, ii) the purpose for collecting information, iii) recommendations and steps to follow to apply the collection technique, and iv) applications of the technique in virtual context.\n\n\nUnable to display PDF file. Download instead.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/observations.html#footnotes",
    "href": "data-collection/qualitative-methods/observations.html#footnotes",
    "title": "Qualitative Observations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDiaz, L. (2010). The observation. Faculty of Psychology, National Autonomous University of Mexico.↩︎\nDiaz, L. (2010). The observation (p. 9). Faculty of Psychology, National Autonomous University of Mexico.↩︎\nKawulich, B. B. (2005). Participant observation as a data collection method. Forum Qualitative Social Research, 6(2), Article 43.↩︎\nCreswell, J. W., & Poth, C. N. (2018). Qualitative inquiry and research design: Choosing among five approaches (4th ed.). SAGE Publications.↩︎\nCreswell, J. W., & Poth, C. N. (2018). Qualitative inquiry and research design: Choosing among five approaches (4th ed.). SAGE Publications.↩︎\nCreswell, J. W., & Poth, C. N. (2018). Qualitative inquiry and research design: Choosing among five approaches (4th ed.). SAGE Publications.↩︎\nRoller, M. R. (2022). Ethnography & the observation method: 15 articles on design, implementation, & uses. Research Design Review.↩︎",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Observations"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#what-are-qualitative-interviews",
    "href": "data-collection/qualitative-methods/interviews.html#what-are-qualitative-interviews",
    "title": "Qualitative Interviews",
    "section": "What are qualitative interviews?",
    "text": "What are qualitative interviews?\nInterviews are a qualitative method of gathering information through a formal dialogue between two people—the interviewer and the interviewee—guided by a specific research goal. Unlike conventional conversations, which involve symmetrical communication and relationship (with no person guiding the conversation) between the interlocutors1, a qualitative interview is based on a structured approach. In this setting, the interviewee permits the interviewer to direct the conversation and guide the dialogue in accordance with the objectives of the study. The interviewee thus becomes the primary source of information.2\nThis collection method is characterized by its flexibility. While there is a script or a list of specific topics to investigate, the interviewer may follow emerging topics or delve deeper into particular aspects according to the interviewee’s answers. The structure of this data collection technique can vary widely. At one end of the spectrum are highly structured interviews, which follow a defined sequence of topics and number of questions. At the other end are semi-structured interviews, where the moderator intuitively delves into the topics of interest.3 The structure of the interview is influenced by the research objectives and the type of data to be obtained.\n\n\n\n\n\n\nData from qualitative interviews\n\n\n\nQualitative interviews seek in-depth answers and the person’s interpretive perspective. In general, interviews have some advantages for certain profiles in contrast to focus groups such as experts in different fields, populations that experienced traumatic events, persons deprived of liberty, geographically dispersed populations, and people with disabilities, among others. Moreover, the types of data gathered via interviews can include:\n\nFeelings and Emotions: Understanding the emotional responses and feelings of the interviewee.\nOpinions and Perspectives: Gaining insights into the interviewee’s viewpoints and beliefs.\nExperiences and Narratives: Collecting detailed accounts of the interviewee’s personal experiences.\nKnowledge and Expertise: Gathering information from experts or individuals with specialized knowledge.\n\n\n\nIn-depth interviews help to learn about the interviewees’ feelings, opinions, perspectives, beliefs, and experiences. The interviewees express themselves in their own words and in an active way, pointing out their point of view on the issues raised by the interviewer. This collection method is appropriate for discussing complex or sensitive topics that some people may be reluctant to discuss in a group setting.4 Qualitative interviews provide unique insights from participants’ experiences and knowledge, translated into detailed narratives and descriptions that reveal how people interpret their experiences and the world around them.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#planning-a-qualitative-interview",
    "href": "data-collection/qualitative-methods/interviews.html#planning-a-qualitative-interview",
    "title": "Qualitative Interviews",
    "section": "Planning a qualitative interview",
    "text": "Planning a qualitative interview\nProper preparation is essential for the success of an interview, ensuring that the research activity meets its field data collection objectives. This section provides detailed guidance on the planning steps that should be undertaken before conducting an interview.\n\n\nStructure your team\n\n\nDuring qualitative interviews, the fieldwork team is composed of a moderator and a facilitator. The facilitator’s participation is crucial to support logistical and note-taking processes. While budget restrictions may sometimes require the moderator to work individually. If you have a facilitator, it is important that you identify the functions they will perform.\n\n\n\n\n\n\nWhen NOT to have a facilitator\n\n\n\nWhen an interview involves sensitive or personal issues, such as when the interviewee is hesitant to share intimate details, the interviewer’s approach can significantly impact the conversation. For example, if a facilitator does not value the importance of mental health, this may become evident in how they take notes during an interview about traumatic experiences related to mental health.\n\n\n\n\nRecognize the skills of the field team\n\n\nThe quality of data produced during qualitative research activities is closely related to the skills of the moderator and facilitator.5 These competencies, outlined in Table 1, enable teams to recognize and adequately represent the diversity within qualitative data.6 While these skills are typically developed through years of study and practice, field teams often consist of individuals from multidisciplinary backgrounds with varying levels of experience. Regardless of experience level, it is important to review and discuss these skills with your team to identify possible gaps and opportunities for improvement.\nCurrently, there are no standardized metrics to measure the prevalence of these skills among qualitative fieldwork moderators. Therefore, the skills in Table 1 should be viewed as a resource for reference and reflection for teams. Ensuring that everyone on the team understands how these competencies contribute to effectively engaging with the population is essential for collecting high-quality information.\n\n\n\nTable 1: Skills of the field team conducting interviews\n\n\n\n\n\n\n\n\n\n\nSkill\nDescription\nWhy is this skill relevant?\n\n\n\n\nCognitive empathy\nThe field team’s ability to understand and communicate participants’ situations from their perspectives, understanding how they see the world and their roles within it.\nAllows researchers to connect more deeply with participant’s realities and experiences. Helps to create a relationship of trust and respect with the participants. Seeks to avoid generalizations and stereotypes that may arise from preconceptions or external influences such as previous studies. Enhances understanding of participants’ situations without resorting to pity.\n\n\nFollow-up\nThe field team’s ability to recognize when additional information is needed to answer the questions initially posed and those that arise during the research process. This ability implies curiosity and a willingness to explore new issues or doubts that emerge as data collection progresses.\nIncreases the quality and robustness of data by allowing a more detailed exploration of the studied phenomenon. Contributes to obtaining deeper responses from participants. Enables exploration of emerging themes during data collection. Helps detect and validate patterns observed in the field.\n\n\nSelf-awareness and reflexivity\nThe field team’s ability to continuously reflect on how their presence, background, and assumptions influence data collection, interpretation, and analysis. This ongoing self-reflection ensures that the qualitative field team is mindful of its impact on the research process and the participants.\nHelps maintain ethics in the researcher-participant relationship. Facilitates understanding of personal limitations in connecting with participants. Aids in developing strategies to overcome communication barriers and create an environment where participants feel comfortable sharing sensitive information.\n\n\nHeterogeneity*\nThe field team’s ability to represent and reflect the diversity within the group being studied. This skill involves recognizing and documenting the differences and variations among individuals or subgroups during qualitative research, typically applied during the data analysis phase.\nContributes to challenging generalized and simplistic patterns. Ensures that data reflect both common and atypical experiences. Demonstrates the field team’s ability to identify, recognize, and document heterogeneity in the population studied.\n\n\nPalpability\nThe field team’s ability to provide detailed descriptions in their field notes or diaries, making the data tangible and clear. This involves avoiding abstract descriptions and, instead, offering vivid accounts that allow the research team to visualize and understand participants’ experiences and contexts.\nReliable findings are supported by specific details that clearly depict the events and situations studied. Helps to avoid abstraction in the data, grounding conclusions in concrete\n\n\n\n\n\n\n\n\nPlan logistics activities\n\n\nLogistical activities play a crucial role in the success of interviews. Careful planning ensures that all necessary elements are in place to conduct interviews smoothly. The following list presents general activities that should happen before implementing interviews. However, this list could be more comprehensive based on the specific research needs of the field work. Ensure you cover all critical aspects to complete your research activities successfully. Based on our experience in qualitative field operations across various contexts, the IPA team has identified key practices that guide research teams in effective planning:\n\n\n\n\n\n\nSchedule Participants\n\n\n\n\n\nSchedule interviews at least one week in advance. Send reminders prior to the activity.\nDuring scheduling, inform participants about the objective, scope, leading organization, and confidentiality of the interview to align expectations and avoid confusion.\n\n\n\n\n\n\n\n\n\nVerify the location of the Interview\n\n\n\n\n\nVerify the location and conditions of the meeting site. Remember that it is important to schedule a place whose location does not pose a risk to the participant or the team.\nThis place should have appropriate seating and furniture so that the participant feels comfortable during the interview.\n\n\n\n\n\n\n\n\n\nPrepare essential materials\n\n\n\n\n\nEnsure you have all the necessary materials for the session. This includes incentives (if applicable), refreshments/snacks, attendance sheet, recording equipment, and batteries.\nTest the audio equipment in advance to ensure clear recording of the interview.\n\n\n\n\n\n\n\n\n\nReview the strategies for taking notes\n\n\n\n\n\nHave a note-taking strategy to: identify topics not recorded in the audio, capture non-verbal communication from the participant, and document the session in case the participant does not consent to being recorded. The facilitator supports this task.\n\n\n\n\n\nDesign and study the script\n\n\nUnderstanding the research questions is crucial for effective interviewing. The script is a guiding tool that helps keep the conversation within the research objectives. However, each dialogue is unique, so it’s important to study the script thoroughly to adapt to the conversation’s context without losing sight of the main topics.\nDuring the script preparation, you should identify the main questions to address the research objectives and strategically use follow-up and probing questions to delve deeper into relevant issues7:\n\nMain questions: These are the questions that guide the interview. They are defined beforehand and specified in the script.\nFollow-up questions: These are used to obtain more details and depth on specific topics, concepts, or events mentioned by the person being interviewed\n\nWhat do you think would happen if…?\nCould you give me an example of…?\nHow did you decide to do it…?\nHow did you determine what was important…?\nHow did you conclude what you are telling me…?\n\nProbing questions: They help validate what the participant is saying was understood and also encourage the dynamic flow throughout the conversation.\n\nIs this what you said…?\nDid I understand you when you said…?\nWhat is another way you could…?\nDid I paraphrase accurately what you said?\n\n\nThis will allow you to obtain the essential information directly related to the study’s objectives and explore additional areas that can provide context and enrich the understanding of the data. It is also important to understand the research goals and main questions. It will allow you to go beyond the questionnaire and approach questions or dimensions of the problem that were not initially known.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#conducting-a-qualitative-interview",
    "href": "data-collection/qualitative-methods/interviews.html#conducting-a-qualitative-interview",
    "title": "Qualitative Interviews",
    "section": "Conducting a qualitative interview",
    "text": "Conducting a qualitative interview\nTo begin the interview, always start by introducing yourself and the objective of the session. Read the informed consent form, ensuring that the interviewee understands the purpose of the activity, its confidentiality, and the potential risks and benefits of participating in it. Use simple words that the interviewee understands. Then, emphasize the data security measures your team is taking to keep the information confidential. This will help the interviewee feel confident that they can freely discuss their experiences and will be heard.Create a comfortable and calm atmosphere. Finally, and throughout the activity, it is essential to create a comfortable and calm atmosphere that allows the interviewee’s opinions to be spontaneous.\n\n\n\n\n\n\nRole of the facilitator in this phase\n\n\n\n\nEnsure that recording equipment is working properly throughout the activity.\nAsk counter-questions to the interviewee.\nVerify that no relevant topics are left out.\nAssist if the interviewee’s emotions prevent them from continuing with the interview. For example, in actions such as offering a glass of water or proposing a pause.\nTake notes of the entire activity, especially the interviewee’s nonverbal reactions.\nSupport the moderator in time management.\n\n\n\n\nBeing an effective interviewer?\nThe interviewer guides the discussion and ensures the flow of the dialogue with the interviewee while focusing on the relevant issues. An effective interviewer, not only facilitates a smooth and natural discussion, but also creates an environment where the participant feels comfortable and safe expressing their opinions openly, without fear of criticism or judgment. Table 2 presents some of the skills of effective qualitative interviewers.\n\n\n\nTable 2: Desirable skills of an interviewer\n\n\n\n\n\n\n\n\n\n\nSkill\nDescription\nWhy is this skill relevant?\n\n\n\n\nProvide for participants’ well-being\nCreate safe and comfortable environment. Prioritize interviewee’s well-being, respect and value. Adapt environment and rhythm to reduce stress/discomfort.\nHelps establish trust and encourages open dialogue. Shows respect for participant’s comfort and dignity. Body language that promotes trust is essential.\n\n\nBe empathetic\nExpress empathy and validate interviewee’s emotions to create atmosphere of openness and sincerity. Practice effective communication.\nCreates atmosphere of trust. Helps interview flow smoothly. Express gratitude for participation. Match facial expressions and tone to emotions shared.\n\n\nUse few interruptions\nAvoid abrupt interruptions. Guide conversation back on track subtly when needed. Let interviewee establish narrative order.\nRespects participant as main source of information. Allows natural flow of conversation while maintaining focus. Can use techniques like paraphrasing to redirect gently.\n\n\nListen actively8\nShow full attention and interest. Consider both verbal and non-verbal communication. Ask thoughtful follow-up questions.\nDemonstrates respect and engagement. Helps ensure accurate understanding. Allows deeper exploration of topics through appropriate follow-up.\n\n\nAvoid value judgments\nMaintain neutral, inquiring stance. Don’t express agreement/disagreement that could influence responses.\nPrevents biasing responses. Keeps focus on participant’s perspective. Use neutral phrases to encourage elaboration.\n\n\nTrain your memory\nDevelop ability to remember key details for meaningful connections during conversation.\nEnables better follow-up questions. Helps maintain conversation flow. Allows tracking of important themes.\n\n\nUse silences positively\nHandle silences constructively to allow reflection time. Avoid filling silence with filler words.\nGives participants time to think deeply. Shows respect for responses. Allows natural pace of conversation.\n\n\n\n\n\n\n\n\nPotential challenges in a qualitative interview\nThere are situations that could take place during a qualitative interview that you should be prepared for. Here are some examples:\n\n\n\n\n\n\nIncomplete, superficial or monosyllabic responses\n\n\n\n\n\nIn some interviews, particularly at the beginning, the interviewee may be shy or inhibited, which prevents them from providing detailed and in-depth answers to the questions posed. To identify an incomplete or superficial response, you can look for aspects such as:\n\nanswers that are too general and do not provide specific details\nanswers that are restricted to one or a few words\nhaste in answering without going into detail.\n\nInvest time at the beginning of the activity to build rapport with the interviewee before addressing more in-depth questions. This initial trust may encourage fuller responses. You can use “icebreaker” activities to do this. Ask open-ended questions that require a more elaborate response and prepare follow-up questions to provide more details on initial responses. Politely ask for clarification by using counter-questions like “How did you feel about this?” or “What was your reaction when this happened?” to encourage more detailed answers. Explain how your answers make a valuable contribution to the study or project. Ask easy-to-understand questions in simple language and rephrase some if necessary.\n\n\n\n\n\n\n\n\n\nEmotional overflow from participants\n\n\n\n\n\nParticipants may experience intense emotions during an interview, which can be challenging to manage due to the personal nature of discussions. Be empathetic and avoid abrupt changes in discussion topics during emotionally charged moments. Allow participants to express their emotions while guiding the discussion constructively. Offer the option to pause or continue based on the participant’s comfort. If emotions are overwhelming, take a short break and show support. Provide relevant mental health care information as per research protocols. Ensure the field team has training in psychological first aid if sensitive issues will be discussed.\n\n\n\n\n\n\n\n\n\nFatigue\n\n\n\n\n\nFatigue can affect both the interviewee and interviewer, leading to a loss of concentration, energy, and quality in responses. This may result in missed questions or premature assumptions. Limit the interview length and be flexible with scheduling if you notice signs of fatigue. Ensure the interview environment is comfortable, with good lighting and low noise. Schedule breaks during the interview if necessary, or continue at another time if needed. Consider active breaks or refreshments to help rejuvenate participants.\n\n\n\n\n\n\n\n\n\nDeviation from the central theme\n\n\n\n\n\nConversations may deviate from the interview’s objectives, requiring the moderator to tactfully redirect the discussion while balancing the exploration of valuable but off-topic insights. Direct the conversation subtly and without abruptly interrupting the interviewee to return to the main topic. Establish clear objectives at the beginning. Before starting the interview, explain the objectives and topics to be covered so that the interviewee is clear about the necessary focus.\n\n\n\n\n\n\n\n\n\nHostile interviewee\n\n\n\n\n\nAn interviewee may dominate the conversation with aggressive or derogatory language, creating a tense atmosphere. Prepare some key concepts about the topic that can help you respond confidently to the interviewee’s objections or challenges. In the event of verbal or other kind of aggression, politely end the interview, thanking the participant for their time.\n\n\n\n\n\nCommon interview mistakes\nWhen conducting qualitative interviews, some mistakes should be avoided so that the research activity, objectives, and the integrity of the person being interviewed are protected. Some mistakes are described here:\n\n\n\nFigure 1. Common mistakes made when conducting interviews",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#after-the-interview",
    "href": "data-collection/qualitative-methods/interviews.html#after-the-interview",
    "title": "Qualitative Interviews",
    "section": "After the interview",
    "text": "After the interview\nThe interview concludes when you, as the interviewer, determine that all the topics outlined in the script have been covered or if the interviewee indicates that the session should end due to time constraints or emotional reasons. To wrap up the working session, it is recommended to:\n\nProvide space for reflection in which the interviewee can express comments, suggestions, or questions about the discussion\nExpress gratitude to the participants for their time and willingness to participate, emphasizing the importance of their opinions and the information they provided to the study\nSecure the data by prioritizing the safe storage of the recording and notes from the session.\n\nIt is also important to start working on the interview notes as soon as possible once it has been completed because if too much time passes between field activities and developing analysis, there is a risk of accumulating information and losing the opportunity to enrich the study research team insights.\n\nDocument Research Activities\nAt the end of the interview, it is important to document the information obtained in detail. How this documentation is done is a decision linked to the research design and is determined before fieldwork begins. Examples of products you can use for this purpose are: - Full transcripts of the discussions - Detailed notes taken during the research activity - Field notes - Field diaries\n\n\n\n\n\n\nRemember:\n\n\n\nThe lack of initial documentation products risks all information processing components and, thus, the quality of the data obtained.\n\n\nInformation should be recorded promptly, as soon as the interview concludes, to prevent the loss of crucial details. This immediate action is vital to the research process. In addition, the products derived from the focus group must follow information storage protocols, which may include anonymization and encryption to avoid compromising the confidentiality of participants.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#online-interviews",
    "href": "data-collection/qualitative-methods/interviews.html#online-interviews",
    "title": "Qualitative Interviews",
    "section": "Online interviews",
    "text": "Online interviews\nRemote interviews (virtual via a digital platform such as meets, Zoom, or telephone) are an alternative when face-to-face interviews are not feasible due to distance, time, and budget constraints or when the interviewee prefers a remote setting. These interviews are beneficial for connecting participants from distant geographic locations or those who cannot attend in person, while also providing a safe and discrete environment. However, remote settings come with specific challenges that must be considered.\n\n\n\nTable 3: Considerations and challenges in virtual interviews\n\n\n\n\n\n\n\n\n\n\nChallenges\nDescription\nPossible solutions\n\n\n\n\nBuilding trust and empathy\nIn remote interviews it is often more difficult to establish trust.\nInvest time in the initial conversation to establish a personal connection. Be verbally expressive and attentive to compensate for the lack of more subtle nonverbal cues. Avoid distractions that may be present. In the case of virtual interviews, ask the participant to use a camera during the activity.\n\n\nConnectivity problems\nConnectivity problems include situations that may cause people to wholly or partially interrupt their participation in the interview.\nDuring the scheduling, validate the participants’ connection difficulties; if they require it, make internet recharges. Avoid that the research activity generates connectivity costs for the participants. If necessary, consider interviewing in person.\n\n\nFatigue due to constant use of screens\nFatigue associated with prolonged screen use or time on the phone can affect the concentration of both the interviewer and the interviewee.\nPlan breaks during lengthy interviews. Limit the duration of each session to a reasonable time, approximately one (1) hour. Plan several sessions if necessary.\n\n\nUsers multitasking\nThe person being interviewed may perform other tasks while participating (for example, preparing lunch or attending to someone else). This may affect their participation in the activity.\nSuggest that the interviewee have their camera turned on. During scheduling, remember that the interview is an activity that involves full attention to listening to others, and engagement with the questions.\n\n\nConfidentiality\nSome interviewees may carry out the activity in spaces shared with family members and acquaintances. Depending on the sensitivity of the topics, this situation may place participants in uncomfortable or risky situations.\nAdvise interviewees on how to select an ideal space to have the interview. Inform the participant when the recording starts, pauses or stops.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#a-practical-guide-for-conducting-interviews",
    "href": "data-collection/qualitative-methods/interviews.html#a-practical-guide-for-conducting-interviews",
    "title": "Qualitative Interviews",
    "section": "A Practical Guide for Conducting Interviews",
    "text": "A Practical Guide for Conducting Interviews\nThe content in this resource was adapted from IPA Colombia’s “Practical Guide for Conducting Qualitative Interviews” (see PDF document below). This practical guide provides some tools to conduct qualitative fieldwork through interviews. However, it is essential to note that data collection is one of the first steps in the process. After data collection, a necessary process of analyzing the information collected follows. This analysis allows the results to be interpreted and understood in depth, facilitating the identification of patterns, themes, and meanings crucial for qualitative research.\n\n\nUnable to display PDF file. Download instead.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/interviews.html#footnotes",
    "href": "data-collection/qualitative-methods/interviews.html#footnotes",
    "title": "Qualitative Interviews",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRuiz, A. (n.d.). Entrevista cualitativa: la conversación como forma de acceso al conocimiento [Paper presentation]. II Jornada de Investigación en Disciplines Artísticas y Proyectuales. http://sedici.unlp.edu.ar/handle/10915/39236↩︎\nLópez, R., & Deslauriers, J. P. (2011). The qualitative interview as a means of research in Social Work. Márgen, (61).↩︎\nRyan, F., Coughlan, M., & Cronin, P. (2009). Interviewing in qualitative research: The one-to-one interview. International Journal of Therapy and Rehabilitation, 16. https://doi.org/10.12968/ijtr.2009.16.6.42433↩︎\nMack, N., Woodsong, C., MacQueen, K. M., Guest, G., & Namey, E. (2005). Module 3 In-Depth Interviews. In Qualitative Research Methods: A Data Collector’s Field Guide (pp. 29-50).↩︎\nSmall, M. L., & Calarco, J. (2022). Qualitative Literacy: A guide to evaluating ethnography and interview research. University of California Press.↩︎\nSmall, M. L., & Calarco, J. (2022). Qualitative Literacy: A guide to evaluating ethnography and interview research. University of California Press.↩︎\nRubin, H. J., & Rubin, I. S. (2012). Structure of the responsive interview. In Qualitative Interviewing: The Art of Hearing Data (3rd ed., pp. 115-129). SAGE Publications.↩︎\nKvale, S. (2007). Conducting an interview. In Doing Interviews (pp. 52-66). SAGE Publications.↩︎",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Interviews"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#what-is-a-rapid-ethnographic-assessment",
    "href": "data-collection/qualitative-methods/ethnographies.html#what-is-a-rapid-ethnographic-assessment",
    "title": "Rapid Ethnographic Assessments",
    "section": "What is a Rapid Ethnographic Assessment?",
    "text": "What is a Rapid Ethnographic Assessment?\nRapid Ethnographic Assessments (REA) are a qualitative research method that allow nimble collection of information for decision-making. This methodology is characterized by several key features1:\n\n\nConduct participant observations: To approach the internal perspective of individuals in specific situations, from everyday life and the researcher’s own experiences during events.\nUse of field notes: To condense the preliminary results from various data collection techniques (e.g., focus groups, interviews, observations, etc.). These field notes include dense descriptions and reflective statements documenting the fieldwork, along with personal reflections.\nEstablish relationships with the community or participants: | REA is based on the premise that extensive and in-depth information can be obtained through short, intensive and participatory fieldwork with the community. This participatory aspect ensures active engagement and involvement.\nSeek social and cultural relationships within a group of people: REA emphasizes on understanding individual daily activities and group’s culture, norms, activities, and social relations. In contrast to classic approaches, it offers a more specific focus, a shorter duration, and limited scope.\nHolistic approach to the topics studied: Conducting an REA allows the researcher to connect qualitative data collection techniques and other available data sources to rapidly generate insights. These insights are obtained through researcher’s interpretations. The focus of REA is not objectivity but the identification of high-quality relationships among people, stories, and events mapped in the field.\n\n\nThese principles have their roots in classical ethnography, which aims to understand a problem or situation from the “insider’s” or “subject’s perspective.” Unlike classical ethnographies that involve extensive time (potentially months or years) in the field, Rapid Ethnographic Assessments (REA) are executed in a short period of time and seek to inform decision-makers in a timely manner. Some authors have suggested that REA should be conducted over four to six weeks.2\n\n\n\n\n\n\nCombining multiple data-collection techniques\n\n\n\nWith rapid ethnographies, information can be collected mainly through qualitative techniques, such as interviews, focus groups, and observations. However, quantitative techniques, such as available data and short surveys, can also be used to support the answer to the research questions.3 To achieve relevant insights, REAs are characterized by the triangulation of results, the consolidation of multidisciplinary teams, and iterative learning processes.4 Combining multiple techniques positions rapid ethnography as a tool that provides findings and recommendations based on detailed, culturally relevant information reflecting local realities.\n\n\n\nWhen to consider doing a REA?\nREAs are particularly useful when practical and actionable recommendations are needed quickly. While this methodology has great potential, the rapid collection and processing mean that REA findings are exploratory. Their scope is limited to identifying findings from particular contexts rather than generating generalizable knowledge. In this sense, REA is especially useful when:\n\nMore information is needed about an emerging problem or situation with little existing knowledge: Rapid ethnographies can provide descriptive information about poorly understood problems, helping to identify causes and design appropriate interventions.\nEngagement with “hidden” or vulnerable populations is necessary: Some populations may be particularly closed and difficult to reach. Accessing these groups requires the support of trusted individuals within the community. Rapid ethnographies often seek to identify and involve these community leaders to facilitate contact and build trust during the research.\nCommunity involvement is essential: Understanding how to address a problem requires the involvement of local community members. Involving the people who are directly affected by a problem often results in more practical and achievable recommendations for the program or intervention.\n\nBelow are three real-world applications of rapid ethnographic assessments:\n\n\n\n\n\n\nPublic Health\n\n\n\n\n\nAfter Hurricane Katrina, New Orleans experienced a demographic increase in the Latino population, particularly among single, undocumented men. Researchers suspected an emerging pattern of crack use among this population but needed more information to formulate responses. The REA results revealed how contextual factors such as a growing drug market, coupled with social isolation and victimization of the undocumented Latino population, led to the initiation and increase in crack use among a group that previously had relatively low drug use.\n\n\n\n\n\n\n\n\n\nMigration\n\n\n\n\n\nAccessing the migrant and refugee vulnerable population is a challenge due to factors such as stigmatization of the population due to lack of regular migratory status, lack of documentation, and distrust towards state institutions. Rapid ethnographies allowed for strategic approaches with community leaders and migrant organizations within local communities. Their involvement was fundamental in building trust in the community and accessing the target population, making them feel included and valued in the process.5\n\n\n\n\n\n\n\n\n\nEmergency Settings\n\n\n\n\n\nBetween November 2020 and January 2021, during the COVID-19 pandemic, researchers conducted a REA in Dhaka, Bangladesh. They used in-depth interviews and participant observations to explore their health-related beliefs and practices. REA revealed a gap between scientific explanations of COVID-19 and the community’s cultural and spiritual beliefs, such as the perception of the virus as a disease of the rich and sinners, leading many to reject biosecurity measures. These findings highlighted the need for a deeper understanding of community perceptions to improve the effectiveness of public health policies.6",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#planning-a-rea",
    "href": "data-collection/qualitative-methods/ethnographies.html#planning-a-rea",
    "title": "Rapid Ethnographic Assessments",
    "section": "Planning a REA",
    "text": "Planning a REA\n\n\nAssess the relevance of the methodology\n\n\nBefore starting a rapid ethnographic assessment, it is crucial to determine if this methodology is suitable for your research objectives. Consider the following questions:\n\nDoes the research require in-depth, qualitative insights within a short timeframe? Rapid ethnographies are designed to provide timely, actionable data.\nAre there specific cultural or social dynamics that need to be understood quickly? This method is particularly useful for exploring complex social interactions and cultural contexts.\nIs there a need for participatory engagement with the community? Rapid ethnographies emphasize active involvement and collaboration with community members.\nAre the necessary resources and expertise available? Ensure that your team has the skills and tools required to conduct qualitative research effectively.\n\nIf the answers to these questions align with your research needs, rapid ethnography may be an appropriate choice. The data produced during REA is gathered through a combination of various data collection techniques. The information and resources obtained from these techniques can be presented in a variety of formats. This interactive process involves the use of:\n\nAudio recordings from interviews and focus groups\nPhotographs and videos taken during observation activities\nTexts resulting from note-taking during activities\nOther resources such as maps or drawings provided by the community\n\nThe mechanism of interaction between resources and the process on how that information contributes to generate insights depends on the scope of research questions and the strategy designed by the researcher to address rich information with time constraints.\n\n\nAdditional considerations for conducting a REA\n\n\n\nDuration: Although there is no set rule on how much time is sufficient to conduct it, most experts agree that the time spent in the field collecting data should be between two and six weeks.7 The speed of data collection will depend on the research objectives, funding, and the technical expertise of the team. Remember that a key aspect of rapid ethnographies is to produce actionable and timely data for decision-makers. If the timeline is not feasible and available funding is limited, another method may be more appropriate. Some key questions to sort this out include: “When are the findings needed?; Can the timeline be met?; Are the necessary technical and financial resources available?\nEthical considerations: Ensure that appropriate IRB permits and certifications are in place if required. This measure ensures that the research will not harm people and communities due to the project’s processes or findings.\nData collection techniques: Identify data collection techniques that will be prioritized Here, consider the information you want to collect and consult the practical guidelines for focus groups, interviews, and observations, as these are the most common collection techniques in REA. However, depending on the research needs and the research team’s experience, other collection techniques such as ethnographic mapping or short surveys can be implemented (For detailed data collection techniques used in rapid ethnographies, see Annex 1).\n\n\n\nStructure your team\n\n\nWhen structuring your team, carefully consider who will make up an effective and productive team. Take into account the experience required for each role and ensure that team members are well-suited to the tasks they will perform in the field. To achieve this, define who will be in the field and the characteristics that each team member should have. The best multidisciplinary teams comprise people with complementary skills and technical or subject matter expertise. In addition, teamwork has been identified as beneficial, as it facilitates the development of ethnographic research from different points of view, often integrating knowledge from various fields, areas, or topics.8 Three essential elements of a strong team are (i) expertise in qualitative methods, (ii) expertise in content or topics, and (iii) expertise in the local context.9\nThere should be at least one person on the project team with experience in qualitative research methods. This person should be responsible for helping to keep the project on track by monitoring the quality of the data collected and training team members when necessary. This role will facilitate learning from participants due to their ethnographic orientation and sensitivity to the project.10\nIt is also highly recommended to have people with thematic expertise and actively involve stakeholders. Thematic experts could guide the research team in understanding the findings nuances and connecting it with literature, as well as provide institutional context, depending on the study topic. In turn, stakeholders can act as advisors throughout the study, ensuring relevance and facilitating the incorporation of findings into practical changes.11\nIn addition, the team should include people who are closely involved on a daily basis with the problem or phenomenon under study. These are usually people from the local community or target population. These people are sometimes called “cultural experts.” They should be a trusted person who can help facilitate access and interaction with hard-to-reach populations and provide information on how things are organized within their community.12\nFinally, assign roles and functions to each team member. Before starting the collection, define the roles and functions of the field team. Some key roles and functions must be assigned to achieve the proposed objectives. To do this, make a role assignment matrix to organize the tasks of contacting or scheduling participants, logistics of access to the territory, information collection, data flow closure, and analysis.\n\n\nRecognize the skills of the field team13\n\n\nThe quality of data produced during qualitative research activities is closely related to the skills of the moderator and facilitator. These competencies, outlined in Table 1, enable teams to recognize and adequately represent the diversity within qualitative data.\nWhile these skills are typically developed through years of study and practice, field teams often consist of individuals from multidisciplinary backgrounds with varying levels of experience. Regardless of experience level, it is important to review and discuss these skills with your team to identify possible gaps and opportunities for improvement.\nCurrently, there are no standardized metrics to measure the prevalence of these skills among qualitative fieldwork moderators. Therefore, the skills in Table 1 should be viewed as a resource for reference and reflection for teams.\nEnsuring that everyone on the team understands how these competencies contribute to effectively engaging with the population is essential for collecting high-quality information.\n\n\n\nTable 1: Skills of field staff conducting a REA\n\n\n\n\n\n\n\n\n\n\nAbility\nDescription\nWhy is this skill important?\n\n\n\n\nCognitive empathy\nThe field team’s ability to understand and communicate participants’ situations from their perspectives, understanding how they see the world and their roles within\nAllows researchers to connect more deeply with participant’s realities and experiences. Helps to create a relationship of trust and respect with the participants. Seeks to avoid generalizations and stereotypes that may arise from preconceptions or external influences such as previous studies. Enhances understanding of participants’ situations without resorting to pity.\n\n\nFollow-up\nThe field team’s ability to recognize when additional information is needed to answer the questions initially posed and those that arise during the research process. This ability implies curiosity and a willingness to explore new issues or doubts that emerge as data collection progresses.\nIncreases the quality and robustness of data by allowing a more detailed exploration of the studied phenomenon. Contributes to obtaining deeper responses from participants. Enables exploration of emerging themes during data collection. Helps in detecting and validating patterns observed in the field.\n\n\nSelf-awareness and reflexivity\nThe field team’s ability to continuously reflect on how their presence, background, and assumptions influence data collection, interpretation, and analysis. This ongoing self-reflection ensures that the qualitative field team is mindful of its impact on the research process and the participants.\nHelps maintain ethics in the researcher-participant relationship. Facilitates understanding of personal limitations in connecting with participants. Aids in developing strategies to overcome communication barriers and create an environment where participants feel comfortable sharing sensitive information.\n\n\nHeterogeneity\nThe field team’s ability to represent and reflect the diversity within the group being studied. This skill involves recognizing and documenting the differences and variations among individuals or subgroups during qualitative research, typically applied during the data analysis phase.\nContributes to challenging generalized and simplistic patterns. Ensures that data reflect both common and atypical experiences. Demonstrates the field team’s ability to identify, recognize, and document heterogeneity in the population studied.\n\n\nPalpability\nThe field team’s ability to provide detailed descriptions in their field notes or diaries, making the data tangible and clear. This involves avoiding abstract descriptions and, instead, offering vivid accounts that allow the research team to visualize and understand participants’ experiences and contexts.\nThe palpable field notes and diaries are accompanied by textual quotations, images, or other audiovisual resources that show events, situations, and actors that support the research findings. Reliable findings are supported by specific details that clearly depict the events and situations studied. Helps to avoid abstraction in the data, grounding conclusions in concrete evidence.\n\n\n\n\n\n\n\n\nPlan logistics activities\n\n\n\nContact allies, leaders, and key actors: Engage with local partners to understand contextual factors, convene participants, and coordinate logistics. Local partners can facilitate data collection.\nMake a schedule defining the field collection activities:: Define all field collection activities, the total number of tasks to be completed, and the time available; Share the schedule with allies and key stakeholders to; Confirm participant availability on the selected dates; Identify locations where activities will take place.; Ensure there are no conflicting events in the community; Use visual tools such as a Gantt chart for developing the schedule.\nVerify the location and conditions of the places where the collection activities will take place: Identify safe locations that facilitate interaction with the community. Work with local community organizations and leaders if possible. Gather general field information and visit the community with someone locally trusted to establish rapport and familiarize yourself with the area.\nEnsure the safety of the field team: Conduct a thorough risk assessment during the planning phase. Prioritize the safety of both the field team and the community to minimize risks.\nEnsure that you have all the necessary materials to carry out the activities: Prepare incentives for participants (if applicable). Arrange refreshments, stationery, attendance lists, informed consents (if applicable), recording equipment, photographic equipment, batteries, etc.\n\n\n\n\n\n\n\nScheduling REA activities\n\n\n\nA field collection activity lasts, on average, 2 to 3 hours. Therefore, a maximum of two (2) activities per day is recommended. This ensures the quality of the data, does not exhaust the field team or the community, and avoids losing focus due to fatigue or saturation. In addition, the schedule of activities should include the time allocated by the team to:\n\nTravel or transport to the collection sites\nCollect data\nTake notes\nRefine the field notes and integrate other resources generated\n\n\n\n\n\nPlan to ensure effective fieldwork and secure storage of gathered information\n\n\nIn addition to logistical planning, the team must decide how to handle the collection and secure management of data to ensure its quality and facilitate its subsequent systematization. To this end:\n\nDefine who will lead data collection and reception within the team: One person should lead the instrument design, data collection, resources reception (based on fieldwork results), and analysis. Ideally, this person should have experience applying qualitative research methods and be involved in fieldwork and data collection. This person’s involvement in the project’s different stages will make it easier to manage the information collected and ensure the integration of the various sources and resources.\nDefine a note-taking strategy for the different activities: Note-taking is essential across all data collection activities in REA, even if recordings are available. The team leader should agree with the team on things like the format that everyone will use for their note-taking, critical aspects that require more or less attention from the team to address in the notes, types of formats that could complement the notes (photographs, videos, maps, etc.), and the dates for intermediate and final results. Overall, Having a common understanding of these processes will ensure the smooth flow of data collection and a clear scope of each role within the team.\nStudy the instruments, scripts, and practical guides provided to ensure data quality during data collection: Before fieldwork, all team members should familiarize themselves with the characteristics of the instruments and the type of notes and supplementary resources to be generated in each case. Use the practical guides provided to prepare accordingly for the prioritized techniques.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#conducting-a-rea",
    "href": "data-collection/qualitative-methods/ethnographies.html#conducting-a-rea",
    "title": "Rapid Ethnographic Assessments",
    "section": "Conducting a REA",
    "text": "Conducting a REA\nStart by establishing a periodic check-in meetings with the team. During fieldwork, the team should meet periodically to share insights and determine if adjustments are needed for upcoming activities. These debriefing sessions are a key component of rapid ethnography and should be scheduled to ensure they are not overlooked. Some guiding Questions for Check-Ins include:\n\nWere there any unexpected or stressful events?\nHow well did you perform as an interviewer, moderator, observer, or note-taker?\nWhat kind of data did you collect?\nAre there any gaps that need follow-up?\nWhat adjustments would you make to the data collection guides or techniques?\nAre there new sites or contexts that need observation?\n\nTake notes during these meetings to track follow-up actions. These sessions are also a chance to discuss the project’s progress, address logistical challenges, and provide team members with training or advice on collection techniques.\n\n\n\n\n\n\nThe importance of check-ins\n\n\n\nDue to time constraints, it’s tempting to skip check-ins or leave discussions for after fieldwork is complete—this is a mistake!\nSharing information in a group setting improves the quality of data collection and subsequent analysis. Make sure blocks of time are scheduled in advance for these meetings.\n\n\n\nPotential challenges during check-in meetings and fieldwork development\nThere are situations that could take place while checking-in with your field team that you should be prepared for. Here are some examples:\n\n\n\nTable 2: Challenges (and solutions) for REA check-ins\n\n\n\n\n\n\n\n\n\nChallenge\nPossible solutions\n\n\n\n\nOne team member usually dominates the conversation during debriefing meetings\nEmphasize the importance of teamwork during training. Rotate facilitators for check-in meetings to give everyone a chance to lead and ensure balanced participation. Foster an environment where each team member shares their insights.\n\n\nField teams may encounter challenges in implementing reflexivity practices when conducting REAs\nEncourage ongoing communication about biases that may influence data interpretation. Adapt meeting formats to fit fieldwork dynamics. Use flexible field diaries to document biases while accommodating the pace and nature of the research.\n\n\nThere is an evident lack of consistency in collecting information among the field team14\nImplement standardized data collection tools and provide clear instructions on using them. During training, discuss the context of the REA and emphasize shared best practices for approaching unstructured situations.\n\n\nSome team members need to pay more attention to the ethical aspects of the research\nAccelerated timelines can lead to ethical lapses. Emphasize the importance of ethical practices during training and ensure that all team members understand how to uphold ethical standards to protect participants and maintain data integrity.15\n\n\nTeam members say they are uncomfortable with the activities they witness\nDiscuss potential uncomfortable situations during training so that team members are prepared. If discomfort arises in the field, reassign less sensitive tasks to the team member and ensure they can perform their role without bias. Some team members may be unsuitable for certain projects due to personal beliefs or values.\n\n\nSome team members are trained and oriented quantitatively and unfamiliar with REAs and qualitative methods\nProvide thorough training on qualitative methods and the specific REA protocols. Ensure that all team members understand their roles in data collection, including note-taking and techniques. Rotate tasks to allow everyone to gain hands-on experience in different aspects of the REA process.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#after-a-rea",
    "href": "data-collection/qualitative-methods/ethnographies.html#after-a-rea",
    "title": "Rapid Ethnographic Assessments",
    "section": "After a REA",
    "text": "After a REA\nOnce data collection is complete, the team will have multiple sources of information, resources, and data from the research activities conducted in the field. To ensure proper management of these data, the following steps are suggested:\n\nAfter each data collection journey, each team member must ensure secure data collection storage according to the protocols for developing human subject research defined for the project. This includes: (i) transfer all recordings, photographs, and audiovisual material to the designated folders or storage platforms; (ii) Name files according to protocol, (iii) Anonymize and encrypt sensitive material to protect participants’ privacy.\n\n\n\n\n\n\n\nWarning\n\n\n\nThe lack of initial documentation products jeopardizes all the information processing components and, therefore, the data quality obtained.\n\n\n\nField notes are the primary data source for rapid ethnographies, so it is crucial to write and expand them as soon as possible, ideally within 24 hours of collection. To do this, integrate complementary material and resources, such as photographs, videos, maps, drawings, field diaries, etc., into the field notes, according to the protocols and quality criteria agreed upon with the team in the planning phase. Standardizing this process will save time during the systematization phases, prevent data loss, and facilitate the project leader’s review of the information.\n\n\n\n\n\n\n\nTip\n\n\n\nUse of photographic material Photographs are excellent complements to field notes. While they don’t need to be technically perfect, their primary function is to document key details and provide contextual information. However, always follow ethical guidelines to ensure participants’ safety and confidentiality before taking photographs.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#digital-ethnographies",
    "href": "data-collection/qualitative-methods/ethnographies.html#digital-ethnographies",
    "title": "Rapid Ethnographic Assessments",
    "section": "Digital Ethnographies",
    "text": "Digital Ethnographies\nThe internet and digital technologies have accelerated the way people live, work, and relate to each other. In response to this social phenomenon, digital ethnography has emerged, a method that studies how people behave and interact in virtual environments, creating communities in digital spaces.16\nDigital ethnography adapts traditional ethnographic research techniques to studying online cultures and communities formed through communications mediated by a computer or mobile device. Instead of physically being in a community, researchers immerse themselves in online communities, forums, and social networking platforms. This way, the digital ethnographer observes and analyzes how individuals interact in these virtual spaces.17\nTechniques commonly used in digital ethnography are participant and non-participant observation, interviews, focus groups, and short surveys. To conduct a digital ethnography, follow the steps described above for performing a rapid ethnography. In addition, these considerations will be useful when adapting this method to a digital environment.18\n\n\n\nTable 3: Challenges (and solutions) for digital REAs\n\n\n\n\n\n\n\n\n\n\nChallenges\nDescription\nSolutions and recommendations\n\n\n\n\nEthical concerns: Informed consent\nObtaining informed consent from online participants can be challenging.\nWhenever possible, contact participants and share and socialize the informed consent. Some platforms may have specific terms of service, but it is essential to ensure that participants understand the research and agree to participate voluntarily.\n\n\nEthical concerns: anonymity and privacy\nProtecting the privacy and anonymity of participants in virtual environments is becoming more complex.\nSome platforms may have specific terms of service and data processing. Please review these terms. Researchers should inform participants if they intend to share information so that appropriate measures can be taken and the risk of participant identification minimized if the participant does not wish to be identified.\n\n\nDigital divide: Disparities in access\nNot everyone can access the Internet or digital devices equally.\nBe mindful of access gaps that may lead to a biased sample, excluding certain demographic groups and limiting the generalizability of the findings.\n\n\nDigital divide: Low digital literacy\nParticipants may have no or low skills in handling technological devices, which may affect their online behaviors.\nThese differences should be considered when presenting findings during the data analysis and interpretation phases. When using WhatsApp, use the application’s various resources, such as voice notes, images, videos, and stickers, to convey information accurately, directly, and responsively to users with these difficulties.\n\n\nData quality and authenticity: Incorrect representation\nParticipants may present themselves differently online, creating a potential gap between their online persona and offline identity.\nNote that automated accounts, trolls, and fake profiles can complicate data interpretation and introduce biased information into the analysis. Always be aware of the potential for misrepresentation in digital environments.\n\n\nLow participation: Interaction at problematic times\nParticipants may need help participating in the activities due to schedule conflicts or lack of time availability.\nConduct baseline surveys to identify the schedules that best meet the population’s needs. From the beginning, underline clear rules about desirable times to receive messages.\n\n\nLow participation: Lack of trust\nParticipants may be distrustful of being artificially linked to virtual communities.\nMake prior contact with participants before linking them to virtual spaces to introduce them to the organization. Present again the purpose of the research. Sometimes, participants do not complete the informed consent form.\n\n\nInterpretation: Difficulty in interpreting content\nMessages shared by participants may present an interpretive challenge for the researcher, as the tone of the message is attributed by the reader.\nActively moderate to ask counter-questions to clarify the message. Promote clear communication in written messages. Record questions arising from participation in virtual scenarios from participant interactions in your field diary or field note.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#a-practical-guide-for-conducting-ethnographies",
    "href": "data-collection/qualitative-methods/ethnographies.html#a-practical-guide-for-conducting-ethnographies",
    "title": "Rapid Ethnographic Assessments",
    "section": "A Practical Guide for Conducting Ethnographies",
    "text": "A Practical Guide for Conducting Ethnographies\n\n\nUnable to display PDF file. Download instead.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/ethnographies.html#footnotes",
    "href": "data-collection/qualitative-methods/ethnographies.html#footnotes",
    "title": "Rapid Ethnographic Assessments",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPalazzo, L., Figueroa Gray, M., Pullmann, M., & Lewis, C. C. (2023). Rapid ethnographic assessment: A toolkit for essential partner perspectives on short timelines.↩︎\nSangaramoorthy, T., & Kroeger, K. (2020). Rapid ethnographic assessments: A practical approach and toolkit for collaborative community research.↩︎\nPalazzo, L., Figueroa Gray, M., Pullmann, M., & Lewis, C. C. (2023). Rapid ethnographic assessment: A toolkit for essential partner perspectives on short timelines; Sangaramoorthy, T., & Kroeger, K. (2020). Rapid ethnographic assessments: A practical approach and toolkit for collaborative community research.↩︎\nPalazzo, L., Figueroa Gray, M., Pullmann, M., & Lewis, C. C. (2023). Rapid ethnographic assessment: A toolkit for essential partner perspectives on short timelines.↩︎\nLesmes Guerrero, N., & Rojas, A. (2022). The role of leaders in the regularization process of Venezuelan migrants in Colombia.↩︎\nAkhter, S., Bashar, F., & Kamruzzaman, M. (2022). A rapid ethnographic assessment of cultural and social perceptions and practices about COVID-19 in Bangladesh: What the policymakers and program planners should know. Qualitative Health Research.↩︎\nSangaramoorthy, T., & Kroeger, K. (2020). Rapid ethnographic assessments: A practical approach and toolkit for collaborative community research.↩︎\nVindrola-Padros, C. (2021). Rapid ethnographies: A practical guide. Cambridge University Press.↩︎\nSangaramoorthy, T., & Kroeger, K. (2020). Rapid ethnographic assessments: A practical approach and toolkit for collaborative community research.↩︎\nPalazzo, L., Figueroa Gray, M., Pullmann, M., & Lewis, C. C. (2023). Rapid ethnographic assessment: A toolkit for essential partner perspectives on short timelines.↩︎\nVindrola-Padros, C. (2021). Rapid ethnographies: A practical guide. Cambridge University Press.↩︎\nTrotter, R. T., Needle, R. H., Goosby, E., Bates, C., & Singer, M. (2001). A methodological model for rapid assessment, response, and evaluation: The RARE program in public health. Field Methods, 13(2), 137-159.↩︎\nSmall, M. L., & McCrory, J. (2022). Qualitative literacy: A guide to evaluating ethnography and interview research.↩︎\nVindrola-Padros, C. (2021). Rapid ethnographies: A practical guide. Cambridge University Press.↩︎\nSangaramoorthy, T., & Kroeger, K. (2020). Rapid ethnographic assessments: A practical approach and toolkit for collaborative community research.↩︎\nKozinets, R. (2015). Netnography: Seeking understanding in a networked communication society. https://doi.org/10.1002/9781118767771.wbiedcs067↩︎\nQuestionPro. (2024, July 9). Digital ethnography: What it is, advantages and tools.↩︎\nEstella, A. (2024). Digital ethnography: A methodological monograph; QuestionPro. (2024, July 9). Digital ethnography: What it is, advantages and tools; Mosquera, M. A. (2008). From anthropological ethnography to virtual ethnography: Study of social relations mediated by the Internet. Fermentum: Revista Venezolana de Sociología y Antropología, 18(53), 532-549.↩︎",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Rapid Ethnographic Assessments"
    ]
  },
  {
    "objectID": "data-collection/index.html",
    "href": "data-collection/index.html",
    "title": "Data Collection at IPA",
    "section": "",
    "text": "IPA employs various data collection methods to ensure comprehensive and high-quality research. This section provides guidance on the main data collection approaches and implementation protocols including in-person surveys, phone surveys, WhatsApp data collection, administrative data, and qualitative methods.",
    "crumbs": [
      "Data Collection",
      "About Data Collection"
    ]
  },
  {
    "objectID": "data-collection/index.html#data-collection-methods",
    "href": "data-collection/index.html#data-collection-methods",
    "title": "Data Collection at IPA",
    "section": "Data Collection Methods",
    "text": "Data Collection Methods\n\n\n\n\n\n\nIn-Person Surveys\n\n\n\n\nIn-Person Survey Guidelines\n\nIn-person surveys remain the gold standard for detailed data collection. Through face-to-face interviews, enumerators can build rapport with respondents, observe behavioral cues, and collect complex information that may be difficult to obtain through other methods.\n\n\n\n\n\n\n\n\nPhone Surveys\n\n\n\n\nPhone Survey Guidelines\n\nPhone surveys are a cornerstone of data collection at IPA. Voice and text-based phone surveys offer a cost-effective and adaptive method to gather high-quality data, especially in contexts where in-person surveys are impractical.\n\n\n\n\n\n\n\n\nWhatsApp Data Collection\n\n\n\n\nWhatsApp Surveys Guidelines\n\nWhatsApp has become a powerful tool for data collection, offering a cost-effective, scalable, and user-friendly alternative to traditional survey methods.\n\n\n\n\n\n\n\n\nAdministrative Data\n\n\n\n\nAdmin Data Guidelines\n\nThis resource provides a quick guide on obtaining and using nonpublic administrative data for randomized evaluations.\n\n\n\n\n\n\n\n\nQualitative Methods\n\n\n\n\nQualitative Methods Guidelines\n\nQualitative research methods provide invaluable insights into human experiences, behaviors, and systems that drive change. These approaches help bridge the gap between quantitative data and the realities of individuals and communities participating in research studies.",
    "crumbs": [
      "Data Collection",
      "About Data Collection"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html",
    "href": "data-collection/admin-data.html",
    "title": "Administrative Data",
    "section": "",
    "text": "A guide to obtaining, using, and managing administrative data for research, covering access processes, ethical considerations, and common challenges.",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html#what-is-administrative-data",
    "href": "data-collection/admin-data.html#what-is-administrative-data",
    "title": "Administrative Data",
    "section": "What is Administrative Data?",
    "text": "What is Administrative Data?\nAdministrative data is typically collected by government agencies and organizations for registration, transaction, and record-keeping purposes. Examples of administrative data can include credit card transactions, electronic medical records, insurance claims, educational records, arrest records, and mortality records.\n\nReal-World Example: IPA’s Experience with Administrative Data\nIPA’s research on using administrative data for Monitoring and Evaluation (2016) highlights several key advantages:\n\nCost-Effectiveness: Administrative data reduces or eliminates the need for additional monitoring activities or surveys.\nTimely Response: Regular updates in management information systems enable faster analysis of key indicators.\nLarge Sample Size: Coverage of entire beneficiary populations provides robust sample sizes.\nImproved Accuracy: Reduces social desirability bias and recall issues common in self-reported data.\n\nThis research emphasizes that data accuracy and reliability should take precedence over cost savings. Organizations must balance data quality, actionability, and resource allocation when incorporating administrative data into their research design.\n\n\nUnable to display PDF file. Download instead.",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html#standard-processes-for-accessing-administrative-data",
    "href": "data-collection/admin-data.html#standard-processes-for-accessing-administrative-data",
    "title": "Administrative Data",
    "section": "Standard Processes for Accessing Administrative Data",
    "text": "Standard Processes for Accessing Administrative Data\nAccessing administrative data involves four main steps:\n\n\n\n\n\n\nFinding Administrative Data\n\n\n\n\n\nImplementing partners and government agencies are valuable sources of administrative data. Common sources include:\n\nHealth Data: Regional/national health departments, hospitals, health insurance records\nFinancial Data: Banks, credit unions, credit reporting agencies\nEducation Data: Schools, ministries of education, standardized testing agencies\n\n\n\n\n\n\n\n\n\n\nFormulating a Data Request\n\n\n\n\n\nWhen requesting administrative data, researchers should:\n\nDefine the time frame, format, and structure needed: “Primary school records from January 2022 to December 2023 in CSV format”\nList specific variables of interest: Student ID, school level, Teacher ID, attendance, test scores\nSpecify whether you need identified or de-identified data: Request de-identified data when possible to reduce ethical complexity\nAvoid broad requests: Instead of “all student data,” specify exact variables, time frames needed, and frequency of updates\n\n\n\n\n\n\n\n\n\n\nData Flow Strategies\n\n\n\n\n\nA well-planned data flow strategy ensures smooth integration of administrative data:\n\nGather Identifying Information: Determine what identifiers are available in the study sample such as national ID numbers, phone numbers, email addresses\nLink Datasets: Use pre-existing identifiers to match study data with administrative data. For example, match student IDs with test records using national ID numbers\nChoose a Matching Strategy:\n\nExact matching: When identifiers are identical such as national ID numbers\nProbabilistic matching: When using combinations of name, date of birth, and location information\n\nDetermine Who Performs the Link: Clarify whether the data provider, researcher, or a third party will conduct the linkage and deindentification to maintain data security and privacy",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html#ethical-considerations-for-using-administrative-data-in-rcts",
    "href": "data-collection/admin-data.html#ethical-considerations-for-using-administrative-data-in-rcts",
    "title": "Administrative Data",
    "section": "Ethical Considerations for Using Administrative Data in RCTs",
    "text": "Ethical Considerations for Using Administrative Data in RCTs\nUsing administrative data in research requires adherence to ethical and legal standards. Key considerations include:\n\nInstitutional Review Board (IRB) Approval\nMost research using administrative data qualifies as human subjects research and requires IRB approval. This includes ensuring:\n\nProper handling of personally identifiable information (PII)\nJustification for using identified vs. de-identified data\nSecurity measures for protecting sensitive information\n\n\n\nInformed Consent\nIn some cases, researchers may need to obtain informed consent from participants before accessing administrative data. This depends on:\n\nThe type of data you access\nWhether it is possible to de-identify the data\nLegal requirements set by the data provider\n\n\n\nData Security and Compliance\nResearchers must implement robust security measures, including:\n\nEncryption for storing and transferring sensitive data\nAccess controls to limit data exposure\nCompliance with legal regulations such as the General Data Protection Regulation (GDPR) or Health Insurance Portability and Accountability Act (HIPAA), if applicable\n\nFor further clarification on IRB-related issues, any project with concerns should email humansubjects@poverty-action.org.",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html#challenges-when-using-administrative-data",
    "href": "data-collection/admin-data.html#challenges-when-using-administrative-data",
    "title": "Administrative Data",
    "section": "Challenges When Using Administrative Data",
    "text": "Challenges When Using Administrative Data\nWhile administrative data offers many advantages, researchers often face challenges such as:\n\nDifferential Coverage\nTreatment and control groups may appear differently in administrative records, leading to bias. Examples include:\n\nIdentifiers Obtained After Enrollment: In a financial literacy program evaluation, treatment group participants may be more willing to provide bank account numbers for linking with administrative data, creating selection bias.\nProgram-Generated Data: If the intervention encourages healthcare visits, treatment group participants will appear more frequently in health administrative records, inflating apparent impact.\n\n\n\nReporting Bias\nSome administrative data relies on self-reporting, which can introduce inaccuracies. Examples include:\n\nIncentives for Misreporting: Agencies or individuals may have reasons to over- or under-report data.\nHuman Error in Data Entry: Manual data entry can introduce inconsistencies.\n\n\n\nCost of Administrative Data\nAdministrative datasets vary in cost, depending on:\n\nThe number of records requested\nFile-years needed\nData preparation time required by the provider",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-collection/admin-data.html#conclusion",
    "href": "data-collection/admin-data.html#conclusion",
    "title": "Administrative Data",
    "section": "Conclusion",
    "text": "Conclusion\nAdministrative data is a powerful tool for randomized evaluations, offering cost-effective, accurate, and comprehensive insights. However, researchers must navigate ethical, legal, and logistical challenges to ensure data quality and validity. By following standardized processes, addressing ethical concerns, and mitigating common challenges, researchers can leverage administrative data for impactful research.",
    "crumbs": [
      "Data Collection",
      "Administrative Data"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html",
    "href": "data-cleaning/raw-data-management.html",
    "title": "Raw Data Management",
    "section": "",
    "text": "Raw data generally come in the form of the instrument used to generate the data, be it a survey form or a customer relationship management system. These formats usually result from the form best used to capture the data and not to process it. Format conversion from the source format to one usable by statistical software often requires changing file formats, changing data formats, and general error correction. This section of the cleaning guide covers that process, primarily focused on getting data from SurveyCTO to a preferred structure in Stata.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#survey-data",
    "href": "data-cleaning/raw-data-management.html#survey-data",
    "title": "Raw Data Management",
    "section": "Survey data",
    "text": "Survey data\nMost IPA research projects include survey data. Survey data has the advantage of being received in a consistent format and a known structure. SurveyCTO data, especially, has tools that aid import into Stata. Deciding the data structure during survey programming provides important benefits for raw data management.\nSurvey data’s structure also carries unique challenges for data management: formats of survey data and responses need to be standardized for analysis, metadata needs to be added to surveys, and corrections need to be completed. Finally, since survey data often holds many sources of personally identifying information in the raw format, deidentification is often very important and requires specific focus. Changes in survey version content may exacerbate this process and require multiple imports. This section provides information on these tasks. This section does not provide information on how to program surveys to make data management easy.\nIPA has developed tools to support survey implementation and data quality assurance. IPA’s data management system (DMS) provides Excel- and Stata-based resources to handle data quality checks. The DMS is required for all IPA projects. It provides information on data quality and will resolve duplicates before data cleaning begins, among many other features.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#administrative-data",
    "href": "data-cleaning/raw-data-management.html#administrative-data",
    "title": "Raw Data Management",
    "section": "Administrative data",
    "text": "Administrative data\nOften, administrative data is preprocessed for functional reasons. Working with SQL databases and other data management software provides additional challenges as data fields may change definitions over time and data structure may not be easily amenable to transfer or import into statistical software such as Stata or R.\nThere is no one-size fits all process to manage administrative data, but automating importing and restructuring, as well as checking data quality are common challenges analysts often face before what we commonly think of cleaning begins. This section provides some information on how to handle these tasks in automatable fashions, as well as ways to think about data storage and unique identification. Other management tasks can be found in the data aggregation section.\nThese problems are exacerbated as data increase in size. Big data requires special data management techniques, especially as data size reaches limitations in statistical software capabilities, processing power, and storage format (Excel, for example, can only store about 1 million observations in .xlsx and 65,000 using .xls). This guide does not cover these challenges in detail, but many resources exist for processing big data in Stata (see NBER and Statalist for tips).",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#importing-into-stata",
    "href": "data-cleaning/raw-data-management.html#importing-into-stata",
    "title": "Raw Data Management",
    "section": "Importing into Stata",
    "text": "Importing into Stata\nData comes in many forms, from raw text (.txt) files to multi-sheet Excel (.xls and .xlsx) files. Importing data into Stata is necessary if the data is not already in Stata format (.dta file). In general, you should be able to use Stata’s functions and loops to efficiently import data. Stata can import most data formats. If your project’s data was collected using a platform like SurveyCTO, the raw data will come in .csv format and the SurveyCTO server will provide a do file that imports the raw .csv data into the Stata .dta format.\n\nImporting different file types\nIn Stata 13 and beyond, the import command can import CSV files, excel files, and more depending on the option used (delimited for CSV, excel for excel), and export does the same for exporting. The import excel and import delimited commands provide a number of options that allow for a large amount of control of importing including from where in the workbook data should be imported from and how data should be saved. See help import for details on these options.\nIf you are new to using import are importing a file type you have not seen before, it can be helpful to use the drop-down menu by clicking “File&gt;Import” and then selecting the appropriate file type. Once you do this, you will be able to copy the specific command syntax directly from the command prompt or review window in Stata to your do-file.\nThe insheet command remains an alternative for .csv, .tsv, and .txt files. It performs differently than import delimited and can be useful for some forms of data, but import delimited should be used preferentially. One thing to note is that it is often a good idea when using the insheet command, to use the option names and have your dataset have the same variable names at those at the top of the raw dataset.\n\n\nImporting multiple files at once\nA useful function for importing multiple files within a folder is the dir extended macro function. You can find documentation on this by typing help extended_fcn in Stata. This function allows you to store all the names of the files in a folder in a local so you can loop through them for importing. See example code of this process below.\n/* This stores all files with the extension .xlsx in the\n\"$raw\" data folder into a local \"files\" */\nlocal files: dir \"$raw\" files \"*.xlsx\", respectcase\n\n/* Loop through the files to import, clean the file name,\nand save as a dta */\nforeach file in `files' {\n\n    *Show your progress of which file you are working on\n    di in red \"working on `file'\"\n\n    *Import each file\n    import excel using \"$raw/`file'\", clear firstrow\n\n    **Quality Checks (Optional)\n    *Assert you have the correct number of observations.\n    qui count\n    // If you know the amount of expected observations\n    assert `r(N)' == [number_of_expected_observations]\n\n    /*Check that what variables you think should be unique\n    identifiers are indeed unique. */\n    isid unique_id_var\n\n    *Check for expected/necessary variables\n    confirm var expected_var_names\n\n    * Edit filename\n    /*The filenames in the local \"files\" includes the\n    extension (in this case .xlsx). So, I remove these and\n    make new clean file name to save the files as.\n    You can edit the filenames however you see fit. */\n    local cleanfilename = subinstr(\"`file'\", \".xlsx\",\"\",.)\n\n    *Save the file with the new clean file name as a dta file\n    save \"filepath/dtafiles/`cleanfilename'_raw.dta\", replace\n}\nNote that the new .dta files are no longer saved in the same folder that your raw excel, csv, or any other type of files were saved in. As the imported data are no longer raw, they should be saved in either a temporary or data folder.\nIt can be helpful set up a “dta” or “temp” folder for you to save these intermediate data files before you start. To do so, you can create a folder to save your files in directly in your script by using mkdir \"filepath\". If the directory already exists, this will create an error. One solution is to use the capture command and type cap mkdir \"filepath\" which will suppress the error. We recommend avoiding capture in most situations.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#data-structure-and-reshaping",
    "href": "data-cleaning/raw-data-management.html#data-structure-and-reshaping",
    "title": "Raw Data Management",
    "section": "Data structure and reshaping",
    "text": "Data structure and reshaping\n\nWide and Long Data\nOne way to describe data is if the dataset is stored in a “long” or “wide” format. Long data keeps repeated values as an observation (row):\n\n\n\nHousehold ID\nMember ID\nTreatment\n\n\n\n\nHH001\n01\nT\n\n\nHH001\n02\nC\n\n\n\nWide data describes data that has similar values as variables (columns). The same example could be displayed wide by expanding the Member ID column to be a suffix of the Treatment column, like the following:\n\n\n\nHousehold ID\nTreatment_01\nTreatment_02\n\n\n\n\nHH001\nT\nC\n\n\n\nThere is no correct choice for how data should be stored. You should decided the format to make the data most usable for the analysis being conducted. As a rule of thumb, in a clean dataset each observation is a row, each variable is a column, and each type of observation is a separate dataset (Wickham, 2014). However, the unit of analysis may change for different analyses. An analysis could be conducted at the person-year-level in one analysis, but at the person-level in another. The context of the data being analyzed are required to determine what format the data should be stored in. As long as an ID variable exists for each level of the data (e.g. a long dataset may have a household ID and a household member ID). For more guidance on how Stata treats “wide” and “long” datasets as well as how to change between them (reshape the data) type help reshape in Stata.\nWhen cleaning data, it’s generally a good idea to decide how the data will be stored based on how it will be cleaned. For example, if one goal of cleaning is to produce an income variable at the household-level, but income is collected at the respondent-day-level, it may be a good idea to clean the income module separately and keep that dataset long. Then, the income data can be collapsed to the household-level and merged onto the household-level dataset later in the variable construction process. How, or if, that happens is up to you as the analyst.\nThere is one point at which the data has a known unit of analysis: during high frequency checks and backchecks. Data is always at the unit of the survey submission when doing quality control. One observation is one survey submission. For multi-day surveys, a survey submission may be a different level of data than the survey.\n\n\nSurveyCTO Data\nWhen downloading from SurveyCTO, you can choose whether to export the data in wide or long format. SurveyCTO also produces a file dataset that links long formatted datasets on their unique IDs if the data is exported long.\nKeeping the data in long format means that SurveyCTO will automatically organize observations at the largest unit level (e.g. household-level) and will save all sub-unit level data into separate datasets for each repeat group (e.g. person-level, plot-level, etc.). This means you will have a larger number of datasets to work with (and perhaps a more involved merging process if you want to compile all the data), but each dataset will be at the unit of the question, so may be more intuitive to work with.\nWide data saves you the process of merging manually. If any repeat groups exist, sub-unit level data will automatically be reshaped in order to fit with the main dataset. For example, names of individual household members collected by the variable name will be reshaped as name_1 (for the first member), name_2 (for the second member), etc. It is easier to run quality checks on wide data, as these data will contain all data collected by the survey. However, these datasets can also grow very large very quickly and become unwieldy to work with. To load wide data into Stata it may be necessary to increase the number of variables Stata can read in a single dataset (up to 32,767 for Stata-SE) by typing set maxvar 32767\n\n\nAlternative to reshape\nTo convert between wide and long data, Stata uses the reshape command. Reshaping is a very computationally intensive command. If you are dealing with a large data set you will quickly find that using reshape can take an excessively long time or even break the current Stata session. There is an alternative way to manually code a reshape using expand and replace, that has the benefits of running much faster. It also provides an understanding of how a reshape transforms your data structure. In addition, variable labels can be modified with more control if done manually.\nThe following code reshapes a wide dataset by person to a long dataset by person-month. The variable that we want to reshape is income.\n/*sCount all of the income variables and create\na variable for each observations*/\nds income*\nlocal copies : word count `r(varlist)'\nexpand `copies'\n\n/*Then create a list of all of the vars with each stub\n and manually expand*/\ngen yearmonth = . // create an empty var that will hold the sub-group identifier (this is the j var in reshape)\nforeach var in income {\n\n    *Save all of the income variables\n    ds `var'_*,\n    local reshapevarlist `r(varlist)'\n\n    /*remove the stub so that we can have the yearmonth\n    or j identifier foreach var alone while maintaining their order*/\n    local monthyear = subinstr(\"`reshapevarlist'\", \"`var'_\", \"\", .)\n\n    *create an empty version of the stub, this will become the long var\n    gen `var' = .\n\n    *Loop through each value\n    forvalues x = 1/`copies' {\n\n        * Replace the variable from the list we defined earlier in the loop\n        /* See \"h mod\" to understand how mod works,\n        but in short \"if mod(n, `copies') == `x'\"\"\n        will only replace the variable for the nth observation\n        in each group defined by\n        an ID variable (e.g. the nth or last row created in the expand)\n        */\n        local currvar : word `x' of `reshapevarlist'\n        replace `var' = `currvar' if mod(_n, `copies') == `x'\n\n        * Generate the identifier variable\n        local yearmonth : word `x' of `monthyear'\n        replace yearmonth = `yearmonth' if mod(_n, `copies') == `x'\n\n        *Drop the wide variable\n        drop `currvar'\n    }\n    // end forval x= 1/`copies'\n}\n// end foreach var in income",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#adding-or-replacing-data",
    "href": "data-cleaning/raw-data-management.html#adding-or-replacing-data",
    "title": "Raw Data Management",
    "section": "Adding or replacing data",
    "text": "Adding or replacing data\nRaw data may not contain the full or correct set of data. There are many reasons why this may be the case: survey responses may need to be corrected by enumerators, translations for responses need to be added, admin data may have entry errors, etc. It is relatively simple to make changes in data using statistical software, but it is important to make changes in a systematic way to ensure all modifications are reproducible.\nThere are at least two common situations in IPA projects where having a standardized data flow for modifying or adding data will increase data quality: replacements and translations. This article suggests best practices to add data collected outside of a survey form.\n\nReplacements\nAs you are collecting data, there will inevitably be errors in your data that need to be manually corrected. It is important to always maintain the raw dataset with the original collected data. Once you have confirmed that a value in your dataset is incorrect and needs to be changed, this replacement should be made and saved in a new dataset, before you have done any other necessary cleaning.\nWhen making a replacement, confirm that you are using a truly unique value for your observation. For example, the key variable should be used if you are making replacements in SurveyCTO data, since there can be duplicates in your ID variable, or you may need to make a replacement in the ID variable.\nFor every replacement you make to your dataset, you must record: * Who made the original error * Who confirmed it was an error * The original value * The new value * The reason for the change\nOne way to make replacements is using the replace command if the key variable matches the observation.\n*enum confirmed they added an extra zero to income\nreplace income = 1000 if key == \"uuid:2b2763e1-71b6-4e1e-8023-c15cdf7fa39d\"\nIf you are making multiple replacements, this method can create long datasets and make it difficult to keep track of which replacements have been made. It can also lead to PII appearing in your do files if you are making replacements on PII data or sensitive data. To avoid encrypting your datasets, consider using user-written commands readreplace or ipacheckreadreplace (ipacheckreadreplace is a wrapper for readreplace). Both commands use an Excel file as an input sheet, where all replacements, notes, original values, and replacements are logged. ipacheckreadreplace has a template replacements Excel file that you can download when you run the ipacheck command.\nIf you are using IPA’s Data Management System, this code snippet is included in the master_check do file. You can also use the ipacheckreadreplace command in your own code with this format:\nipacheckreadreplace using \"hfc_replacements.xlsm\", ///\n    id(\"key\") ///\n    variable(\"variable\") ///\n    value(\"value\") ///\n    newvalue(\"newvalue\") ///\n    action(\"action\") ///\n    comments(\"comments\") ///\n    sheet(\"sheetname\") ///\n    logusing(\"replacements_log.xlsx\")\nThe Excel template already uses these column names, so you must change the options/column names if you are using your own file or column names. ipacheckreadreplace also creates a replacements log, another Excel file that lists all the replacements, notes, and values, as well as a note that specifies if the replacement was successful. A replacement will only be successful in ipacheckreadreplace if the unique ID variable and the original value match what was entered in hfc_replacements.xlsx.\n\n\nTranslation\nSometimes open survey responses need to be translated for deliverables or to support an analyst who isn’t fluent in the survey language. Translating these data within statistical software can result in long scripts with large potential for error rates and a potential to contain PII. This can be avoided by using an excel-based workflow with encrypted translation file: - For each variable that needs to be translated, save the values that need translation to an excel sheet with an empty column (variable in the Stata .dta) for the language the responses need to be translated into. - Translate the responses using a standardized procedure, e.g. double-entry with another person breaking ties and rules on when to drop comments with PII. - Write code to merge the translation from the excel file back into the do file, instead of running this as a series of replace commands that are prone to error.\nThis workflow is shown below:\n/* MR 10/25/2019:\n  Create a file to store translations for question q.\n*/\n\n*Generate translated variable name\ngen q_en = \"\"\nlocal vlab : variable label q // extract variable label to copy\nlabel variable q_en \"`vlab', English\" // label with translation info\n\n*Save excel file for coding with only those questions that need translating\nexport excel id q q_en using \"${temp}/q_en.xlsx\" if !mi(q), firstrow(variables) replace\nThis results in a table that looks like this:\n\n\n\nid\nq\nq_en\n\n\n\n\n01-0001\nLe dio sus herramientas agrícolas a su primo\n\n\n\n18-0007\nEl ID de esta respuesta debe set 18-0008, no 18-0007\n\n\n\n\nThe responses would be translated and then the file is then saved with a different name. We recommend saving the file as “[filename]_translated_[date]_[initials]”. We recommend doing double entry for all manual additions and comparing differences between any added responses. The completed file would have a value for every question below.\n\n\n\n\n\n\n\n\nid\nq\nq_en\n\n\n\n\n01-0001\nLe dio sus herramientas agrícolas a su primo.\nThis respondent gave their farming tools to their cousin\n\n\n18-0007\nEl ID de esta respuesta debe set 18-0008, no 18-0007\nThe ID of this response should be 18-0008, not 18-0007\n\n\n\nOnce these translations are completed, they would be merged on to the do file. The code to complete that looks like this:\n/* MR 01/24/20:\n    Merge on the translated data from the saved excel file.\n\n    MR translated these data on January 24, 2020 and double entered them.\n    MR's RM double checked conflicting translated entries.\n\n    If PII was removed as part of the translation process, this will be\n    marked with a dummy* and corrected in the response of both languages.\n\n    *Note: no responses needed PII removal, so this code does not\n    create the dummy.\n*/\n*Load in data and save a tempfile\npreserve\n\nimport excel using \"${temp}/q_en_20200124_MR.xlsx\", first clear\n\n*Do some cleaning to ensure excel files matches expected\nmissing dropvars, force // remove extravars\nmissing dropobs, force // remove empty observations\nconfirm variable id q q_en // check have variables\n\n*Save tempfile to merge\ntempfile q_en\nsave `q_en'\n\nrestore\n\n*Merge on file\nmmerge id using `q_en', t(1:1) uname(check_)\n\n*Check file\nassert _merge == 1 | _merge == 3 // in master only or translated\nassert q == check_q if _merge == 3 // ensure no changes to comment field\nassert _merge == 3 if !mi(q) // ensure all are translated\n\n*Manually replace translation after checks\nreplace q_en = check_q_en\n\n*Housecleaning\ndrop _merge check_q check_q_en\nThis process can be repeated for any number of variables. It can also be extended to remove PII as part of the translation process. In that case, make sure to maintain a raw version of the dataset that is encrypted, and mark which values were changed to remove PII in the translated dataset.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#surveycto-split",
    "href": "data-cleaning/raw-data-management.html#surveycto-split",
    "title": "Raw Data Management",
    "section": "SurveyCTO split",
    "text": "SurveyCTO split\nSome surveys questions have the option of “check all that apply”, meaning that they allow for multiple responses. If you uncheck the “export select_multiple responses as a series of 1/0 columns” in SurveyCTO desktop, SurveyCTO will export these variables as a string containing all possible answers in the form of a space-separated list (e.g., a variable may have the string “A C E” to indicate responses of A, C, and E).\nFor analysis purposes, it’s usually best to split these variables into binary variables, one for each possible choice (A, B, C, D, or E), as well as one for each combination of choices. The IPA-written stringdum function can help converting these variables to a more useful form, including separate dummies for each option, variables that count the number of times each option is selected, and several options for naming conventions. The split command can also convert these variables, by parsing the variable on spaces. This splits the variable into a new variable after each space (see help split). If this is not sufficient, Stata has a number of string functions (help string functions). You can also use the regexm function to accomplish this, which uses regular expressions. Below is an example script using both split and regexm to accomplish cleaning a select multiple question manually.\n* Create a local of all string variables\nqui ds _all, has(type string)\nforeach var in `r(varlist)' {\n    local stringvars `stringvars' `var'\n}\n\n\n/* Exclude from stringvars vars with names that will be too long if we append\n  four characters (“_num”) to them first check using tab that they are not\n  select_mult. If the length of the variable name is greater than 27 characters,\n    1. manually verify that it is not a select_mult variable\n    2. add it to a special local\n*/\nforeach var of varlist _all {\n    if strlen(\"`var'\")&gt;27 {\n        tab `var'\n        local too_long_vars `too_long_vars' `var'\n    }\n}\n\n* Remove the too_long_vars from the string variable list\nlocal stringvars: list stringvars - too_long_vars\n\n/* For each string variable,\n   1.  create a tempvar,\n   2.  an indicator for which have a number-space-number combo and\n   3. add them to a select multiple local\n*/\nforeach var in `stringvars' {\n    tempvar `var'_num\n    gen ``var'_num' = (regexm(`var', \"[0-9] [0-9]\"))\n    qui sum ``var'_num'\n    if r(max) ==1 {\n        *add the variable to a list of select_multiple variables\n        local select_mult `select_mult' `var'\n    }\n}\n\n/* Exclude from the `select_mult' local variables which have been\nerroneously captured by the process above irregular responses to\nthe \"survey_note\" variable are captured by this process */\nlocal exclude_notes \"survey_notes\"\nlocal select_mult: list select_mult - exclude_notes\n\n/*For several otherwise numeric variables,\nthe option \"Not asked in this version\" remains; remove it*/\nforeach var in `select_mult' {\n\n     *no observations; safe to use this as a numeric indicator for .v\n    tab `var' if `var'==\"-444\"\n    replace `var'=\"-444\" if `var'==\"Not asked in this version\"\n\n    /* split and de-string vars in the selec_mult list,\n    which now have only numeric characters */\n    split `var', gen(`var'_) destring\n}\n\n*Re-code missing values in the now-numeric variables\nqui ds _all, has(type numeric)\nforeach var in `r(varlist)' {\n    replace `var'=.o if `var'==-777\n    replace `var'=.d if `var'==-888\n    replace `var'=.r if `var'==-999\n    replace `var'=.v if `var'==-444\n}",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#unique-identifiers",
    "href": "data-cleaning/raw-data-management.html#unique-identifiers",
    "title": "Raw Data Management",
    "section": "Unique identifiers",
    "text": "Unique identifiers\nUnique IDs are critical to a well-managed dataset, particularly when it comes time to merge across datasets or sort values in a consistent manner. You should use the isid command in Stata to check that the ID is indeed unique before you begin any sort of data management. Uniqueness is important not just to describe data, but because it affects how Stata manages data. Data will take a random order within a non-unique value if data are sorted on a shared identifier. This randomness is controlled by a separate random seed in Stata and can be made reproducible using set sortseed or sort, stable. Those approaches do not substitute for not having a unique ID; reproducibility is not a substitute for uniqueness.\nTo illustrate this, you can run the following code in Stata:\n*Use system dataset\nset sortseed 1\nsysuse auto, clear\n\n*sort by foreign and save order\nsort foreign\ngen sort_order = _n\n\n*sort randomly so Stata will sort by foreign again\n/*  sort first checks if it's in order, and doesn't do anything if\n    the data are in the expected order\n*/\ngen rand = runiform()\nsort rand\ndrop rand\n\n*Check if foreign has a unique order\nsort foreign\nassert _n == sort_order // check if the current order == saved order\n\n73 contradictions in 74 observations\nassertion is false\nr(9);\n\nDuplicates\nID variable should describe data at the unit of analysis. The unit of analysis is dependent on what the dataset is describing. For example, a survey module that describes yield by plot should not be unique at the household-level, but should be at the household-plot-level. That is equivalent to saying that isid householdid plotid should not return an error in Stata. If you receive an error, use the duplicates command to investigate as to why you have duplicate observations (help duplicates). Although duplicate surveys should be resolved in IPA’s data management system, duplicate observations may remain in the raw data for a variety of reasons.\nIf they are true duplicates across all variables and it is clear why these duplicates were created, you can proceed to remove duplicate copies. If they are not duplicates across all variables, you will need to find why there are multiple observations and develop a rule for choosing which one to keep. Selected values should be reproducible and follow a consistent rule. In general, observations that are more recent and more informative (i.e., have fewer missing values) are better. However, for some projects, it is better to keep the earlier observation. You should check with your PI, the project manager and other staff involved in the survey wave about how to create a rules or rules. Once you come up with a decision, be sure to document both what you decide to do and why it was decided, as well as when and who made the decision for future reference.\nDuplicates may not just exist for an ID variable. Some respondents may take a survey twice and receive two different IDs. See help duplicates for guidance on commands that can be useful for this. Apart from dropping duplicates in terms of all variables using duplicates drop, check for duplicates in terms of things you suspect may identify the same person (e.g., name, address, phone number, birthday and combinations of the above) using either duplicates or isid.\nOnce you’ve cleaned each dataset individually, it is wise to check that the unique IDs are assigned properly across datasets. For instance, if you have a baseline survey and an endline survey, after merging them based on unique ID, check that the names and birthdate variables from each survey match to the other survey.\n\n\nID formats\nIDs may not be unique due to how Stata manages numerical formats. If the ID variable is longer than 17 digits, numeric IDs will no longer be unique as Stata will begin to round the trailing digits. This is due to how Stata stores when they have more digits than their storage type can hold (16 for doubles). No numeric IDs will be unique if they have more than 17 digits, especially if the last digits are changing for individuals that should be unique. It’s best to store IDs as strings and include a letter to ensure that the ID will not be turned into a numeric variable and subsequently rounded by compress or destring. Alternatively, keep ID values at the minimum length needed, as it generally not necessary to have an ID value over 17 digits.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/raw-data-management.html#de-identifying-data",
    "href": "data-cleaning/raw-data-management.html#de-identifying-data",
    "title": "Raw Data Management",
    "section": "De-identifying data",
    "text": "De-identifying data\nPersonally Identifiable Information (or PII) is any data point or combination of data points that allows someone to identify an individual or household with a reasonable degree of certainty.\nExamples of individual data points of PII include names, GPS coordinates, national identification numbers and addresses. Depending on the context, certain combinations of demographic data points qualify as PII so long as they can identify an individual or household with a reasonable degree of certainty. For example, the combination of village name, birth date, gender might be identifiable in small communities. Requirements and recommendations around PII apply equally to PII that consist of singular data points and those that consist of combinations of data points.\nAll PII must remain encrypted in storage and securely transmitted between devices. The only people who can access PII data must be both on the IRB-approved research protocol and referenced in the informed consent. For more information, see IPA’s protocols surrounding PII\n\nWhen to remove PII\nOnce you have data, it’s best practise to remove PII as soon as possible. The earlier you can de-identify — i.e., remove all identifying information from the datasets you’re using – the better. Unless it’s necessary, you should not be working with data containing PII as you move forward with analysis.\nSome aspects of cleaning and analysis will require including PII. For instance, if you are trying to remove duplicate observations and need to determine if two respondents have the same name, you’ll want that in there. As always, you will need to keep the data encrypted with Boxcryptor at that point. Make sure do-files/scripts are encrypted as well if they include PII.\nOnce you’ve reached the point of no longer needing PII, you should strip it from the main dataset. The best practice for de-identifying data is to:\n\nCreate a first .do file that imports the data, standardizes duplicate observations, completes corrections, and removes PII.\nCreate a second .do file that performs the data cleaning on the limited or fully deidentified dataset. If need be, you can save this version in an unencrypted folder so that other project members who can access the data.\n\nThis results in a data flow where all data modification happens after the data are deidentified.",
    "crumbs": [
      "Data Cleaning",
      "Raw Data Management"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#features-of-well-documented-datasets",
    "href": "data-cleaning/dataset-documentation.html#features-of-well-documented-datasets",
    "title": "Dataset Documentation",
    "section": "Features of well-documented datasets",
    "text": "Features of well-documented datasets\nDocumented datasets in Stata should have the following characteristics: - Variable names should be patterned for both interpretability and ease in programming tasks. - All variables should be labeled with descriptive labels. - All values of categorical variables should be labeled and checked for consistency when labels are assigned. - All datasets should only contain variables needed as part of the dataflow. - Datasets should have internal notes describing additional information that’s necessary to use the data and/or additional information such as the name of the item in the questionnaire.\nThis documentation should be written in addition to project manuals, codebooks, and readmes that describe other aspects of the data generating process, including why decisions were made to create variables, how datasets relate and change through the dataflow, and how variables used in the analysis are defined. If the documentation",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#variable-names",
    "href": "data-cleaning/dataset-documentation.html#variable-names",
    "title": "Dataset Documentation",
    "section": "Variable names",
    "text": "Variable names\nVariable names are generally inherited from the prior method of data storage. These names will not necessarily be optimize for use in coding in statistical software due to length, formatting, or clarity. Standardizing these names to usable and interpratable formats is one of the first steps to ensure datasets are easy and intuitive to use.\nIf you are using SurveyCTO data, variable names and labels should be automatically generated for you upon import (as long as you use the SurveyCTO import template) . If you are using other data or not using this template then you will need to rename your variables.\n\nNaming Standards\nVariable names should correspond to both interpretability by a user, as well as the utilities Statistical software allows. For example, in Stata a number of commands allow using wildcard commands such as * and ? to stand-in for patterns in the data. This allows for data modification to be done systematically. If all of the income variables start with the inc_ prefix, then it’s easy to modify every variable at once:\n*Call all income variables\nds inc_*\nWe recommend balancing the following considerations while naming variables: - Group variable names that describe outcome categories (e.g. all variables that count yield could be prefixed with y_). - Group types of variables like comment fields with a unique substring such as _note. - Create names that have a substantive meaning and are also easy to type (e.g. inc_bus_ & inc_ag instead of section1b_ & section2a_) - For indicator variables, do not name the variable the category. Instead, name the variable what the value “1” indicates (e.g. if a variable takes 1 when a respondent is female and 0 when a respondent is male, name the variable female not gender) - Create unique and consistent naming patterns across all datasets used in the project - Two datasets that have different units of analysis should not be identified by the uninformative variable name id - Two datasets that describe income at various levels should use the same prefix to describe the same construct (e.g. plot-level income could be inc_ag_plot1 and baseline household income could be inc_ag*_bl)\nIn wide data, it’s also important to consider how statistical software performs. Often times patterning variable names is necessary for tasks like reshaping to work smoothly. In wide-data stored in Stata, reshape uses a stub in the variable name to identify the value the long dataset would take for each group. Ensuring that variables are named consistently (e.g. baseline variables are suffixed by _1, midline by _2, and endline by _3) can make it easier to reshape datasets.\n\n\nRenaming in Stata\nStata’s rename command is used to change variable names. While it is possible to rename multiple variables with these commands, it can often be easier to rename many variables from an external file such as an .xls. However, rename allows for some operators to rename multiple variables that share patterns. These commands can be very powerful and can sometimes capture variables that you do not intend to rename. See h rename group for a full description of renaming commands. Some options that are relevant for survey data follow:\n\n\n\n\n\n\n\n\nExtended command\nFunction\nExample\n\n\n\n\n*\nAny number of characters\nren year_* * removes the prefix year_ from all variable names that start with year_\n\n\n?\nExactly one character\nren monday_? day_?_1 would change monday_a to day_a_1\n\n\n#\nOne or more digit (numeric only)\nren age# age(##) renames all numeric variables to use a minimum of two digits for number suffixes (e.g. age_1 becomes age_01)\n\n\n, renumber\nReorders names to increase by 1\nren survey_# survey_#, renumber reorders all variables prefixed with survey_ that end with a number so that they increase by 1\n\n\n\nAlso see renvars (net search renvars to install) a user written command that can help with complicated renaming tasks.\n\n\nRenaming from External Files\nIf you are renaming/labeling a lot of variables it can be cleaner to put them in an excel file and import from there, rather than writing it all in your do file. For an example of how to efficiently rename variables from a .xlsx file, see the following:\n**A. Import codebook file\n/*\nThis file contains the master name and labels, as well as the\nsurvey-wise name and labels\n*/\nimport excel \"${raw}/variable_codebook.xlsx\", firstrow clear\n\n\n** B. Make locals with common names and corresponding survey names\nsort common_varname // sort in unique order\n\n*Init project specific locals empty\nloc survey_names    // project-specific variable names\nloc common_names    // corresponding common variable names\n\n* Loop through all value of the excel file\nforvalues i = 1/`=_N' {\n\n    *Save name and labels in order from the excel sheet\n    loc survey_name = varname in `i'\n    loc common_name = common_varname in `i'\n    loc common_varl = common_varlab in `i'\n\n    *Fill locals to add information to project\n    loc proj_names `proj_names' `proj_name'\n    loc common_names `common_names' `common_name'\n    loc common_label \"`common_label' `\"`common_varl'\"'\"\n}\n// end forvalue i == 1/`N'\n\n\n**C. Run some checks\n*Check renaming lists are same length\nassert \"`:word count `proj_names''\" == \"`:word count `common_names''\"\n\n*Save list of locals for logc\nmacro list\n\n\n**D. IMPORT THE DATASETS IN A LOOP AND RENAME\n*Clean locals\nloc common_name // init empty\nloc common_varl // init empty\n\n*Load raw data\nuse \"``project'_directory'/`project'`input_dataset_suffix'.dta\", clear\n\n*Loop through variable names to remain\nforvalues i = 1(1)`: word count `proj_names'' {\n\n    *Collect names from list to rename variables\n    loc proj_name `:word `i' of `proj_names''\n    loc common_name `:word `i' of `common_names''\n    loc common_varl `:word `i' of `common_label''\n\n    *Rename and label from common names\n    rename `proj_name' `common_name'\n    lab var `common_name' \"`common_varl'\"\n}\n// end forvalues i = 1/`: word '",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#variable-labels",
    "href": "data-cleaning/dataset-documentation.html#variable-labels",
    "title": "Dataset Documentation",
    "section": "Variable labels",
    "text": "Variable labels\nStata variables have both names and labels. Variable names are the name that Stata uses to define a column. Variables labels are added information that can easily be displayed to the analyst. Names should follow patterns that make it easy to program (e.g. all consumption questions could be coded as cons_1 - cons_20 and could easily be called by ds cons_? cons_??) Variable labels are best used as descriptors: they should say exactly what the variable is about. You can pull the exact question text from the survey, or use a paraphrased version if the text itself is quite lengthy.\n\nSystematizing labels\nVariable labels provide information about variable names which are often defined for programmatic reasons. 1. All variables should have labels, and all multiple choice variables have value labels. 1. The labeling system should be internally consistent. 1. It should be easy to connect the variable in the dataset with the question on the questionnaire. Most analysis is done with the questionnaire in hand.\nOne format to define variable labels for survey data is to including both the question number in the questionnaire as well as a description of the contents in the variable. The basic format for that system is:\n&lt;div class=\"code-example\" markdown=\"1\"&gt;\nVariable name: descriptive name that uses prefixes or suffixes to provide patterns\nVariable label: [question_number] descriptive label\n&lt;/div&gt;\nThis style is implemented below:\n*Define variable labels variables\nlabel var child_15      \"[QA.101] Has children under 15\"\nlabel var child_15B     \"[QA.102a] Number boys under 15\"\nlabel var child_15B_S       \"[QA.102b] Number boys in school\"\nlabel var child_15G     \"[QA.103a] Number girls under 15\"\nlabel var child_15G_S       \"[QA.103b] Number girls in school\"\nNote that this code aligns the variable names and the variable labels in the text. This makes it easy to read the labeling as a programmer.\n\n\nLabels from SurveyCTO\nSurveyCTO automatically labels the variables using the questions from the survey instrument. However, labels are allowed a maximum of only 80 characters in Stata, which means that in many cases the labels imported from SurveyCTO will be truncated. For tips on how to attach information that is longer than 80 characters see the variable notes guide.\n\n\nStata Storage of Variable Labels\nStata can use value label data using the extended macro functions (see h extended_fcn). The following code call a variable label and assign it to a local.\n*Call variable label of variable \"var\"\nlocal vlab : variable label var\nThis information can be searched conditionally. If, for example, you wanted to only apply a function to variables in the “QA” section of the survey defined in “Systematizing Labels” section in this article, you could check to see if the label starts with “[QA.”:\n\nforeach var of varlist _all {\n    if regexm(\"`: variable label var'\", \"^\\[QA\") {\n        [do something]\n    }\n    // end if regexm(\"`: variable label var'\", \"^\\[QA\\.\") {\n}\n// end foreach var in `r(varlist)",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#variable-metadata",
    "href": "data-cleaning/dataset-documentation.html#variable-metadata",
    "title": "Dataset Documentation",
    "section": "Variable metadata",
    "text": "Variable metadata\nSometimes you will want to attach information or other labeling that is longer than Stata allows (labels are capped at 80 characters). If this is the case, you can store the full desired label into the variable notes or characteristics. Both notes and characteristics can describe variables or the dta file.\n\nNotes\nOne variable can have multiple notes. Notes can be added into variables by typing note VARIABLE : “Note” (i.e. for variable VARIABLE the note note was added as. To display the notes stored in one variable just type “notes VARIABLE”. Notes are also stored in Stata as locals and can be called using `VARIABLE[note1]'. These notes are numbered based on the order in which they are received. Note’s ordering can be modified and deleted by the note command (see help notes in Stata).\nSurvey CTO includes the full text of the question from the survey instrument as variable notes (as well as the truncated questions as variable labels) as part of the import do file. These notes will always be in the downloaded language. They will not contain filled values for the respondent that are produced as the result of calculate fields.\nIf variable labels have been changed or converted as part of a data transformation, notes can be converted into labels by looping through variables and using the stored local for notes:\n*Loop through each variable in the varlist VARIABLES\nforeach var of varlist VARIABLES {\n    label var `var' ``var'[note1]'\n}\n\n\nThe char command\nAdditional information can be added using characteristics, which function similarly to notes. The Stata manual describes characteristics as “an arcane feature of Stata [that] are great use to Stata programmers.” Many commands use and define specific named characteristics to attach metadata. Characteristics (type help char in Stata) can describe variables and the dataset itself.\nThe main difference between characteristics and notes is that the char command requires a name for each characteristic. Whereas note VARIABLE : \"Note\" creates the next sequential note (1 if the first note, 2 if the second, etc.), char explicitly requires a character name, “charname” in the following code: char define VARIABLE[charname] \"Note\". This can be useful for saving labels in multiple languages. These characteristics can then be called by name, instead of an arbitrarily assigned number.\nFor example, a data flow could take labels in each language from a SurveyCTO form and assign them as characteristics to each variable produced by the survey in the following:\n*Import SurveyCTO\nimport excel using \"Baseline Household Survey.xlsx\", first clear\n\n*Keep variables with labels\nkeep type name label labelbangla relevance\nren label labelenglish\nren label* * // rename to remove \"label_\" prefix from all variables\n\n*Remove variables not exported to Stata\ndrop if inlist(type, \"begin group\",  ///\n  \"end group\", \"image\", \"begin repeat\", \"end repeat\")\ndrop type\n\n*Only keep variables with non_missing\nds name, not // get list of label variables\nloc languages `r(varlist)' relevance\negen has_lab = rownonmiss(`languages'), strok\n// keep only rows with has_lab\nkeep if has_lab &gt;= 1 & !mi(has_lab)\n\n*Save variables and language names\nloc varnames // init empty\nforval i = 1(1)`=_N' {\n  loc name = name[`i'] // save name of variable\n\n  *Save labels as locals\n  loc j = 1 // init counter at start\n  foreach language of local languages {\n     loc `name'_`j' = `language'[`i']\n     loc ++j\n  }\n  // end foreach language of local languages\n\n  *save local of names to add question text to\n  loc varnames `varnames' `name'\n}\n// end forval i = 1(1)_N\n\n*Load data\nuse survey.dta, clear\n\n*Loop through names to add characteristics\nforeach name of local varnames {\n  ds `name'* // collect names that are inclusive of repeat groups\n  loc varl `r(varlist)'\n\n  foreach var of local varl {\n\n  *Confirm only the variable or the repeat group\n  cap assert \"`var'\" == \"`name'\" | regexm(\"`var'\",\"^`name'[0-9][0-9]?$\")\n  if _rc continue // skip if \"`name'\" is a prefix\n\n     *add characteristic as a named language\n     loc j = 1\n     foreach language of local languages {\n        char define `var'[`language'] \"``name'_`j''\"\n        loc ++j\n     }\n     // end foreach language of local languages\n\n  }\n  // end foreach var of local varl\n\n}\n// end foreach name of local names",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#value-labels",
    "href": "data-cleaning/dataset-documentation.html#value-labels",
    "title": "Dataset Documentation",
    "section": "Value labels",
    "text": "Value labels\nFor categorical variables the raw data will often show the string values for the selected response. For instance, you may see “male” and “female” displayed as possible responses to the variable gender. When doing calculations, however, you’ll need these variables to be numeric (in the float or long format) – if they are not already imported this way. It is helpful to preserve the extra information the strings capture by using “value labels.” A value label such as gender would assign “female” to 0 and “male” to 1 and display female and male to the analyst. See help label for how to do this in Stata. It is very important to label values for two reasons: - it provides information to the analyst that will reduce mistakes made in coding or analyzing data - many programs will use information on whether a variable has value labels in order to identify it as a categorical variable, as opposed to a continuous numeric variable.\n\nEncoding String Values in Stata\nThe quickest way to change string variables to numeric variables with value labels is the encode command. encode will automatically convert the string variable into a numeric variable and assign the numbers 1 – x (where x is the number of unique answer choices) to the alphabetized list of the answer choices (ordered 0-9, followed by a-z). Because this is done automatically based on alphabetical order, if you are trying to make value labels match some existing assignment, you may need to recode or label them manually.\nStata stores value labels independently from the variables, so it’s important to manage value labels separately from variables as they can contain PII. Deleting all variables that have a value label and saving the dataset will ensure that the value label is removed from the .dta file. To see which labels are currently defined in Stata and their content you can use the label list command (helpful summary information is stored in the return values of label list and label dir as well). These labels can be modified or deleted to combine using the options of label define function:\n*Drop old labels\nlabel drop ex1 ex2 ex3\n\n*Define label\nlabel define yesno 1 \"No\" 3 \"Yes\"\nlabel list yesno\n\n*Modify label to correct the error\nlabel define yesno 1 \"No\" 2 \"Yes\", modify\n\n*Add extended values to the label defined above\nlabel define yesno .n \"No response\" 3 \"Maybe\", add\n\n*Apply the label to all of the variables it should apply to\nloc dummy_vars ex1 ex2 ex3\nlabel values `dummy_vars' yesno\n\n\nFormatting Labeling in Stata\nIt can be useful to change the delimiter to a semicolon so that a single command can take up several rows in your text editor, making it easier to read labeling. This is especially useful when multiple values are labeled. See help delimit to learn about delimiters in Stata. An example would be:\n* Set delimiter for labeling\n#delimit ;\n\nlabel def female\n    0 \"[0] Male\"\n    1 \"[1] Female\"\n;\n\nlabel def region\n    1 \"[1] Northern\"\n    2 \"[2] Southern\"\n    3 \"[3] Western\"\n    4 \"[4] Eastern\"\n    5 \"[5] Central\"\n;\n\n#delimit cr\n\nlabel values female female\nlabel values region region\nNote how the labels have the corresponding value as well as the description in the value label. This is not strictly necessary, but can be useful if you want to values to display alongside labels in outputs.\n\n\nDefensive Workflow for Encoding Values\nOne way to ensure that data is encoded in an expected way is to check that values are only encoded from a list of value labels that you defined. The user written command sencode (installed using ssc install sencode) can help to support this. sencode labels the variable according to the values that you’ve predefined and then adds additional values in order from the highest value if it encounters values that you haven’t defined. An example data flow follows:\n*Ensure sencode is installed\ncap which sencode\nif _rc ssc install sencode\n\n*Load data\n    sysuse auto, clear\nkeep if _n &lt;= 10 // Keep the first ten observations of the sample\n\n# del ;\n\n/*\nThis label is named by the variable name, an \"_\", and then \"label\"\nso that we can loop over the labels.\n*/\nlabel define make_label\n    1   \"AMC Concord\"\n    2   \"AMC Pacer\"\n    3   \"AMC Spirit\"\n    4   \"Buick Century\"\n    5   \"Buick Electra\"\n    6   \"Buick LeSabre\"\n    7   \"Buick Opel\"\n    8   \"Buick Regal\"\n    9   \"Buick Riviera\"\n    10  \"Buick Skylark\"\n;\n\n# del cr\n\n*Create a local list of variables to encode\nloc str_var make\n\n*Encode values and confirm expected\nforeach var of local str_var {\n\n    *Encode variables\n    /*\n    type h sencode to see options, the noextend option returns an error\n    if the existing label doesn't capture all values.\n    */\n    sencode `var', label(`var'_label) replace noextend\n}\n// end foreach v of local str_var\n\n*Display the labeled and unlabeled values\ntab make\ntab make, nol",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/dataset-documentation.html#dataset-management",
    "href": "data-cleaning/dataset-documentation.html#dataset-management",
    "title": "Dataset Documentation",
    "section": "Dataset Management",
    "text": "Dataset Management\nVariables should only keep necessary variables. Those variables should be ordered in a understandable way, and should be named and labeled. They should also be in the correct storage format for analysis. The clearest way to do this may vary, especially with variable order. The order that questions appear in the survey is a good candidate. Unique identifiers should always be first.\nAny script that saves data should have code that identifies the variables saved, orders them, and describes them for readers. This will ensure that a reader can look at the code and understand what it produces without running a do file. An example codeblock for the end of a do file follows. Note that values are described using comments and the file ends with some commented marker.\n**B. Sort and clean vars\n    isid hhid // confirm Household ID is unique\n    sort hhid // sort in a unique order\n\n    *Create a local of variables\n    loc vars                        ///\n    hhid        enum_id             /// ID Variables\n    cluster     survey_date form_id /// File source variables\n    treatment   scto_rand           /// Treatment assignment\n    bl_hhh_age  bl_hhh_female   bl_hhh_educ /// Baseline demos\n    bl_hh_size                      ///\n    bl_cons_veg_*   bl_cons_meat_*  bl_cons_purch_* /// Consumption\n    bl_cons_alc                     ///\n    bl_loan_size    bl_loan_exp_pay_m*  bl_loan_miss_m* /// Loan information\n    bl_msf      bl_otaf                 // Lender Fees\n\n    *Keep necessary values\n    qui ds `vars', not\n    assert `: word count `r(varlist)'' == 0 // check no variables dropped\n    keep `vars'\n\n    *Order ID first\n    order `vars'\n\n\n**C. Save and close\n    *Save data to the data folder\n    save \"${data}01a_baseline.dta\", replace\n\n    *Close the log\n    log c\n\n\n**EOF**",
    "crumbs": [
      "Data Cleaning",
      "Dataset Documentation"
    ]
  },
  {
    "objectID": "data-cleaning/data-aggregation.html#appending-data",
    "href": "data-cleaning/data-aggregation.html#appending-data",
    "title": "Data Aggregation",
    "section": "Appending data",
    "text": "Appending data\nIf you have two files that contain the same variables, but different observations, you will most-likely want to append these two files to create a complete dataset. For example, if you have one dataset of adults and another with just children from your survey, or females in one file and males in another, you will append the two datasets into one. In appending datasets, it is important to pay attention to variable names and types.\n\nOnly variables with the exact same name in the two files will be appended on top of each other.\nIf you have a variable in one dataset (say you have “#_of_children” in a females data set but not the males) and you append these, the variable will be in the joint dataset but all of the observations from the dataset without that variable will be missing (i.e. the value of #_of_children for all males will be missing)\nVariables you want to combine should be of the same general type (i.e. numeric or string)\n\nIf they are not, you will get an error and Stata will prompt you to use the force option\nThis option is not preferable. It will keep the type of your variable in the master data and replace your using observations for that variable as missing.\nThus you should sort out whether they should be string or numeric ahead of time\n\nCombining string variables of different lengths (e.g. str5 and str10) will result in a string of the longer length of the two (e.g. str10).\nWhen combining different numeric types (e.g. float, double, int, byte) Stata will keep the more precise numeric type and will convert the variable of lower precision to the one of higher precision.",
    "crumbs": [
      "Data Cleaning",
      "Data Aggregation"
    ]
  },
  {
    "objectID": "data-cleaning/data-aggregation.html#merging-data",
    "href": "data-cleaning/data-aggregation.html#merging-data",
    "title": "Data Aggregation",
    "section": "Merging data",
    "text": "Merging data\nSometimes, you may need to merge two or more datasets together, if they are split by variables and contain the same observations. For example, you may have variables that were split between two datasets by the survey program. Be sure that both datasets have a unique ID and be extra careful to specify whether the merge is one-to-one or one-to-many (although you will receive an error if you do the wrong merge type so you don’t have to worry too much about this causes problems). You should also check that your two datasets do not have any variables with the same names. When you perform a merge, if you have the same variable in both datasets, Stata will automatically keep the master data as authority. You can change this assumption by using the update and/or replace options to use the using values. However, it probably makes more sense to rename one of the variables and keep both.\n\nMany-to-many merge\nA many-to-many merge is a really bad practice and should not be done. Many people think that a many-to-many merge will create all of the pairwise combinations of observations that match on each ID. If this is what you desire you should use joinby. Rather, a many-to-many merge pairs your two datasets by the way the observations are sorted within the id. So it matches the first observation in dataset 1 for person 1 with the first observation in dataset 2 for person 1 and so on.\n\n\nPost merge\nIn a merge, each type of “match” is assigned a number (see help merge for the numeric codes assigned). After the merge, type tab _merge and check to see that the results (number of matches, number from master data only, number from using data only, updated missing values, and conflicting nonmissing values) were what you expected. Adding a few assertions after the merge is good practice to make sure things are running correctly. There are a couple other merge command options that try to build in more safety features for you. You should look at the documentation for both safemerge and mmerge for alternative merge methods.\n\n\nHelpful options\nOptions that are helpful to include are assert, keep, keepusing, gen, nogen. If you are not familiar with any of these see the help merge file.\nSee the IPA Stata beginner’s training manual for step-by-step guidance on how to merge datasets. The IPA high intermediate Stata training also has a helpful module on merging, including a discussion of common pitfalls.",
    "crumbs": [
      "Data Cleaning",
      "Data Aggregation"
    ]
  },
  {
    "objectID": "data-cleaning/data-aggregation.html#fuzzy-merge",
    "href": "data-cleaning/data-aggregation.html#fuzzy-merge",
    "title": "Data Aggregation",
    "section": "Fuzzy Merge",
    "text": "Fuzzy Merge\nUsually when you merge, you have a unique ID — or at least enough of one that you can salvage. Sometimes, however, no unique identifier was collected, and you’re left searching for alternative ways to link two datasets. The most obvious way to do this is to try and match on names or other string variables. However, this approach is often inaccurate: small misspellings in these variables can easily result in mismatches. For data where names are machine entered, removing obvious sources of mismatches (spaces, capital letters, etc.) may resolve this problem. Small numbers of mismatches can be manually matching But in many cases the amount of data may make this impossible. Fuzzy merging, also called fuzzy matching, is a solution in that case.\nFuzzy matching refers to the technique of finding strings that approximately match or are the most likely to be similar in two sets of comparisons, rather than exactly matching. Commands that use this type of algorithms will typically give out probabilities of matches and should only be used when exact matching is not an option. If you are thinking about using one of these commands, check with your manager to identify alternatives as fuzzy mergeing’s match rate is usually much less than exact matching. Exact matching is almost always preferred if it’s possible.\nUsually fuzzy matching consists of three steps: 1. String cleaning – prepare the match data by standardizing spaces, capitalization, removing special characters. Based on the data this can include common phrases such as titles (e.g. “Mrs.”) in name. 2. Probabilistic matching – the fuzzy matching function estimates a probability that an observation in the master data one matches to an observation in the using data. 3. Matching review – matches need to be reviewed to decide the point (e.g. 0.2 Jaro-winkler distance) where the match is considered successful, after which records need to be manually matched.\n\nCommands\nThere are a few commands that can help with fuzzy mergeing in Stata. All are user written and can be installed using ssc install [command] :\n\nreclink\n\nInstead of a single unique ID, you specify one or more variables that reclink assess for similarity. For example, two numeric ages of 25 and 26 are a closer match than 35 and 65. reclink also supports string matching, so, for example, you can try using string variables in the linkage even if the variables aren’t perfectly clean. After reclink these values\nreclink is has some well known issues: Previous RAs have run into the following issues. Each bullet below describes a problem along with the attempted solutions and whether they succeeded.\n\nThe variable specified to idusing() should never be in the master dataset. If this is the case,_merge match U* should be right.\nreclink will not merge in values of shared variables from the using dataset without warning the user. The two datasets shouldn’t share any variable names except for the variables for matching.\nIf idusing() and idmaster() have the same variable names, matches might not happen properly. When using reclink, tempfiles can be especially helpful, since you will likely need to be jumping back and forth between files to change variables names, and changing names simply for the period of matching might be one of the easiest ways of ensuring you’re preserving the original versions of variable names in your dataset.\n\nThere is a second reclink2 command that improves on the reclink command and adds many-to-one matching. This is installed by typing net install dm0082 to install the entire package.\n\n\n\nmatchit\n\nmatchit only matches single variables to generate a probability score between those variables. You can match multiple columns sequentially and average or weight the probabilities to match on multiple string columns.\nmatchit has multiple matching algorithms that are explained in the helpfile. All of these provide more than one likely match, which can be used to determine a second best guess.\nThe results from matchit can be merged by joinby or merge to the using or master datasets, but matchit does not function like a merge. This is useful for most workflows.\n\n\n\nstrgroup\n\nYou will need to type net install strgroup to get this command. This command calculates the difference between strings and uses a user-specified threshold to create groups/matches.\nstrgroup works within a single dataset. Data preparation to create this usually involves joining a single master variable to the ID variables in the using dataset.\n\nA number of other commands and approaches eist for this problem. This has been evaluated in the economics literature for historical record linkage. Abramitzky et. al. test multiple matching protocols and find that automated comparison techniques compare favorably to human matching in a variety of circumstances. Stata resources are included with the linked paper.",
    "crumbs": [
      "Data Cleaning",
      "Data Aggregation"
    ]
  },
  {
    "objectID": "data-cleaning/index.html",
    "href": "data-cleaning/index.html",
    "title": "IPA/GPRL Data Cleaning Guide",
    "section": "",
    "text": "Proper data cleaning is essential for analytical accuracy. Raw data needs to be modified before it can be used for data analysis. These modifications are called cleaning. The cleaning process should always be reproducible, well documented, and defensive; the code should tell the user if the data isn’t as expected.\nThe IPA/GPRL Data Cleaning Guide presents a set of common tasks and provides information on “what” each step is and “how” we suggest this step is completed in Stata. The guide also flags potential roadblocks during the data cleaning process. This guide assumes basic knowledge of Stata (introductory Stata training can be found here).\nAs part of this guide, we briefly cover other parts of the data flow, including coding best practices, deidentification, and version control. In many ways these topics are distinct from data cleaning, but all interrelate to some extent. Effective data cleaning will follow coding best practices, have a version control system, and be well documented.",
    "crumbs": [
      "Data Cleaning",
      "About Data Cleaning"
    ]
  },
  {
    "objectID": "data-cleaning/index.html#data-flow",
    "href": "data-cleaning/index.html#data-flow",
    "title": "IPA/GPRL Data Cleaning Guide",
    "section": "Data flow",
    "text": "Data flow\nAt a high-level, the process that data goes through from when it is generated, in a survey or from an automated banking systems, is a transition from a format that reflects the structure of what is collecting the data to a structure that can be used for analyzing the information. The contents of the data do not change during this process, but the format in which they’re stored, aggregated, and labeled do.\nThis entire process is called a data flow. At GPRL and IPA, we think of the steps in the data flow that take place in statistical software in the four steps below. It is worth noting that differences in the data may make it impossible to follow this order exactly. Generally, deidentification should happen as soon as possible in the data flow if the data contains PII:\n\n\n\nData Flow Process\n\n\n\n\nImport data: All collected data is combined into a format readable by statistical software. In this step, the raw data is imported, corrections from enumerators are applied, and duplicates observations are removed.\nDeidentify data: Personally identifying information (PII) is removed. This includes all individually identifying PII (geographic information, names, addresses, enumerator comments, etc.), as well as group identifying information (a combination of village and birthdate for example).\nClean data: Data content, formats, and encoding is standardized. After this, data consistency is verified and similar datasets are appended to create single datasets used to create outcomes.\nCreate outcomes: Individual outcome variables are created from the clean data. Data are merged and appended as part of this project to make a dataset at the level of analysis needed.",
    "crumbs": [
      "Data Cleaning",
      "About Data Cleaning"
    ]
  },
  {
    "objectID": "data-cleaning/index.html#data-cleaning",
    "href": "data-cleaning/index.html#data-cleaning",
    "title": "IPA/GPRL Data Cleaning Guide",
    "section": "Data cleaning",
    "text": "Data cleaning\nIt goes without saying that raw data cannot be used for analysis. Individual survey items will not be informative on their own in most cases. Outcome variables need to be created from standardized sets of variables. In addition, documentation needs to be added so users of the data are clear on what each dataset contains.\nRaw data often needs corrections and deduplication that often requires additional data from enumerators or respondents. We view data collection for replacement as part of the data collection process. Often, these replacements are collected and made as part of the monitoring process. IPA and GPRL produced many tools and resources to help this process. In particular, IPA’s Data Management System supports data quality monitoring, duplicate management, and corrections.\nOnce data is in a format to be imported, the raw data will have its own idiosyncrasies. The cleaning process attempts to standardize these idiosyncrasies in a reproducible way. Imagine you have three surveys each with slightly different outputs. Cleaning would make the output from those datasets equivalent in format, and standardized modifications made to the content. The code that produces those data should be able to be run any number of times and should tell the user if something about the data has changed so that it can’t accomplish its function.\nWe find it useful to think about the cleaning processing in four rough stage:\n\nRaw Survey Data Management\nVariable Management\nDataset, Value, and Variable Documentation\nData Aggregation\n\nEach of these stages has a description in the guide, as well as a list of tasks which each has a subpage in the guide. In addition, this guide briefly touches on Stata coding practices relevant to this process, as well as some tasks related to outcome creation that require data management and are particularly prone to error in Stata.",
    "crumbs": [
      "Data Cleaning",
      "About Data Cleaning"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html",
    "href": "data-cleaning/variable-management.html",
    "title": "Variable Management",
    "section": "",
    "text": "Raw survey data is often relatively clean at the variable-level because the data is generated with a variety of constraints on how the data are formatted. For example, multiple response (select multiple) variables only allow certain responses which are known to the analyst from the survey instrument. These responses do not change in content unless the survey does. For other types of variables, most computer-assisted personal interviewing software such as SurveyCTO allow for constraints to be built into the survey instrument. IPA has a number of tools to support data quality during data collection such as the data management system, which checks for data quality concerns.\nMuch of the cleaning work required for survey data includes standardizing formats of variables so that they are usable for analysis. This includes ensuring missing and non-response values are missing in statistical software, that categorical formats are in a useful format, and variables correspond to the correct storage format, subjective orientation, and follow missingness patterns. These are substantive coding tasks and can benefit from consistent and automated approaches. This section is primarily concerned with doing those tasks safely and quickly with minimal manual input or transcription.",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#handling-missing-values",
    "href": "data-cleaning/variable-management.html#handling-missing-values",
    "title": "Variable Management",
    "section": "Handling missing values",
    "text": "Handling missing values\nFor a number of reasons, variables will have missing values for certain observations. It is helpful to have the data reflect why these values are missing, particularly for numeric variables. For instance, you may want to know whether someone didn’t answer a question about business revenues because the question was skipped (e.g., they weren’t business owners) or whether it was because they could not remember.\n\nMissing values on import\nMany statistical software will import variables and observations that only contain missing values when importing from other data formats. Often times, it’s useful to clear those values immediately after importing data. This can be done manually, or through the missing command which can be installed through SSC. One approach is to do this is as follows:\n*Import data starting on the row of variable names: B1\nimport excel using \"${raw}/rawdata.xlsx\", cellrange(B1) first clear allstring\n\n*Remove rows and columns with only missing\nmissing dropobs, force\nmissing dropvars, force // usually don't use force, but fine in this case\n\n*Ensure non-missing IDs\nisid id\nSometimes missing values are filled as non-empty values in other data management software (SQL uses “NULL”, R uses two types: “NA” (has 4 subtypes) & “NaN”, etc.). It’s worth checking data to ensure those values are removed or properly turned to missing after importing\n*Check variable names if anything equals \"NULL\"\nds, has(type string) // only search strings\nforeach var in `r(varlist)' {\n    replace `var' = \"\" if `var' == \"NULL\"\n}\nFor numeric variables, this can be done in one line using recode. For example, imagine all -99 values should be missing values:\n*Recode -99 to missing for all values\nrecode * (-99=.)\n\n\nExtended missing values in Stata\nStata has special codes for numeric missing values. For numeric variables, missing values are considered to be greater in value than all other numbers and themselves have an order of magnitude. The magnitude of missing values increases across the alphabet, with the standard missing value . coming before .a: . &lt; .a &lt; .b &lt; .c &lt; … &lt; .z The .a, .b, etc. are called “extended missing values.” . Note that extended missing values cannot be stored in string variables. Instead, all string variables with a missing value are shown as “” (called “blank”).\nEnsure extended missing values consistently represent missing values in your data. For instance, if -99 and -999 refer to “don’t know” in two different waves of the survey, they should be standardized. In that case, you will want to replace all -99 and -999 values with .d. It can be helpful to use the recode command to efficiently replace those values. We suggest keeping the following standards for extended missing values:\n\n\n\nType of Missing\nExtended Missing\n\n\n\n\nDon’t know\n.d\n\n\nOther\n.o\n\n\nNot applicable\n.n\n\n\nRefusal\n.r\n\n\nSkip\n.s\n\n\nVersion differences\n.v\n\n\n\nSome responses may require the enumerator to switch from the standard missing values (for example if a response is restricted to be positive, -99 may not be allowed). Other times, enumerators may enter the wrong missing value by mistake, such as -999 instead of -99. As part of the code to relabel missing values by type, you can include code that searches for these changes. The following code replaces multiple values and looks for positive versions of the missing values in outliers.\n*Assign numerical codes\nloc idk     -99 99 999  // numerical code for \"Don't Know\"\nloc rf      -77 77 75   // numerical code for \"Refuse\"\nloc na      -88         // numerical code for \"Not Applicable\"\nloc oth     -66         // numerical code for \"Other\"\nloc skip    -70         // numerical code for  \"Skip\"\n\n* Replace values for each type of refusal across numerical variables\nqui ds, not(type string)\nlocal numvars `r(varlist)'\nforeach var of local numvars {\n\n    ** Replace missing values as negative for unlabeled numeric variable above 0\n    if mi(\"`: value label `var''\") { // no labels from SurveyCTO import code\n\n        *Skip if value takes less than 0 values\n        if `var' &lt; 0 continue\n\n        *now check if value has missing\n        qui sum `var' if inlist(`var', 99, 88, 77, 66)\n        if `r(N)' == 0 continue // move to next variable if no values have positive version\n\n        * only change if this is the outlier value conditional on previous being completed\n        foreach val of 99 88 77 66 {\n            di \"`var' has `r(N)' cases of `val'\"\n            qui sum `var'\n            qui replace `var' = -`val' if `var' == `val' & (`r(max)' == `val' | `r(min)' == `val')\n        }\n        // end foreach val of 99 88 77 66\n\n    }\n    // end if mi(\"`: value label `var''\")\n\n    ** Relabel based on missing patterns\n    foreach x of local idk {\n        replace `var' = .d if `var' == `x'      // Don't know\n    }\n    // end foreach x of local idk\n    foreach x of local na {\n        replace `var' = .n if `var' == `x'      // N/A\n    }\n    // end foreach x of local na\n    foreach x of local oth {\n        replace `var' = .o if `var' == `x'      // Other\n    }\n    // end foreach x of local oth\n    foreach x of local rf {\n        replace `var' = .r if `var' == `x'      // Refuse\n    }\n    // end foreach x of local rf\n    foreach x of local skip {\n        replace `var' = .s if `var' == `x'      // Skip\n    }\n    // end foreach x of local\n}\n// end foreach var of local numvars\nWe recommend checking outliers and replacements manually, and to search for modal responses in numeric variables that won’t have missing values as outliers. Accurate responses can overlap with missing response codes. Automated replacement code, such as the code above, should only be completed after confirming that all inverted values are correct. Even better, use of defensive coding such as assert or the pause command will resolve this. The best solution is often to make sure that the data generating process guards against this type of messiness. Programming in confirmation questions in the survey (“Did the respondent really answer 99 or is this a missing value?”) can help accomplish this with more accuracy.",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#categorical-and-dummy-variables",
    "href": "data-cleaning/variable-management.html#categorical-and-dummy-variables",
    "title": "Variable Management",
    "section": "Categorical and dummy variables",
    "text": "Categorical and dummy variables\nCategorical variables are ones that have no obvious ordering to the responses. For example, the question “What crop do you grow?” could have the following answers: soy bean, maize, cassava, ground nut, and yams. It can be helpful to have a numeric value attached to each response, however there is no clear ordering here. You can use the command encode to create a value for each in alphabetical order and it keeps the original response as the value label.\nDummy variables are one of the most common variable types you will use. These are also referred to as Boolean or indicator variables. These variables typically take on the values 0 and 1. However, it is important to note that your variable could and/or should have missing values if applicable. For example, an indicator about whether someone has a credit score could be defined as 1 for yes, 0 for no score and missing would mean there was no credit information available about that individual. Note that 0 and missing have different meanings and you should be careful around if and what values are missing. In Stata, you have several options for creating a dummy variable. Two examples of creating this “Has a credit score” dummy variable is below.\n\nThis first way recommended method is to start with an entirely missing variable and then replace with 1's and 0's for each condition.\n\ngen has_score = .\nreplace has_score = 1 if credit_score != .\nreplace has_score = 0 if (credit_score == . & info_available == 1)\nIt is important to note that 0 is defined for those missing a credit score but that credit information is available for, the observations that remain missing are those that are missing a credit score because there was no credit information available. You do not want to lose this information due to poor coding in which you say all these people have no score.\n\nThe second way is more concise but can be trickier.\n\ngen has_score = (credit_score != .) if (info_available == 1)\nThis method does the above in one step. The first half creates a 1/0 dummy by assigning 1 to any observation that meets the condition in the first parentheses and 0 if it does not. Then it uses the if and second parenthesis to assign missing values. If the second condition (info_available == 1) is false, then that observation will be missing. Either method is acceptable, just be careful to take the 0’s and missing values into account.",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#specify-variables",
    "href": "data-cleaning/variable-management.html#specify-variables",
    "title": "Variable Management",
    "section": "“Specify” Variables",
    "text": "“Specify” Variables\nSurvey questions may have a “specify” option, in which the respondent explains their answer or gives an alternate answer not available on the list of choices for that question. These are often triggered by an “other” response. In the raw dataset, alongside the original variable will be a “specify” variable that shows the comments for that question. You (or someone else familiar with the survey) will sometimes need to read through these specify answers and then recode the original variable accordingly. (“Specify” variables are also called other/specify variables, “other” variables, and free-text variables.)\nFor example, if a question asked for someone’s favorite color, giving the options of blue, red, yellow, green, and other. If someone answered “other” and then wrote “sky blue” for their answer, you would want to recode the original variable for favorite color to say “blue” instead of “other”. However, if someone wrote “purple” you could leave their response as is (or, if enough people wrote purple, you could add another category to the variable).\nParticularly for large surveys, this can be a hassle. One helpful approach is to do the following: - First clean each string variable so that similar answers will show the same value. Use string functions like lower(), trim(), and itrim() to convert answers like “PUR pLE”, “ Purple” and “purple” to all be “purple”. - For each specify variable, collapse the dataset into unique answers (for example, if three people wrote “purple” the collapsed dataset would only show “purple” once). - Store those unique answers into a spreadsheet with another column that shows what variable the answer corresponds to. Then, leave one column blank, which you will eventually fill in with the value from the original variable that the response corresponds to (if it should be recoded). For instance, next to “purple” you would put nothing, but next to “sky blue” you would put 1 if 1 corresponded to the “blue” answer option. - Write code to merge the manual corrections from the excel file back into the do file, instead of running this as a series of replace or if `var' == \"sky blue\" | `var' == \"ocean blue\" | `var' == ... commands in the do file.\nMake sure you save do files and documents so that this process can be replicated and understood by someone else in the future.\nThis data flow would like the following. First, the specify responses are cleaned and saved so that the excel sheet can be modified.\n/* MR 10/25/2019:\n  The variable q_oth is the \"specify\" variable corresponding to\n  the variable q If q == 99, then q_oth has a string value input\n  by the enumerator.\n\n  First, I standardize strung responses of the q_other variable and\n  then output an excel document with each unique response.\n*/\n*String cleaning\ngen q_oth_cl = q_oth // create a clean copy to preserve the raw data\nreplace q_oth_cl = lower(q_oth_cl)\nreplace q_oth_cl = strtrim(q_oth_cl) // only trim external spaces so \"sky blue\" does not become \"skyblue\"\n\n*Save excel file\ntempvar map // create column header\ngen `map' = \"\"\nlab var `map'  \"Mapping\"\nlab var q_oth_cl \"Other values\"\n\n*Save to temporary file folder in the in the project folder\npreserve\n\n  keep q_oth_cl `map'\n  duplicates drop q_oth_cl, force\n  export excel q_oth_cl `map' using \"${temp}q_oth.xlsx\", firstrow(varl) replace\n\nrestore\nThis results in a table that looks like this:\n\n\n\nOther\nMapping\n\n\n\n\nsky blue\n1\n\n\nocean blue\n1\n\n\nnavy\n1\n\n\ndepends on the day\n-66\n\n\npurple\n\n\n\n\nThe RA would fill out the mapping column based on the allowed values in the survey. This means that the “Mapping” column would take 1 for the “sky blue” value if the data uses 1 for the survey. If the data uses string values at this point in the cleaning process the “Mapping” column could be filled with “blue.” Ensure that this process is reproducible and rule based. Inconsistent mapping of variables does not create clean data. After this table is completed, it can be merged back into the file to save the values.\nThe code to complete that looks like this:\n/* MR 10/25/19:\n  For question \"q\", specified other values were cleaned according to the\n  following rules:\n    -Any color response with more than 1% of the sample was\n     added as a category\n    -Specified colors that are a subset of the option (sample)\n    -Non-colors were replaced as missing\n      -Extended missing values were used if these should have been\n      an extended missing value captured by the survey.\n\n  These values were saved in a file in the Project Folder at:\n    ../08_Analysis&Results/01_Cleaning/05_Temp/q_oth_mapped.xlsx\n  They will then be merged in and replaced to the individual variables.\n*/\n*Load in data and save a tempfile\npreserve\n\n  import excel using \"${temp}q_oth_mapped.xlsx\", first clear\n  keep if !mi(Mapping) // only merge on mapped values\n  ren Othervalues q_oth_cl // change the file back to q_oth for the merge\n  tempfile q_oth_mapping\n  save `q_oth_mapping'\n\nrestore\n\n*Merge on file\nmmerge q_oth_cl using `q_oth_mapping', t(n:1) missing(nomatch)\n/*\n  Alternatively, merge to the subset of responses with non_missing values and\n  append these files afterwards using \"merge m:1 q_oth using `q_oth_mapping'\"\n*/\nassert _merge == -1 | _merge == 1 | _merge == 3 // missing, no coding, or coded\n\n*Replace values\nlevelsof q // first collect every level of q and replace\nloc levels `r(levels)'\nforeach level of local levels {\n  replace q = `level' if mapping == `level'\n}\n\n*Replace extended values\n// do this manually\n\n*replace missing values to IPA standard missing values\nreplace q = .d if mapping == -66 // don't know\nreplace q = .r if mapping == -77 // refusal\nreplace q = .n if mapping == -88 // not applicable\n\n*finally check that everything was captured\nassert q != 99 if _merge == 3 // this assumes 99 == other in the survey AND that the all values were coded\ndrop _merge q_oth_cl mapping // remove extraneous variable",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#skip-logic",
    "href": "data-cleaning/variable-management.html#skip-logic",
    "title": "Variable Management",
    "section": "Skip Logic",
    "text": "Skip Logic\nSurveys will likely have skip logic. For instance, if a respondent says they have zero goats to a question, the survey may instruct the surveyor to (or the program may automatically) go to questions about sheep instead of questions about the quality of goat cheese the respondent makes from their goats. When a survey is bench tested and piloted, you should have tested that these skips worked by developing a series of checks based on a close reading of the survey instrument itself. However, skips may not be passed to the final dataset by some programs, such as SurveyCTO. This can make it hard to check if there were any errors in the survey coding.\nDefining additional missing values for skips and for questions that were not asked, such as those in long repeat groups can be helpful for two reasons: 1. Skip values that take an extended missing values can be identified using ==.s without capturing other types of general missing values .s. 1. Excluding skip values from the general missing value . can help to identify errors in cleaning later on, as Stata will not impute .s normally. Then, failures in skip logic can be identified as part of the cleaning process. If some of the skips did not work or allowed for some entry error among respondents, document the issues by outputting a list of the problematic observations into a spreadsheet and mention it to the PIs.\nThe following code assigns skip values and then confirms that the skips were successful during the survey implementation. It can be very helpful to use the assert command to check this. In addition, ensure that the observations who answered those questions are marked in the data by a dummy variable named in a consistent manner.\n/*\n    In this example, there is a module that asks about business profits\n    only if the respondent has a business. The question that starts\n    a set of questions, b_prof_s*, on business profits is b_prof_yn.\n    All questions should be skipped if  b_prof_yn == 0, but the\n    variables b_prof_s* exist if any respondent has a business.\n\n    First we assign the skip missing value to all observations if they\n    do not have a value. Then we run an assert to confirm skips worked\n    as intended. If they did not, the user is warned and\n    a dataset is saved.\n*/\n\n/* First identify if the respondent has a business and\nfill skip values */\nunab bus_items : b_prof_s* // save all business profits questions\nforeach var of local bus_items {\n    /* create skip patternm note that `var' == ., not mi(`var')\n    to ensure extended missing values are not overwritten */\n    replace `var' = .s if `var' == . & b_prof_yn == 0\n}\n\n\n** Now check to confirm that\nforeach var of local bus_items {\n\n    // don't use capture unless you control for every outcome\n    cap assert `var' == .s if b_prof_yn == 0\n\n    *Tag variables if this fails\n    if _rc == 9 gen `var'_nos = `var' != .s & b_prof_yn == 0\n\n    *Controlling for other options\n    else if !_rc di \"No errors in `var'\"\n\n    // exit with an error if a different error than the assert failing\n    else exit _rc\n}\n\n\n** Export a list of each variable and if it were skipped\n/* Formatting could be done differently here, the below\n   outputs an excel sheet that preserves all other answers\n   and is in the wide format.\n*/\npreserve\n\n    *Save ID and relevant variables\n    keep id key startdate b_prof*\n\n    *Keep relevant observations\n    qui ds b_prof_*_nos\n    egen tokeep = rowmax(`r(varlist)')\n    keep if tokeep == 1\n    drop tokeep\n\n    *Order by variable and missing\n    foreach var of local bus_items {\n        order `var' `var'_nos\n    }\n\n    *Save files\n    export excel using \"${temp}business_skip_errors.xlsx\", first(var) replace\n\nrestore",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#storage-types-in-stata",
    "href": "data-cleaning/variable-management.html#storage-types-in-stata",
    "title": "Variable Management",
    "section": "Storage Types in Stata",
    "text": "Storage Types in Stata\nStatistical software requires a storage type to determine how and what data to store about each variable or value. This storage type determines if the software treats a variable as text or a number, and how much information is stored in each variable. This information could be how many digits of precision are required or if the variable is just 0 or 1s. Some data types such as dates have specific metadata attached – January 1, 1960 was a Friday – that relate to storage type.\nVariables are stored in two broad categories: string (text) or numeric. For tasks in analysis such as regression, Stata requires categorical variables to be stored as numeric variables, not string variables. This is also beneficial for storage size of variables. As a rule of thumb in Stata, ordinal and categorical variable should be stored as numeric variables with labeled values. Only text or IDs should ever be stored as a string variables. Labeling categorical variables is preferred and should be treated as a part of data management.\nStorage formats such string or numeric are the variable’s type, different from its format. Variable formats affect how Stata displays values of variables to the user and are loosely related to the storage type – a string cannot be displayed with significant digits for example.\nNumeric variables are stored as byte, int, long, float or double. Float and double are the two that can hold non-integer numbers (decimals) and are the most common. More details on how numerical formats may affect datasets is available in this guide article. Numerical and string formats can be changed using the recast command, or by specifying a storage format using the generate command.\nString variables storage types are identified by their character length (str4 has 4 characters, str7 has 7 characters, etc.,). Variables are stored as string if they have any nonnumeric character in them (this includes commas and periods if they are imported as such). See help data_types for more information about variable types. Useful commands to go between string and numeric variables are destring and tostring. The command destring turns a variable from a string into a numeric (must contain all nonnumeric characters). The command tostring changes a numeric variable into a string variable. To convert strings to labeled numeric formats and vice versa see the encode and decode (or sencode and sdecode user-written commands).\nA variable’s format controls how the data is displayed. This is can be used to format numeric variables to display with commas or a specific number of decimal points. For details on the corresponding formats for each variable type and how to format variables, type help format. In short, it’s important to match the displayed format to the content, especially for outputs, so that content can be interpretable by humans.",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#date-variables",
    "href": "data-cleaning/variable-management.html#date-variables",
    "title": "Variable Management",
    "section": "Date variables",
    "text": "Date variables\nDates are especially complex to work with in Stata. Stata stores dates as a numeric variable that captures either the number of days, months, quarters, or years since January 1, 1960. It is important to know that dates can also have a time component (datetimes), and are then stored as the number of milliseconds since January 1, 1960. These formats are numeric, but once they are stored as a date in Stata several special Stata functions can be applied to them to help with calculations that relate to dates and time. For more information see h datetime translation.\nSurvey CTO defaults to storing date variables as strings when importing them to Stata. It’s advantageous to convert these variables to a proper date format, as it allows for various logical and mathematical calculations. For example, you could count the number of days between a survey start date and submission date, or the number of minutes between the survey was started and completed. The SurveyCTO datetime metadata (starttime endtime submissiondate) are already stored as date variables.starttime and endtime are formatted as datetimes (%tc) and submissiondate is formatted as a date (%td)).\nTo convert imported dates to be stored as a date type in Stata, the functions date() and mdy() will convert non-date variables to date-formatted variables. The functions clock() and mdyhms() will convert non-date variables to datetime-formatted variables. The date() and clock() functions are useful if your dates are stored as a string variable whereas the mdy() and mdyhms() functions are useful if your dates are stored as numeric variables. These commands will create a variable that is the number of days, or the number of milliseconds, since January 1, 1960.\nFor a set of SurveyCTO datetimes using the same format, the following code will convert all of the variables to Stata date formats and check for data quality:\n*Define list of date variable\nds *_date // this should match your naming convention\nloc date_vars `r(varlist)'\n\n*save tempvar so indifferent to var length\ntempvar temp\n* create double to store datetime to avoid rounding\ngen double `temp' = .\n\n*Foreach date variable, convert to datetime and run checks\nforeach var of local date_vars {\n\n    *Display progress\n    di \"Working on `var'\"\n\n    *Skip if the date is already formatted as any date\n    /*\n        Note: This could also standardize formats using\n        the following code:\n\n        if regexm(\"`: format `v''\", \"%tc\") {\n             replace `v' = cofd(`v')\n             format `v' %tc_CCYY_NN_DD\n        }\n        else if regexm(“`: format `var'', “%t”) continue\n    */\n    if regexm(\"`: format `var''\", \"%t\") continue\n\n    *Convert from string to date\n    /*\n        Note: This specifies a format that all variables share.\n        See h datetime in Stata for an overview on how to define\n        datetime formats for the clock() and date() functions.\n    */\n    loc varl : var label `var' // save var label\n    replace `temp' = . // clear tempvar\n    replace `temp' = clock(`var', \"MDYhms\")\n    *drop the variable as cannot replace values and convert type\n    drop `var'\n    gen double `var' = `temp'\n    format `var' %tcCCYY_NN_DD__HH:MM:SS // choose a preferred format\n\n    *Check within range\n    loc survey_start = clock(\"Jan. 01 1960, 12:00:00 AM\", \"MDYhms\")\n    loc survey_end = clock(\"Feb. 29 2020, 11:59:59 PM\", \"MDYhms\")\n    assert inrange(`var', `survey_start', `survey_end')\n\n    *Check non-missing for calculate fields\n    /*\n        This may not be the case for all projects if some\n        calculate fields are conditional on being read\n    */\n    assert !mi(`var')\n\n}\n// end foreach var of local date_vars\nSome of these checks will duplicate checks conducted as part of IPA’s data management system. It doesn’t hurt to run these confirmations, but we recommend using the data management system to be aware of any problems as soon as possible.\nIf you would like to convert your daily variable into a monthly or yearly variable you can use the following functions: mofd() and yofd(). You can find descriptions of all the functions that convert between which count types for dates (daily, monthly, quarterly, or yearly) by typing help date() and clicking on “Date and time functions” to go to the Stata manual.\nOnce you have date in the right type, you can work with the formatting of the variable. The formatting is how you make the date look like a date rather than the underlying numeric value. You can read how to format your dates in any way imaginable by typing help datetime display formats. Note that changing the format of a date variable does not change its underlying value.",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-cleaning/variable-management.html#logic-tests",
    "href": "data-cleaning/variable-management.html#logic-tests",
    "title": "Variable Management",
    "section": "Logic tests",
    "text": "Logic tests\nClean data should be free of mistakes such as out of range values. Yet, the thousands of lines of survey, database management, cleaning and analysis code that make up projects often contain a number of mistakes. These mistakes are a natural part of any large project. Instead of focusing on having mistake-free code in all cases, it’s often more effective to write code that tests for if the data matches expectations. This approach does not substitute for code review and being careful, but\nCommands like assert in Stata and stopifnot() in R allow the programmer to break the code if some logic test is not met. Logic tests check if the values observed in the data make sense given other values. For instance, can someone who says they were born in 2000 really have been a member of their current community for thirty years? These tests are used to ensure that the clean data is truly clean, not just that the programmer thinks the data are clean.\nThe list of logic tests to test is dependent on each individual dataset. Check for things that would be problematic for data analysis, such as missing values in variables you expect to always have a value. These checks should include other problems in the data that would clearly indicate that something is wrong with the data such as responses to a Likert scale survey question that wasn’t in the list of programmed responses. If any of those tests fail, flag the values in the data and bring them up with the PIs.\n\nDefensive Programming\nIn computer science, programming that ensures a program can function under unanticipated situations conditions is called defensive programming. It can be useful to bring this mentality into social science research. In many cases, defensive programming is natural with the type of data we work with. Many variables have characteristics that we expect from the data and can be easily checked. For example, for a survey of employed adults in the US, with a working age of 18, no respondents should have age below 18.\nWe can check that this is the case in Stata:\nassert age &gt;= 18 & !mi(age) // . is considered infinitely large by Stata, so &gt; 18 captures missing values as well.\nBuilding these tests into your data flow should be a natural test that you work into data cleaning. This can be expanded to other functions like merges. If every household but one received both an agricultural and household survey, each household survey should merge to the plot dataset except one observation. The merge can be checked to confirm that that is the case:\n*Check merge success rate\nmerge 1:1 id using “plots.dta” // note: merge has a built-in assert option\ncount if _merge != 3 // check how many merges did not have an observation in both\nassert `r(N)' == 1\nThese tests should be built into cleaning code, as they are computationally cheap unless data is large. They should be executed every time the code runs, and should test major modifications that affect important variables.\n\n\nLogic Tests for Survey Data\nSurvey data has the benefit of coming from a survey that you, as an analyst, have probably programmed. The survey software and import process often controls for many types of errors. However, data management errors can also occur due to the particular forms that survey data contains. We find these errors are common in survey data management: - Missing values occur in variables that the programmer assumes always has real values - Missing values are inconsistently defined in the survey and are not fully replaced (e.g. “Not Applicable” is -99, -98, and 77) - Variable or value options change between survey versions and aren’t reconciled - Variables with the same name are overwritten as part of a merge. See h mmerge for a user written command that stores this information. - Observations are not unique and some actions such as sorting become irreproducible\nWe strongly recommend testing for these errors as part of the cleaning process.\n\n\nLogic Tests in Administrative Data\nThere are often a broader set of concerns for administrative data as we do not directly have control over the data generation and management process. This means that data definitions and formats may change or be inconsistent over longitudinal data.\nSome additional concerns to focus on in administrative data are: - Ensure that variables remain consistent over repeated deliveries - Data translation and missingness standards of the storage system may create values in statistical software (e.g. SQL treats missing as “NULL”)\nVariable consistency can be handled using value labeling in Stata. For example, to ensure that data remains the same over the course of data collection, it can be useful to check that categorical variables map to expected values to a previously created value label. The noextend option of the encode commands allows you to confirm no values exist in the variable other than those in the supplied label. The following code accomplishes this:\n*Create a local list of variables to encode\nloc str_var var\n\n*Encode values and confirm expected\nforeach var of local str_var {\n\n    *Encode variables\n    sencode `var', label(`var'_label) replace noextend // type h sencode to see options\n}\n// end foreach v of local str_var",
    "crumbs": [
      "Data Cleaning",
      "Variable Management"
    ]
  },
  {
    "objectID": "data-collection/in-person-surveys.html",
    "href": "data-collection/in-person-surveys.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "data-collection/phone-surveys.html",
    "href": "data-collection/phone-surveys.html",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "",
    "text": "This guide provides best practices and tools for implementing phone surveys, a cornerstone of data collection for Innovations for Poverty Action. Voice and text-based phone surveys offer a cost-effective and adaptive method to gather high-quality data, especially in contexts where in-person surveys are impractical.",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/phone-surveys.html#methods-and-best-practices",
    "href": "data-collection/phone-surveys.html#methods-and-best-practices",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "1. Methods and Best Practices",
    "text": "1. Methods and Best Practices\n\nIntroduction\nPhone surveys have become essential for development research, particularly when in-person data collection faces logistical challenges or safety constraints. These methods proved invaluable during the COVID-19 pandemic and continue to offer advantages in hard-to-reach areas, emergency contexts, and time-sensitive research scenarios.\nThis page provides IPA teams and partners with:\n\nGeneral insights on the role and advantages of phone surveys in development research.\nAcademic research synthesizing evidence on best practices (e.g., optimizing response rates, minimizing attrition).\nPractical resources – handbooks, SurveyCTO templates, and implementation guides – to design and deploy effective phone surveys.\n\nWhether adapting an existing in-person survey to phone-based methods or launching a new remote data collection effort, the materials below offer evidence-backed guidance at every stage.\n\n\nWhat Are Phone Surveys?\nPhone surveys are a method of collecting quantitative or qualitative data by contacting respondents over the phone. Common approaches include:\n\nComputer-Assisted Telephone Interviewing (CATI): Live interviews conducted by trained enumerators.\nInteractive Voice Response (IVR): Automated surveys where respondents answer on a keypad or by voice.\nSMS/Text-based Surveys: Questionnaires delivered by text messaging.\n\n\n\nWhy Use Phone Surveys?\n\nAccessibility: Reach respondents in hard-to-access regions or during disruptions (e.g., pandemics).\nCost-Effectiveness: Lower logistical costs compared to in-person surveys.\nSpeed: Rapid deployment for time-sensitive data (e.g., crisis monitoring).\nSafety: Avoid physical contact during health emergencies.",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/phone-surveys.html#weighing-the-advantages-and-challenges",
    "href": "data-collection/phone-surveys.html#weighing-the-advantages-and-challenges",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "2. Weighing the Advantages and Challenges",
    "text": "2. Weighing the Advantages and Challenges\n\nAdvantages of Phone Surveys\n\n\n\n\n\n\nRandom Enumerator Assignment\n\n\n\n\n\nEnumerators can be assigned at random without geographic or travel constraints. Ensures fairness and reduces bias in data collection.\n\n\n\n\n\n\n\n\n\nReduced Logistical Constraints\n\n\n\n\n\nNo need for travel, reducing costs and time. Enumerators can work remotely, increasing flexibility.\n\n\n\n\n\n\n\n\n\nCost-Effectiveness\n\n\n\n\n\nLower operational costs compared to in-person surveys (e.g., no transportation or accommodation expenses). Scalable for large sample sizes.\n\n\n\n\n\n\n\n\n\nFaster Data Collection\n\n\n\n\n\nSurveys can be conducted quickly, especially with automated dialing systems. Real-time data entry reduces post-survey processing time.\n\n\n\n\n\n\n\n\n\nImproved Data Quality\n\n\n\n\n\nComputer-assisted systems minimize human errors in data entry. Built-in validation checks ensure accurate responses.\n\n\n\n\n\n\n\n\n\nWide Geographic Coverage\n\n\n\n\n\nAbility to reach respondents across large or remote areas without physical presence.\n\n\n\n\n\n\n\n\n\nFlexibility in Scheduling\n\n\n\n\n\nSurveys can be conducted at convenient times for respondents, improving response rates.\n\n\n\n\n\n\n\n\n\nEnhanced Monitoring\n\n\n\n\n\nSupervisors can monitor calls in real time, ensuring quality control. Automated systems track call outcomes (e.g., completed, refused, invalid).\n\n\n\n\n\nChallenges of Phone Surveys\n\n\n\n\n\n\nRespondent Tracking\n\n\n\n\n\nDifficulty maintaining contact with respondents over time. Higher attrition rates compared to in-person surveys.\n\n\n\n\n\n\n\n\n\nLanguage Barriers\n\n\n\n\n\nLimited availability of multilingual enumerators. Need for translation services increases costs.\n\n\n\n\n\n\n\n\n\nCall Refusals\n\n\n\n\n\nHigher refusal rates compared to in-person surveys. Respondent fatigue with repeated calls.\n\n\n\n\n\n\n\n\n\nTechnical Issues\n\n\n\n\n\nDependence on reliable phone networks and internet connectivity. Risk of dropped calls or poor audio quality.\n\n\n\n\n\n\n\n\n\nData Privacy Concerns\n\n\n\n\n\nChallenges in verifying respondent identity. Limited control over privacy during calls.\n\n\n\n\n\n\n\n\n\nLimited Non-Verbal Communication\n\n\n\n\n\nCannot observe body language or environmental context. More difficult to build rapport with respondents.\n\n\n\n\n\n\n\n\n\nCall Timing Constraints\n\n\n\n\n\nRestricted windows for successful contact. Need to balance persistence with respondent convenience.\n\n\n\n\n\n\n\n\n\nSurvey Design Limitations\n\n\n\n\n\nShorter attention spans for phone interviews. Complex questions may be harder to convey verbally.",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/phone-surveys.html#when-to-implement-phone-surveys",
    "href": "data-collection/phone-surveys.html#when-to-implement-phone-surveys",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "3. When to Implement Phone Surveys?",
    "text": "3. When to Implement Phone Surveys?\nAfter weighing the advantages and challenges, consider these key factors before implementing phone surveys:\n\nEssential Criteria\n\n\n\n\n\n\n\nCriterion\nKey Questions\n\n\n\n\nData Urgency\n- Is immediate data collection necessary?  - Can the research questions wait for in-person collection?\n\n\nSafety and Ethics\n- Can data be collected safely and ethically?  - Are there risks to respondents or enumerators?\n\n\nTechnical Feasibility\n- Do you have reliable phone numbers?  - Do respondents have consistent phone access?  - Is there adequate network coverage?\n\n\nResource Availability\n- Can you compensate respondents?  - Do you have budget for airtime and equipment?  - Are trained enumerators available?\n\n\nResearch Design Compatibility\n- Can your research questions be answered by phone?  - Is the target population reachable by phone?  - Are survey length and complexity suitable?\n\n\n\n\n\nChoosing an Appropriate Mode\nRecommended modes:\n\nCATI: Best for data quality but requires interviewers\nIVR: Lower cost but may frustrate respondents\nSMS: Limited by literacy and message length\nWeb: Less common in low-income countries\n\n\n\nResearch Goals by Mode\nSource: Remote Surveying in a Pandemic: Handbook\n\n\n\nGoal\nCATI\nIVR\nSMS\nWeb\n\n\n\n\nTracking respondents\n~\n+\n~\n-\n\n\nUpdating contact info\n+\n-\n~\n~\n\n\nDetermining language\n+\n+\n-\n+\n\n\nHigh-frequency data\n~\n+*\n+*\n+\n\n\nSensitive outcomes\n~\n~\n-\n~\n\n\nHigh response rates\n+\n-\n-\n-\n\n\nLarge samples\n-\n+\n~\n+",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/phone-surveys.html#resources",
    "href": "data-collection/phone-surveys.html#resources",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "4. Resources",
    "text": "4. Resources\n\nGuides and Templates\n\n\nRemote Surveying in a Pandemic: Handbook\nComprehensive guide to designing phone surveys during disruptions.\n\n\nUnable to display PDF file. Download instead.\n\n\n\n\nSurveyCTO Templates for Phone Surveys\nPre-built templates for phone surveys in SurveyCTO, including:\n\nCATI call tracking forms\nPhone number validation\nAppointment scheduling\nCall attempt logging\nMulti-language support\n\nView Templates on GitHub\n\n\nIPA RECOVR Phone Survey\nInsights on IPA’s phone survey initiative during COVID-19, including:\n\nSurvey implementation guide\nSample tracking protocols\nResponse rate optimization\nQuality control measures\nCross-country coordination\n\nView RECOVR Resources\n\n\nCATI SurveyCTO Plug-ins Webinar\nDiscover how J-PAL and IPA use SurveyCTO plug-ins for phone surveys, including:\n\nAutomated call scheduling\nMulti-language support\nCall tracking integration\nQuality monitoring tools\nCross-platform compatibility\n\nView Webinar Recording\n\n\nAcademic Research\n\n\nRemote Surveying in a Pandemic: Research Synthesis\nMeta-analysis of phone survey adaptations.\nDownload source data (Excel)\n\n\nPre-Survey SMS Contact\nEvidence on messaging to boost response rates.: Download PDF\n\n\nMonetary Incentives\nImpact of incentives on participation.: Download PDF\n\n\nMode Effects on Data Quality\nComparing phone vs. in-person data accuracy.: Download PDF\n\n\nAttrition in Mobile Phone Panels\nStrategies to mitigate panel dropout.: Download PDF\n\n\nOptimal Timing for Random Digit Dialing\nMaximizing contact success rates.: Download PDF\n\n\nRepeated Attempts in Random Digit Dialing Surveys\nBest practices for rescheduling calls.: Download PDF\n\n\nBest Practices Summary\n\nPre-notification: Send SMS/WhatsApp alerts to improve response (WhatsApp Start Guide)\nIncentives: Small monetary rewards increase participation\nCall Scheduling: Prioritize evenings/weekends\nQuality Checks: Monitor for mode-related biases (Mode Effects)",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/phone-surveys.html#conclusion",
    "href": "data-collection/phone-surveys.html#conclusion",
    "title": "Phone Surveys: Best Practices and Tools",
    "section": "5. Conclusion",
    "text": "5. Conclusion\nEffective phone surveys require careful planning, appropriate technology, and systematic quality control. Success depends on matching survey mode to research objectives, implementing robust tracking systems, and applying evidence-based practices for maximizing response rates and data quality.",
    "crumbs": [
      "Data Collection",
      "Phone Surveys"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#what-is-a-focus-group",
    "href": "data-collection/qualitative-methods/focus-groups.html#what-is-a-focus-group",
    "title": "Conducting Focus Groups",
    "section": "What is a focus group?",
    "text": "What is a focus group?\nFocus groups are one of the most widely used techniques in social research, particularly within qualitative studies. This method involves creating a discussion space where participants engage in an in-depth conversation about one or more topics.1 Focus groups represent an artificially configured environment whose main goal is to gather information on the interaction among participants. This includes exploring their perceptions, opinions, and attitudes toward specific topics.2\nUnlike individual interviews that capture personal perspectives in isolation, focus groups reveal how opinions form, evolve, and are negotiated in social contexts. They’re particularly valuable when you need to understand community norms, examine areas of consensus or disagreement, or explore how people collectively make meaning of experiences.\n\n\n\n\n\n\nFocus groups with migrant populations\n\n\n\nIn a focus group with Venezuelan migrants in Colombia, several common perceptions about the healthcare system emerged. While some participants acknowledged the accessibility of essential medical services as an advantage of the Colombian system, others expressed concerns about the quality of care, long wait times, and challenges in accessing specialized services, particularly due to their migratory status. The group dynamics revealed how participants validated each other’s experiences, creating a more comprehensive picture than individual interviews might have provided.\n\n\nIn a typical focus group, a moderator leads the discussion. This person ensures active interaction among participants. The moderator’s role is to ask questions that stimulate discussion, guide the conversation to gather valuable insights, and build trust with the participants. This trust is crucial to making participants feel comfortable expressing themselves freely, ensuring the discussion remains productive and focused on relevant topics. Focus groups allow us to gather data on how participants communicate, share their opinions and experiences, and react to the contributions of others.\nThe dynamics of focus groups allows researchers to identify what information is censored or encouraged among participants.3 In this context, group conversation does not necessarily imply consensus, because during the conversation participants may misinterpret each other’s accounts, question themselves and attempt to persuade each other.4 Disagreement is also a key component of this collection technique, as it allows exploring the diversity of opinions and the reasons behind participants’ beliefs and attitudes. Overall, focus groups make it possible to identify both shared perceptions and divergences among participants on a specific topic.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#planning-a-focus-group",
    "href": "data-collection/qualitative-methods/focus-groups.html#planning-a-focus-group",
    "title": "Conducting Focus Groups",
    "section": "Planning a focus group",
    "text": "Planning a focus group\nProper preparation is essential for the success of focus groups, ensuring that the research activity meets its field data collection objectives. This section provides detailed guidance on the planning steps that should be undertaken before conducting a focus group.\n\n\nStructure your team\n\n\nIdeally, focus group teams should consist of at least two roles: a moderator and a facilitator. The moderator’s primary responsibility is to lead the discussion during the focus group, ensuring that the conversation remains on track and that all participants are engaged. The facilitator handles logistical activities such as setting up recording equipment, providing refreshments and incentives, setting up the space, as well as, taking notes. It is crucial to clearly define and assign these roles in advance to ensure a smooth execution of the focus group.\n\n\n\n\n\n\nBudget vs. quality trade-offs\n\n\n\nIf budget constraints prevent hiring a facilitator, it is important to recognize that this could negatively impact the quality of the activity and the data collected. Overburdening the moderator with both discussion and logistical duties may compromise their ability to maintain participant focus and engagement. Researchers should be aware of these potential drawbacks when planning qualitative data collection without a dedicated facilitator.\n\n\n\n\nRecognize the skills of the field team\n\n\nThe quality of data produced during qualitative research activities is closely related to the skills of the moderator and facilitator. These competencies, outlined in Table 1, enable teams to recognize and adequately represent the diversity within qualitative data. While these skills are typically developed through years of study and practice, field teams often consist of individuals from multidisciplinary backgrounds with varying levels of experience. Regardless of experience level, it is important to review and discuss these skills with your team to identify possible gaps and opportunities for improvement.\nCurrently, there are no standardized metrics to measure the prevalence of these skills among qualitative fieldwork moderators. Therefore, the skills in Table 1 should be viewed as a resource for reference and reflection for teams. Ensuring that everyone on the team understands how these competencies contribute to effectively engaging with the population is essential for collecting high-quality information.\n\n\n\nTable 1: Skills of field staff conducting focus groups\n\n\n\n\n\n\n\n\n\n\nSkill\nDescription\nWhy is this skill relevant?\n\n\n\n\nCognitive empathy\nThe field team’s ability to understand and communicate participants’ situations from their perspectives, understanding how they see the world and their roles within it.\nAllows researchers to connect more deeply with participant’s realities and experiences. Helps to create a relationship of trust and respect with the participants. Seeks to avoid generalizations and stereotypes that may arise from preconceptions or external influences such as previous studies. Enhances understanding of participants’ situations without resorting to pity.\n\n\nFollow-up\nThe field team’s ability to recognize when additional information is needed to answer the questions initially posed and those that arise during the research process. This ability implies curiosity and a willingness to explore new issues or doubts that emerge as data collection progresses.\nIncreases the quality and robustness of data by allowing a more detailed exploration of the studied phenomenon. Contributes to obtaining deeper responses from participants. Enables exploration of emerging themes during data collection. Helps in detecting and validating patterns observed in the field.\n\n\nSelf-awareness and reflexivity\nThe field team’s ability to continuously reflect on how their presence, background, and assumptions influence data collection, interpretation, and analysis. This ongoing self-reflection ensures that the qualitative field team is mindful of its impact on the research process and the participants.\nHelps maintain ethics in the researcher-participant relationship. Facilitates understanding of personal limitations in connecting with participants. Aids in developing strategies to overcome communication barriers and create an environment where participants feel comfortable sharing sensitive information.\n\n\nHeterogeneity\nThe field team’s ability to represent and reflect the diversity within the group being studied. This skill involves recognizing and documenting the differences and variations among individuals or subgroups during qualitative research, typically applied during the data analysis phase.\nContributes to challenging generalized and simplistic patterns. Ensures that data reflect both common and atypical experiences. Demonstrates the field team’s ability to identify, recognize, and document heterogeneity in the population studied.\n\n\nPalpability\nThe field team’s ability to provide detailed descriptions in their field notes or diaries, making the data tangible and clear. This involves avoiding abstract descriptions and, instead, offering vivid accounts that allow the research team to visualize and understand participants’ experiences and contexts.\nThe palpable field notes and diaries are accompanied by textual quotations, images, or other audiovisual resources that show events, situations, and actors that support the research findings. Reliable findings are supported by specific details that clearly depict the events and situations studied. Helps to avoid abstraction in the data, grounding conclusions in concrete evidence.\n\n\n\n\n\n\n\n\nPlan the logistics of your focus group\n\n\nLogistical activities are important to ensure the correct implementation of focus groups. Careful logistical planning will ensure that all the necessary elements are in place to carry out the activities, participants have been scheduled in a timely manner, and all the details surrounding the fieldwork are clear. Based on the experience of conducting qualitative field operations in various contexts, the IPA Colombia team has identified several key practices that are essential for the logistical preparation of a focus group:\n\n\n\n\n\n\nSchedule Participants\n\n\n\n\n\nSchedule activities and participants at least one week in advance. Send reminders prior to the activity.\nDuring scheduling, inform participants about the objective, scope, leading organization, and confidentiality of the focus group to align expectations and avoid confusion.\n\n\n\n\n\n\n\n\n\nVerify the location of the focus group\n\n\n\n\n\nVerify the location and conditions of the meeting site. Remember that it is important to schedule a place whose location does not pose a risk to the participants or the team.\nThis place should have the necessary furniture (chairs and tables) so that participants feel comfortable and can interact with each other.\n\n\n\n\n\n\n\n\n\nPrepare essential materials\n\n\n\n\n\nEnsure you have all the necessary materials for the session. This includes incentives (if applicable), refreshments/snacks, attendance list, recording equipment, and batteries.\nTest the audio equipment in advance to ensure clear recording and facilitate the group dynamics.\n\n\n\n\n\n\n\n\n\nReview the strategies for taking notes\n\n\n\n\n\nHave a note-taking strategy to: identify topics not recorded in the audio, capture non-verbal interactions among participants, and document the session in case participants do not consent to being recorded. The facilitator supports this task.\n\n\n\nIt is worth noting that there is no particular order/progression to these activities. The sequencing presented above is suggested and may change according to the context in which the focus groups are conducted. The listed activities exclude logistical tasks that the field and research team had to undertake to ensure the feasibility of conducting research activities, such as guaranteeing a space, contacting leaders, purchasing materials, etc. You should make a comprehensive list of the critical aspects to ensure the success of your qualitative data collection at different levels. As the fieldwork approaches, we suggest you consult the issues previously mentioned.\n\n\nDesign and study the script\n\n\nThe discussion script is a support tool that seeks to guide the conversation during the focus group according to the research objectives. It contains open-ended questions and topics designed to encourage reflection and discussion. You should study the script several times before the activity so that you will be able to explore new topics without losing sight of the objectives of the session. During this process of studying the script, identify:\n\nThe objective of the research activity.\nThe logical order of the focus group guide.\nPossible words or expressions that may confuse the participants so that you have time to change them to more understandable ones.\n\nIf you know in detail the topics to be explored, the script will serve as a reminder during the talk, allowing you to have more flexible and deeper conversations, without losing sight of the research objectives.\n\n\n\n\n\n\nThe role of the facilitator\n\n\n\nIn addition to understanding the script, the facilitator must also understand the research questions of the project. This will allow them to probe beyond the guide and see, during the execution of the activity, possible questions or dimensions of the problem that were not known when the script was developed.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#conducting-a-focus-group",
    "href": "data-collection/qualitative-methods/focus-groups.html#conducting-a-focus-group",
    "title": "Conducting Focus Groups",
    "section": "Conducting a focus group",
    "text": "Conducting a focus group\nWhen initiating a focus group, always start by introducing yourself, explaining the role of each member of the work team, and the overall dynamics of the session. Read the informed consent, ensuring all participants clearly understand the purpose of the activity and the potential risks and benefits of their participation. During this process, emphasize the confidentiality and anonymity of the information collected during the focus group. The moderator should explicitly obtain the participants’ authorization to record the session. Throughout the activity, create a comfortable and calm environment that allows participants to express their opinions spontaneously and without censorship. To maintain a favorable atmosphere, show interest, cordiality, and respect for all interventions, having an attitude of curiosity, even when the topics are extended or the opinions expressed differ from yours.\n\nBeing an effective moderator\nTable 2 presents key principles to moderate focus groups. 5 The moderator plays a key role guiding the discussion, ensuring equal participation from all members, and keeping the conversation focused on relevant topics. An effective moderator facilitates a smooth and natural discussion, creating an environment where participants feel comfortable and safe to express their opinions openly, without fear of criticism or judgment. The moderator also manages potentially challenging group dynamics, ensuring that all participants have equal opportunities to contribute, and preventing any one participant from dominating the conversation. Other key responsibilities of an effective moderator include:\n\nEnsuring the recording equipment is working properly throughout the activity.\nTaking comprehensive notes on the entire activity, particularly focusing on participants’ interactions and nonverbal reactions.\nEnsuring that the seating arrangement of the participants is appropriate for effective communication.\nProviding logistical support to the moderator by delivering refreshments and incentives (if applicable) and attending to the specific needs of participants, such as assisting visually impaired individuals or accommodating participants with children.\nSupporting the moderator in managing the session’s timing.\n\n\n\n\nTable 2: Principles of focus group moderation\n\n\n\n\n\n\n\n\n\nActivity\nDescription\n\n\n\n\nShow interest in participants\nAs a moderator, it’s important to show respect and genuine interest in each participant’s contributions. Recognize that everyone has valuable knowledge, regardless of their education level, experience or background. Acknowledge contributions with expressions such as “Thank you for sharing that” or “That’s a very interesting point.” Address participants by their first name or their chosen pseudonym.\n\n\nAvoid assumptions\nDo not assume that the concepts or ideas expressed by the participants are obvious. Avoid taking for granted the meaning of any idea, concept, or expression. For example: In a focus group with Venezuelan migrants, the expression “chamo” comes up. If you do not know this word, you should ask the participants directly what they are referring to with that word.\n\n\nGenerate empathy with participants\nTry to generate an empathetic connection with the focus group attendees, as this will help them feel safe and valued in sharing their emotions and experiences. By creating a non-judgmental environment, participants may feel more comfortable speaking honestly and openly. Repeat or summarize participants’ comments to show that you understand their perspectives. Be patient. Do not rush the answers. Allow participants to take their time to think and respond.\n\n\nBe a moderator, not a participant\nThe moderator’s role is to guide the conversation, not to be part of it or share personal views. Some moderators assume that sharing personal experiences will encourage a greater exchange of ideas among participants. However, this practice can induce bias and affect the conversation’s overall flow.\n\n\nBe prepared to listen to different opinions and control your reactions\nThe moderator is not impartial, no matter how hard they try. It is important to identify your own biases and seek to contain personal assessments of the various opinions that may come from the participants. Avoid making value judgments about the testimonies and responses of the attendees. It’s important to be mindful of your reactions, as even small responses like nodding or giving short positive feedback such as “I think so too” or “You are right” can inadvertently influence the discussion. These reactions can induce social desirability bias, potentially altering the participants’ responses and the overall dynamics of the discussion.\n\n\nUse your talents\nIdentify your talents and use those that build trust and encourage conversation among participants. Make a list of your skills and talents. Think about what you do well and how these talents can be useful in the context of a focus group.\n\n\nAsk follow-up questions\nAsking follow-up questions allows for a deeper exploration of participant’s responses. This is essential to understand not only what people think, but why they think the way they do.\n\n\n\n\n\n\n\n\nPotential challenges during a focus group\nThere are situations that could take place during a focus group that you should be prepared for. Here are some examples:\n\n\n\n\n\n\nEmotional overflow from participants\n\n\n\n\n\nManaging emotions can be one of the most complex challenges during a focus group, especially when discussions touch on intense or personal topics. Allow participants to express their emotions, but guide them constructively. Ask how they feel and why, and look for ways to channel those emotions into the discussion. If a person is emotionally affected by an event, ask them if they wish to continue the activity and remind them that participation is voluntary. If emotions disrupt the session, take a short break and show understanding and support. In accordance with research protocols, provide relevant mental health care resources that may be useful for the participants. If the issues to be addressed during the focus group sessions are sensitive, it is desirable for the field team to have a course or training on psychological first aid.\n\n\n\n\n\n\n\n\n\nResistance to recording\n\n\n\n\n\nSome participants may not agree with the recording of their testimonies. If this happens, take into account the following recommendations. If this is the case, emphasize confidentiality, anonymity, and privacy of the data. Remind participants that during the analysis of the information, no personal data of any participant will be added. If you do not obtain authorization to record the session, take notes on topics of conversation, interactions between participants, and other relevant data.\n\n\n\n\n\n\n\n\n\nConversation diversion\n\n\n\n\n\nWhile deviations from the central theme can sometimes provide valuable insights, it’s necessary to steer the conversation back to the research objectives when it strays too far. During the participants’ interventions, ask follow-up questions that allow you to close the ideas and/or redirect them to the research objectives.\n\n\n\n\n\n\n\n\n\nParticipants trying to dominate the conversation\n\n\n\n\n\nOccasionally, some participants may attempt to dominate the discussion, overshadowing more reserved participants. Set ground rules at the start of the session regarding the length of contributions. Identify strategies for asking participants to close their ideas when they are too long. For example, you can use an eye-catching object like a signaling paddle to get participants to finish their contributions.\n\n\n\n\n\n\n\n\n\nParticipants who are shy or reluctant to participate\n\n\n\n\n\nSome participants are too shy to participate or are pushed aside by those who seek to dominate the conversation. In these cases, you must control the situation so everyone can join the conversation. Use “icebreaker” activities at the beginning of the session in which everyone participates. Directly address less active attendees with open-ended questions that encourage them to express their thoughts.\n\n\n\n\n\n\n\n\n\nPolarization of the conversation\n\n\n\n\n\nSome topics may have one side polarization on the group discussion, leading to an “excessive consensus” where some participants may hesitate to contradict the dominant view on certain topics. This can limit the diversity of perspectives and affect data quality. Emphasize that all viewpoints are valuable and that there are no right or wrong answers. Divide the group into smaller subgroups to discuss certain topics, then reconvene to share different perspectives. Limit speaking time to prevent any one participant from monopolizing the discussion. If the conversation becomes hostile, remind the group of the activity’s purpose and, if necessary, pause the session.\n\n\n\n\n\nFrequent mistakes during moderation\nWhen conducting focus groups, it is important to avoid common mistakes that can compromise the effectiveness of the session and the quality of the collected data. Some of the most critical mistakes are described here:\n\n\n\nFigure 1. Common mistakes made when conducting focus groups",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#after-the-focus-group",
    "href": "data-collection/qualitative-methods/focus-groups.html#after-the-focus-group",
    "title": "Conducting Focus Groups",
    "section": "After the focus group",
    "text": "After the focus group\nThe focus group session ends when all research topics have been covered and no new data or relevant information is obtained; the research objectives have been achieved, collecting the quantity and quality of data needed to answer the research questions, or when time and resources have reached their limits. To close the work session, it is recommended to (i) offer space for reflection in which participants can express comments, suggestions, or questions about what happened in the focus group; (ii) thank the participants for their time and willingness to participate, emphasizing that the opinions and information provided are of great importance for the study or research being conducted; and (iii) close the data flow, prioritizing the safe storage of the recording of the research activity. Some of the moderator’s responbibilites in this phase include:\n\nSupport data flow closure and secure storage of information.\nProvide the notes taken to the moderator.\nEnsure that all equipment used (tape recorders, computers, microphones, etc.) is complete.\n\nAt the end of the focus group, it is extremely important to document the information obtained in detail. The lack of initial documentation products risks all information processing components and, thus, the quality of the obtained data. How this documentation is done is a decision linked to the research design and is determined before fieldwork begins. Information should be recorded promptly, as soon as the focus group concludes, to prevent the loss of crucial details. This immediate action is vital to the research process. In addition, the products derived from the focus group must follow information storage protocols, which may include anonymization and encryption to avoid compromising the confidentiality of participants. Examples of products you can use for this purpose are:\n\nFull transcripts of the discussions\nDetailed notes taken during the research activity\nField notes\nField diaries",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#online-focus-groups",
    "href": "data-collection/qualitative-methods/focus-groups.html#online-focus-groups",
    "title": "Conducting Focus Groups",
    "section": "Online focus groups",
    "text": "Online focus groups\nVirtual focus groups are a viable alternative when in-person sessions are not possible due to factors like distance, time, or budget constraints. While the virtual format shares many characteristics with in-person focus groups, including preparation and moderation activities, it also presents unique challenges that require specific attention.\n\nPotential challenges of online focus groups\n\n\n\n\n\n\nLow interaction\n\n\n\n\n\nVirtual settings can reduce interaction due to participants’ inability to read body language and challenges in responding in real time. Adapt icebreakers to virtual environments. Use activities that promote group dynamics and interaction. Encourage people to keep their cameras turned on. Try to schedule fewer participants, in order to focus attention on the attendees. Manage short conversational scripts as virtual environments may limit direct communication, which could result in skipping sections and/or questions.\n\n\n\n\n\n\n\n\n\nConnectivity problems\n\n\n\n\n\nConnectivity issues may cause partial or complete interruptions in participants’ involvement. Validate participants’ internet connection before scheduling. Provide necessary support, such as data recharges, to ensure participation. Avoid imposing any costs on participants for participating.\n\n\n\n\n\n\n\n\n\nLack of knowledge of the video call platform\n\n\n\n\n\nSome participants may struggle with connecting to and navigating the chosen platform due to unfamiliarity with digital tools. During the scheduling, offer training on how to use the platform on which the activity will be carried out, for those who need assistance.\n\n\n\n\n\n\n\n\n\nLack of privacy\n\n\n\n\n\nSome participants may take the video call in shared spaces. This situation may place participants in uncomfortable or risky situations, depending on the sensitivity of the topics. During the scheduling, ask the participants directly (1) where they will take the interview, (2) who might listen to you, and (3) if they feel safe having the interview under these conditions. Based on the above, assess whether it is convenient for certain people to participate in the study under these conditions. If people cannot find a private space and sensitive or confidential topics are handled, we recommend not including that participant in the focus group. And evaluate interviewing this person in a different setting.\n\n\n\n\n\n\n\n\n\nDistractions and lack of focus\n\n\n\n\n\nParticipants may be distracted by other duties or social media during the session, affecting their concentration and participation. Suggest that people have their cameras turned on. Emphasize the need for full attention and engagement during the session.\n\n\n\n\n\n\n\n\n\nFatigue due to constant use of screens\n\n\n\n\n\nProlonged screen time can lead to fatigue, affecting the focus and energy of both moderators and participants. Schedule breaks during long sessions. Limit the duration of each session to a reasonable time, approximately one (1) hour. Plan multiple sessions if needed.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#a-practical-guide-for-conducting-focus-groups",
    "href": "data-collection/qualitative-methods/focus-groups.html#a-practical-guide-for-conducting-focus-groups",
    "title": "Conducting Focus Groups",
    "section": "A Practical Guide for Conducting Focus Groups",
    "text": "A Practical Guide for Conducting Focus Groups\nThe content in this resource was adapted from IPA Colombia’s “Practical Guide for Conducting Focus Groups” (see PDF document below). This practical guide provides an overview of how to conduct focus groups for qualitative data collection in the context of public policy design and evaluation of social programs. The guide includes a definition of this specific data collection technique, the purpose and benefits of using this technique, recommendations and steps-by-step instructions for implementation, and real-world applications.\n\n\nUnable to display PDF file. Download instead.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/focus-groups.html#footnotes",
    "href": "data-collection/qualitative-methods/focus-groups.html#footnotes",
    "title": "Conducting Focus Groups",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nKitzinger, J. (1999). Qualitative Research: Introducing focus groups. BMJ, 311, 299-302. https://doi.org/10.1136/bmj.311.7000.299↩︎\nKitzinger, J. (1994). The methodology of focus groups: The importance of interaction between research participants. Sociology of Health & Illness, 16(1), 106.↩︎\nKitzinger, J. (1994). The methodology of focus groups: The importance of interaction between research participants. Sociology of Health & Illness, 16(1), 110.↩︎\nKitzinger, J. (1994). The methodology of focus groups: The importance of interaction between research participants. Sociology of Health & Illness, 16(1), 110.↩︎\nKrueger, R. A. (1998). Moderating focus groups. SAGE Publications.↩︎",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "Focus Groups"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/intro-qual-methods.html#about-qualitative-research",
    "href": "data-collection/qualitative-methods/intro-qual-methods.html#about-qualitative-research",
    "title": "About Qualitative Methods",
    "section": "About qualitative research",
    "text": "About qualitative research\nQualitative research methods are tools for exploring the how and why behind human actions, decisions, and experiences. Unlike quantitative approaches, which focus on numbers and statistical trends, qualitative methods delve into words, narratives, and visual data to uncover rich, contextual insights. These methods are particularly valuable for understanding the complexities of poverty and the effectiveness of interventions.\nAddressing poverty is about more than measuring income or access to resources; it’s about understanding the underlying social, cultural, and psychological factors that perpetuate it. Qualitative methods help us:\n\nUnderstand Context: Explore how local norms, values, and practices influence the impact of programs.\nAmplify Voices: Capture the perspectives of marginalized groups who are often overlooked in traditional studies.\nDesign Better Interventions: Use insights to tailor programs that meet the specific needs of target populations.\nEvaluate Impact: Unpack the mechanisms behind why interventions succeed or fail.\n\n\n\n\n\n\n\nQualitative research at IPA\n\n\n\nAt IPA, qualitative research plays a vital role in designing, implementing, and evaluating programs aimed at reducing poverty. Here are some examples:\n\nFinancial Inclusion Studies: Interviews and focus groups with low-income individuals to understand barriers to saving, borrowing, and using financial products.\nEducation Interventions: Ethnographic studies in schools to explore teacher-student dynamics and identify strategies to improve learning outcomes.\nHealth Programs: In-depth interviews with caregivers and healthcare workers to assess the cultural acceptability of new health interventions.\nGender Dynamics: Case studies to explore how social norms and power structures affect women’s participation in economic programs.\n\n\n\nQualitative research doesn’t stand alone—it complements quantitative methods to create a more holistic understanding. For example, qualitative data can explain anomalies in survey results, uncover mechanisms of change in randomized controlled trials (RCTs), and provide actionable insights for scaling successful programs.\n\n\n\n\nQualitative data collection in Tumaco, Colombia, photo by German Acosta",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "About Qualitative Methods"
    ]
  },
  {
    "objectID": "data-collection/qualitative-methods/intro-qual-methods.html#a-toolkit-of-qualitative-methods",
    "href": "data-collection/qualitative-methods/intro-qual-methods.html#a-toolkit-of-qualitative-methods",
    "title": "About Qualitative Methods",
    "section": "A Toolkit of Qualitative Methods",
    "text": "A Toolkit of Qualitative Methods\nBy incorporating qualitative methods in our research, IPA ensures that our programs are not only evidence-based but also deeply rooted in the realities of the people we serve. These methods help us design innovative solutions, evaluate their effectiveness, and ultimately, contribute to a world free of poverty.\n\n\n\n\n\n\nFocus Groups\n\n\n\nFocus groups involve guided discussions with a small group of participants to explore their perceptions, opinions, and attitudes towards a specific topic. This method is useful for generating diverse perspectives and understanding group dynamics. → Learn more about focus groups\n\n\n\n\n\n\n\n\nQualitative Interviews\n\n\n\nInterviews involve one-on-one conversations between a researcher and a participant to explore individual experiences, beliefs, and motivations. This method allows for deep, personal insights and is flexible in terms of structure and depth. → Learn more about qualitative interviews.\n\n\n\n\n\n\n\n\nObservations\n\n\n\nObservational research involves systematically watching and recording behaviors and interactions in their natural settings. This method provides insights into real-world practices and social interactions that might not be captured through other methods. → Learn more about observations.\n\n\n\n\n\n\n\n\nRapid Ethnographies\n\n\n\nRapid ethnographies are short-term, intensive studies that use ethnographic techniques to quickly gather in-depth information about a community or organization. This method is particularly useful for understanding cultural contexts and identifying key issues in a limited timeframe. → Learn more about rapid ethnographies.",
    "crumbs": [
      "Data Collection",
      "Qualitative Methods",
      "About Qualitative Methods"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-data-security.html#encrypting-data-via-whatsapp-surveys",
    "href": "data-collection/whatsapp/whatsapp-data-security.html#encrypting-data-via-whatsapp-surveys",
    "title": "WhatsApp and Data Security",
    "section": "Encrypting Data via WhatsApp Surveys",
    "text": "Encrypting Data via WhatsApp Surveys\nEnsuring the security of sensitive data is crucial, especially when dealing with Personally Identifiable Information (PII). If your survey or workflow involves PII, follow these steps to implement encryption before publishing into Google Sheets:\n\nSet Up Encryption in Twilio:\n\nNavigate to “Functions/Services/Create Service” within your Twilio console.\nCreate a new service called “encrypt”.\n\n\n\n\nEncrypt Service\n\n\n\nClick on “Add Function” and paste the following code:\n\n\n Twilio Encrypt Function\n\n\n\n\n\nEncrypt configuration snapshot\n\n\n\nModify the secret_key and store it securely on your computer. Modify line 50 as it is shown in the next image.\n\n\n\n\nChange encryption key\n\n\n\nAdjust the amount and names of the variables you intend to encrypt in lines 53 and 54 as shown in the previous image.\n\n\n\nCreate an Encryption Widget in Twilio Studio Flow:\n\nJust before the function widget that publishes to Google Sheets, create a function widget for encryption.\n\n\n\n\nEncryption Widget Configuration\n\n\n\nSelect the service you created and set the environment as “UI” as shown in the previous image.\nChoose the name of the function you created and input the variables to be encrypted as function parameters.\n\n\n\n\nEncryption Widget Configuration Example\n\n\n\nUtilize the keys you want as variable names in the function code, using {widgets.widget_name.inbound.Body} as the values, as shown in the previous image.\n\n\n\nUpdate Google Sheets Publishing Function:\n\nIn the function responsible for publishing to Google Sheets, replace {widgets.variable_name.inbound.Body} with {widgets.name_of_your_encryption_widget.parsed.name_of_the_variable}\n\n\n\n\nExample of the configuration of the publish function\n\n\nBy implementing these steps, you will protect all the PII within your survey or workflow, ensuring that sensitive information remains confidential throughout the data collection.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "WhatsApp and Data Security"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-data-security.html#decrypting-data-via-whatsapp-surveys",
    "href": "data-collection/whatsapp/whatsapp-data-security.html#decrypting-data-via-whatsapp-surveys",
    "title": "WhatsApp and Data Security",
    "section": "Decrypting Data via WhatsApp Surveys",
    "text": "Decrypting Data via WhatsApp Surveys\nOnce your encrypted data is sent to Google Sheets, you’ll receive strings that may seem unintelligible. Follow these steps for decryption:\n\nDownload and Save Encrypted File:\n\nDownload the encrypted file provided.\nSave it as a .csv file into a Boxcryptor/Cryptomator location for added security. It needs to be an “X:/” route.\n\n\n\nRun Decryption Code:\n\nExecute the following Python code in the command prompt:\n\npython .\\csv_decryptor.py --encrypted_csv_path X:\\path\\to\\your\\csv\\demo.csv --list_of_columns_to_decrypt col1,col2 --secret_key your_secret_key1\n\nEnsure you replace the placeholders; here is where you can find the information needed:\n\n\nX:\\path\\to\\your\\csv\\demo.csv: The location of the encrypted dataset. Ensure this is in an “X:/” route for proper functionality.\ncol1,col2: The columns that are encrypted.\nyour_secret_key1: The secret key specified when creating the encryption function.\n\nThis process will generate a decrypted file version in the same path as the encrypted one. Following these clear steps ensures a smooth and secure decryption of your data.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "WhatsApp and Data Security"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-design.html#content-template-builder-in-twilio",
    "href": "data-collection/whatsapp/whatsapp-design.html#content-template-builder-in-twilio",
    "title": "Designing a WhatsApp Survey",
    "section": "Content Template Builder in Twilio",
    "text": "Content Template Builder in Twilio\nThe Twilio Content Template Builder allows you to create and manage message templates across multiple Twilio-supported messaging channels, including WhatsApp. This tool provides a unified framework for designing structured messages, ensuring a consistent user experience across platforms while simplifying implementation. You can find this tool in the Twilio Console under the Messaging dropdown, then Senders, and finally Content Template Builder.\n\n\n\nCreate a new content template\n\n\n\nCreating a Content Template\nTo create a new template, go to the Twilio Console and open the Content Template Builder Click “Create New”\nTemplates consist of fixed content and dynamic variables, allowing you to personalize messages with user-specific details such as names, order confirmations, or appointment times. When creating a template, you need to provide: - A template name - The template language - The Content type\n\n\nMessage Content Types in Twilio\n\ntext (Text): A standard text message containing only plain text.\nmedia (Media): A message that includes images, videos, or audio files.\nquick-reply (Quick Reply): A message with predefined response buttons for users to select from.\ncall-to-action (Call to Action): A message with buttons that direct users to a link or initiate a phone call.\nlist-picker (List Picker): A structured message that presents users with a selectable list of options.\ncard (Card): A message format that includes an image, title, description, and optional buttons for interaction.\ncard (WhatsApp Card): A WhatsApp-specific card message with rich media and interactive elements.\nauthentication (Authentication): A message type designed for sending authentication codes.\ncatalog (Catalog): A message format for showcasing multiple items in a structured catalog layout.\n\n\n\n\nNew content template\n\n\nWhatsApp requires all templates to go through a review process before they can be used. Manage your templates using the Content Template Builder. Submit templates for WhatsApp approval, monitor approval statuses, delete, or duplicate your templates.\n\n\nAdding Interactive Buttons\nThe Content Template Builder makes it easy to add interactive buttons to your templates. Buttons can be configured to: - Send quick replies with predefined responses - Dial a phone number - Redirect users to a specific link\nWe will show an example of a quick-reply template that can have buttons for an intro message.\n\n\n\nCreate buttons for a content template\n\n\n\n\nUsing Approved Templates\nOnce approved, content templates can be used to send messages via the Twilio API. The API dynamically replaces template variables with actual values before sending the message. Here’s an example of an approved WhatsApp message with interactive buttons:\n\n\n\nExample of a text with buttons",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Designing a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-design.html#widgets",
    "href": "data-collection/whatsapp/whatsapp-design.html#widgets",
    "title": "Designing a WhatsApp Survey",
    "section": "Widgets",
    "text": "Widgets\nTo create a new Twilio flow, follow these steps. First, navigate to the “Studio” section in the main navigation menu. Click on the “Create a Flow” button or the “+” icon to start creating a new flow. Provide a name and an optional description for your flow. You will then be taken to the Flow Builder, where you can visually design your flow.\n\n\n\nCreate a new Twilio flow\n\n\nOnce the flow is created, you can drag and drop widgets from the sidebar onto the canvas to build your flow, connecting them with connectors to define the conversation or logic flow. Customize each widget’s settings according to your requirements. In Twilio messaging, widgets are interactive elements or components that can be used to enhance the user experience and gather information from users. They provide a way to incorporate dynamic and engaging elements within the messaging flow. Widgets are typically used to collect user input, display options, or present interactive content.\nThe widget library is on the right side of the Flow Builder. Here you can see the four main categories:\n\nFlow control: These widgets allow you to implement conditional logic and control the flow of a conversation or process, enabling dynamic decision-making based on specific conditions or user inputs.\nVoice: These widgets facilitate the implementation of voice-based interactions, enabling functionalities such as making and receiving phone calls, playing audio prompts, gathering user input via speech recognition, and routing calls to different destinations based on conditions or logic.\nMessaging: These widgets enable the implementation of interactive messaging experiences, allowing functionalities like sending and receiving SMS, WhatsApp, and MMS messages, collecting user input, displaying options, and handling conversations in a dynamic and engaging manner.\nTools and execute code: These widgets provide developers with tools to perform actions like making API requests, executing JavaScript code, accessing external resources, and integrating custom logic into their Twilio applications, allowing for enhanced customization and flexibility in the application’s behavior.\nConnect other products: These widgets facilitate seamless integration with external services and products, enabling developers to incorporate functionalities from other platforms, such as CRM systems, databases, or third-party APIs, into their Twilio applications, expanding the capabilities and possibilities of their communication workflows.\n\n\n\n\nTwilio Flow Builder Interface\n\n\n\nTrigger Widget\nIn Twilio Studio, the “Trigger” widget is a crucial component with specific functionality. The Trigger widget initiates the execution of a Twilio Studio flow. Here’s how it works:\n\nEntry Point: The Trigger widget serves as the entry point of your Studio flow. When an event or condition occurs that should start the flow, the Trigger widget is activated.\nEvent-Based Start: The Trigger widget is often configured to start the flow based on a specific event, such as an incoming call, message, or any other trigger you define.\nConnectivity to External Systems: The Trigger widget can also be connected to external systems or services using Twilio Functions or other Twilio products. For example, you might use a Trigger to initiate a flow when receiving a webhook.\nCustom Triggers: Additionally, you can use custom triggers to initiate a flow. This involves setting up conditions within your application or system that, when met, send a request to Twilio to trigger the associated Studio flow.\nHandling Incoming Communication: Common use cases involve using the Trigger widget to handle incoming communication, such as an incoming call or message, and then guiding the flow through subsequent widgets to provide responses or perform specific actions.\n\n\n\n\nTrigger Widget Example\n\n\n\n\nMessaging Widgets\nThere are two widgets in this section: the “Send Message” and “Send and Wait for Reply” widgets. These are used for displaying content in the survey.\n\nSend Message widget: This feature allows you to send outbound messages to recipients using various channels, including SMS, WhatsApp, or other messaging services. By specifying the content, it enables efficient and personalized communication with users. The Send Message widget in Twilio establishes a unidirectional connection, where the system sends a message to a recipient without waiting for or expecting a response. It is primarily used for one-way notifications, alerts, or information dissemination.\n\n\n\n\nSend Message Widget Example\n\n\n\nSend and Wait for Reply widget: This feature allows you to send a message to a recipient and pause the flow, waiting for their response. You can specify the message content, and the flow will wait for the recipient to reply before proceeding. This facilitates interactive and dynamic conversations involving back-and-forth communication with users. The Send and Wait for Reply widget establishes a bidirectional connection, enabling interactive conversations and allowing for dynamic communication between the system and the user.\n\n\n\n\nSend & Wait Widget Example\n\n\nIn summary, the key distinction lies in the type of connection established by these widgets. The Send Message widget operates with a unidirectional connection for one-way messaging, while the Send and Wait for Reply widget establishes a bidirectional connection to enable interactive conversations by awaiting and processing user responses.\n\n\nFlow Control Widgets\nThere are three widgets in this section: the “Split Based On,” “Set Variable,” and “Run Subflow” widgets. These widgets allow you to implement conditional logic and control the flow of a conversation or process, enabling dynamic decision-making based on specific conditions or user inputs.\n\nSplit Based On: This widget enables you to dynamically split the flow of your application based on specific conditions or logic. It allows you to define multiple paths or branches within your flow, each with its own set of conditions and actions. When a message or event reaches the Split Based On widget, you can configure it to evaluate certain criteria, such as user input, variables, or data from previous steps in the flow. Based on the evaluation, the widget routes the flow to the appropriate branch that matches the condition. This widget is useful for implementing decision-making logic within your application. It enables you to create different paths or outcomes based on specific conditions, providing a way to customize the user experience, handle different scenarios, and route conversations accordingly. In this example, we are evaluating if the participant replied with a Yes or a No.\n\n\n\n\nSplit Based On Widget Example\n\n\n\nSet Variable: This widget enables the creation and assignment of variables within an application’s flow. By defining variable names and assigning values to them, developers can store and manipulate data throughout the conversation or process. These values can be constants, dynamic inputs from users or system data, or the result of calculations. The variables can then be referenced and utilized in subsequent steps of the flow, allowing for personalized and dynamic interactions. The Set Variable widget empowers developers to manage and track information, perform calculations, and make conditional decisions based on the stored values, enhancing the flexibility and customization of Twilio applications. In this case, we are creating a dummy variable that will take a value of 1 when the user replies with a Yes.\n\n\n\n\nSet Variable Widget Example\n\n\n\nRun Subflow: This widget enables the execution of separate and reusable subflows within the main flow of an application. By invoking a specific subflow and providing necessary input parameters, developers can modularize complex logic or functionality. This promotes code reusability, simplifies maintenance, and enhances flow organization. Upon executing the subflow, the control returns to the main flow, allowing for seamless integration and continuation of the application’s logic. The Run Subflow widget empowers developers to create more efficient and manageable Twilio applications by encapsulating and invoking reusable subflows as needed. In this case, we are telling Twilio to send a user to a different flow (or survey) based on their answer.\n\n\n\n\nRun Subflow Widget Example\n\n\nIn summary, the Split Based On widget enables branching based on conditions, the Set Variable widget transitions linearly with variable assignments, and the Run Subflow widget transitions back to the main flow after executing the separate subflow. You can see how they look in the following image.\n\n\nFunction Widgets\n\nRun Function widget: This feature provides a powerful capability to execute custom code or serverless functions within your Twilio application. By utilizing this widget, you can perform specific actions, implement custom logic, and seamlessly integrate external functionality into your Twilio Studio flow. Whether you need to make API calls, perform calculations, access external resources, or implement complex business logic, the “Run Function” widget enhances the capabilities of your Twilio application, allowing you to extend its functionality and customize its behavior according to your unique requirements. In this example, we use a function that waits a few seconds between questions or messages. This is very useful when you want to make the survey feel more natural and have a more human-like interaction with the user.\n\n\n\n\nRun Function Widget Example",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Designing a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-design.html#functions",
    "href": "data-collection/whatsapp/whatsapp-design.html#functions",
    "title": "Designing a WhatsApp Survey",
    "section": "Functions",
    "text": "Functions\nThere are three widgets in this section: the “Run Function,” “Make HTTP Request,” and “Add TwiML Redirect” widgets. In this section, we will focus only on the “Run Function” widget.\nTo leverage functions in Twilio, you can write them in JavaScript or any supported language of your choice. These functions can be triggered within a Twilio Studio flow using either the “HTTP Request” or “Run Function” widgets. By incorporating the “Run Function” widget, you can execute custom code or serverless functions, enabling you to perform specific actions and implement customized logic tailored to your Twilio application. This integration of functions seamlessly merges external functionality, enhancing the capabilities of your Twilio Studio flow and empowering you to create dynamic and powerful communication experiences.\n\nWait Function\nThe Wait function creates a pause in the flow execution, allowing for a more natural experience for the respondent. By introducing pauses between questions or messages, the Wait function gives respondents sufficient time to read and comprehend lengthy text in the survey. This helps to ensure a smooth and user-friendly survey interaction, allowing respondents to fully engage with the content and provide thoughtful responses. Let’s create this function in Twilio.\n\nNavigate to Functions and Assets: Go to the Twilio Console and locate the “Functions and Assets” section.\nAccess the Services Tab: Within “Functions and Assets,” click on the “Services” tab to manage your services.\n\n\n\n\nAccess the Services Tab\n\n\n\nCreate a New Service: Click on the option to create a new service. Name this new service “functions.”\n\n\n\n\nCreate a New Service\n\n\n\nCreate a New Function: Inside the “functions” service, select the option to create a new function.\nName the Function: When prompted to name the function, enter “wait.”\n\n\n\n\nName the Function\n\n\n\nPaste the Code: Within the “wait” function, paste the following lines of code.\n\nexports.handler = function(context, event, callback) { &lt;br&gt;\n setTimeout(function() { &lt;br&gt;\n return callback(null, null) &lt;br&gt;\n  }, 1000) &lt;br&gt;\n}\n\nSave the Function: Save the function after pasting the code to ensure your changes are preserved.\nDependencies: Click on the dependency configuration and select the “Node.js v16” option.\nDeploy the Service: Once the function is saved, deploy the entire service to make the changes effective.\n\nBy following these steps, you’ll successfully create a Wait function inside the Twilio platform.\n\n\nGSheet Publish Function\nThe GSheet Publish function in Twilio facilitates the transmission of participant responses to a Google Sheet, enabling you to effectively track and manage the collected data. By utilizing this function, the responses provided by participants are seamlessly sent to a designated Google Sheet, ensuring easy access to the data for analysis and tracking purposes. This functionality greatly streamlines the process of gathering and organizing responses, allowing you to efficiently monitor and manage the collected information within a familiar spreadsheet format.\nThis function will be covered in detail in the Whatsapp survey deploy section.\n\n\nEncrypt Function\nThe Encrypt function is designed to encrypt variables, ensuring that sensitive information, such as personally identifiable information (PII), remains secure when data is stored or published. By encrypting the variables, the values are transformed into a secure format, protecting them from unauthorized access or exposure. This functionality is crucial for safeguarding sensitive information and maintaining the privacy and confidentiality of user data within the server. The Encrypt function provides a robust layer of security to prevent the public disclosure of sensitive data.\nThis function will be covered in detail in the Whatsapp data security section.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Designing a WhatsApp Survey"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#overview-of-twilio-as-a-tool",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#overview-of-twilio-as-a-tool",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Overview of Twilio as a Tool",
    "text": "Overview of Twilio as a Tool\nTwilio is a versatile cloud communications platform that enables developers and organizations to build, scale, and operate communication solutions across various channels, including SMS, voice, video, email, and WhatsApp. Its robust APIs and user-friendly interface make it a preferred choice for integrating communication functionalities into applications and workflows.\n\nWhy Choose Twilio Over Alternatives?\nWhile there are several alternatives like EngageSpark, Twilio stands out due to its:\n\nScalability: Twilio’s infrastructure is designed to handle high volumes of communication, making it suitable for both small-scale and enterprise-level projects.\nFlexibility: With support for multiple communication channels, Twilio allows seamless integration across platforms, enabling organizations to diversify their outreach strategies.\nDeveloper-Friendly APIs: Twilio provides comprehensive documentation and SDKs, making it easier for developers to implement and customize solutions.\nGlobal Reach: Twilio’s extensive network ensures reliable communication across regions, with localized support for various countries.\nAdvanced Features: Features like real-time analytics, message tracking, and two-way communication enhance the overall user experience.\nCost-Effectiveness: Twilio’s pay-as-you-go pricing model ensures that organizations only pay for what they use, making it a budget-friendly option.\n\nIn comparison, EngageSpark, while user-friendly, is more limited in terms of scalability, advanced features, and integration capabilities. Twilio’s robust ecosystem and flexibility make it a more comprehensive solution for organizations looking to implement sophisticated communication workflows.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#twilio-for-whatsapp-surveys",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#twilio-for-whatsapp-surveys",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Twilio for WhatsApp Surveys",
    "text": "Twilio for WhatsApp Surveys\nIn today’s digital age, reaching out to participants through efficient and reliable communication channels is crucial for data collection and engagement. WhatsApp, with its widespread usage and user-friendly interface, presents an excellent platform for conducting surveys. Twilio, a cloud communications platform, offers robust tools and APIs to integrate WhatsApp into your survey workflows seamlessly.\nBy leveraging Twilio’s capabilities, researchers and organizations can automate survey distribution, track responses in real-time, and ensure higher engagement rates. This guide will walk you through the process of setting up Twilio for WhatsApp surveys, providing practical insights into its implementation and pricing considerations.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#key-twilio-concepts-for-whatsapp-surveys",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#key-twilio-concepts-for-whatsapp-surveys",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Key Twilio Concepts for WhatsApp Surveys",
    "text": "Key Twilio Concepts for WhatsApp Surveys\nTo effectively use Twilio for WhatsApp surveys, it’s important to understand the following key concepts:\n\nTwilio Console: The centralized interface where users manage and control various Twilio services. It is the primary dashboard for configuring, monitoring, and optimizing communication functionalities.\nWhatsApp Functionality: Enhanced communication capabilities unlocked by upgrading a Twilio account. This includes leveraging WhatsApp for surveys and other interactive communication.\nWhatsApp Sender Management: Within the Twilio Console, users manage WhatsApp senders through the “Messaging” section. This functionality provides oversight and control over sender-related activities.\nAPI Access Request: Users can create new senders within the Twilio Console, request access to the WhatsApp API, and submit necessary information for approval. This process enables integration with WhatsApp services.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#setting-up-a-twilio-console",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#setting-up-a-twilio-console",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Setting up a Twilio Console",
    "text": "Setting up a Twilio Console\nFollow these steps to set up a Twilio console for WhatsApp data collection:\n\nGo to the Twilio website and sign up for a new account. Provide the required information and complete the registration process.\nAfter signing up, log in to your Twilio account. Verify your email and log in.\n\n\n\n\nTwilio setup and login\n\n\n\nOnce logged in, navigate to the Twilio Console, the main dashboard for managing your Twilio services.\nClick on the “Phone Numbers” dropdown in the top-left corner and select “Manage.” Then select “Buy a number” and pick a phone number in the required location.\n\n\n\n\nBuying a phone number in the Twilio Console\n\n\n\nUpgrade the account to access WhatsApp functionalities.\n\n\n\n\nUpgrading the Twilio Console",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#twilio-pricing-and-fees",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#twilio-pricing-and-fees",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Twilio Pricing and Fees",
    "text": "Twilio Pricing and Fees\nUnderstanding Twilio’s pricing structure is crucial for budgeting WhatsApp survey projects. Below are the key pricing details:\nFor the most up-to-date and detailed pricing information, visit the Twilio WhatsApp Pricing Page. If you are planning to conduct a WhatsApp survey, consider using the calculations included on the Twilio page to estimate your costs accurately.\n\nConversation initiation cost: USD 0.010 per 24 hours\nUser-initiated conversation cost: USD 0.006 per 24 hours\nFixed monthly cost per WhatsApp number: USD 1.00\nCost per message sent: USD 0.005\n\nThese prices might vary depending on the region where the survey is going to take place.\nTwilio requires purchasing a phone number, and automatic top-ups are enabled by default to ensure service continuity.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#verifying-your-twilio-console",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#verifying-your-twilio-console",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Verifying Your Twilio Console",
    "text": "Verifying Your Twilio Console\nThe Twilio console verification process takes approximately one week. Once approved, you can proceed with setting up your WhatsApp profile.\n\nNavigate to “Messaging” in the Console and select the “Senders” tab to view WhatsApp senders.\nClick on “Create New Sender” and fill out the necessary fields, selecting the purchased phone number.\nSubmit the request for WhatsApp API access.\n\n\n\n\nCreate a new WhastApp sender\n\n\nFor increased trust and improved response rates, consider Meta Business Verification to obtain a green tick for your WhatsApp sender.",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-collection/whatsapp/whatsapp-surveys-twilio.html#creating-a-whatsapp-profile",
    "href": "data-collection/whatsapp/whatsapp-surveys-twilio.html#creating-a-whatsapp-profile",
    "title": "Setting up Twilio for WhatsApp Surveys",
    "section": "Creating a WhatsApp Profile",
    "text": "Creating a WhatsApp Profile\nFinalize your Twilio setup by configuring your WhatsApp profile:\n\nNavigate to the created sender and update the profile with an image, name, and description.\nSave changes and start your first WhatsApp survey.\n\n\n\n\nCreate a new WhastApp profile",
    "crumbs": [
      "Data Collection",
      "WhatsApp Surveys",
      "Twilio Setup"
    ]
  },
  {
    "objectID": "data-quality/aea-registry.html#what-is-the-aea-rct-registry-and-why-is-it-important",
    "href": "data-quality/aea-registry.html#what-is-the-aea-rct-registry-and-why-is-it-important",
    "title": "AEA RCT Registry",
    "section": "What is the AEA RCT Registry and why is it important?",
    "text": "What is the AEA RCT Registry and why is it important?\nThe AEA RCT Registry is a website for registering RCTs in the social sciences, established by the American Economics Association. It is important because it combats publication bias by providing a public record of the study. Pre-registration is a long-standing requirement in the medical community (e.g., for FDA approval, for publication in medical journals), and it is increasingly becoming a focus in the social sciences as well.\n\nHow to create an account on the AEA RCT Registry website\n\nCreate an account at: AEA RCT Registry Signup.\nFill in your first and last name, organization name, contact number, email, and location.\nFollow the automated prompt to confirm your email.\nOnce confirmed, log in and register trials.\n\n\n\nHow to create a trial on behalf of someone else (i.e., you are not the ‘lead’ investigator or Primary Investigator)\n\nLog in to your AEA Registry account.\nCreate a trial from the main page by clicking on “Register a Trial.”\nFill out the required fields (highlighted in red) and any other available study information.\nUpload a pre-analysis plan (optional, can be added later).\nWhen ready for the PI to review the trial, add them as a collaborator:\n\nFrom the draft trial main page, click the “Manage Collaborator” button (orange, upper right corner).\nAdd collaborators using their registered email address.\n\n\n\n\nManaging Collaborators\n\nClick the “Add Collaborator” field and enter each person’s registered email.\nScroll down and press “Save.”\nChange the email in the ‘Primary Investigator’ field from your email to the PI’s email via the dropdown menu.\nThe “Trial Information” page will update automatically with the assigned PI.\n\n\n\n\n\nWhat to do before clicking the “Register Trial” button\n\nHave the PI review the draft registration for accuracy and completeness.\nMake any necessary modifications.\nClick the “Register Trial” button to finalize registration.\n\n\n\nWhat happens once my trial reaches its “Trial End Date” in the registry?\n\nThe registry system uses the end date to remind PIs to update the trial and to publish hidden fields via an automated email.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "AEA Registry"
    ]
  },
  {
    "objectID": "data-quality/aea-registry.html#draft-email-templates-to-pis",
    "href": "data-quality/aea-registry.html#draft-email-templates-to-pis",
    "title": "AEA RCT Registry",
    "section": "Draft Email Templates to PIs",
    "text": "Draft Email Templates to PIs\n\n\n\n\n\n\nDraft email for a PI with an Existing Account\n\n\n\n\n\nDear [-PI name-], I have created a draft registration for your trial “[-trial name-]” in the AEA RCT Registry (https://www.socialscienceregistry.org). For the draft, I was able to complete most of the required fields by reviewing your [-name of documents-], but there is still some information that is missing. Before the trial can be officially registered, you must add the following information: [-list what is missing for mandatory fields-]\nTo complete registration, please log in and:\n\nReview the draft registration at [-direct link here-], checking for accuracy, and any additional information you may want to include.\nMake any necessary changes or modifications.\nClick the “Register Trial” button to complete the registration.\n\nLet me know if you have any questions. I am adding you to this trial right now, so you should receive an automated email from the registry system.\nBest regards, [-Your name-]\n\n\n\n\n\n\n\n\n\nDraft email for a new PI\n\n\n\n\n\nDear [-PI name-], In an effort to register IPA projects in the American Economic Association’s registry for randomized controlled trials (https://www.socialscienceregistry.org), I have drafted a registration for your trial “[-trial name-].” Before the trial can be officially registered and first reviewed by you, please create an account at: https://www.socialscienceregistry.org/users/sign_up and then follow the prompt to confirm your email. Once you have an account, I can add you as a collaborator to review and publish this trial.\nLet me know if you have any questions.\nBest regards, [-Your name-]",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "AEA Registry"
    ]
  },
  {
    "objectID": "data-quality/bench-testing.html#what-is-bench-testing",
    "href": "data-quality/bench-testing.html#what-is-bench-testing",
    "title": "Bench Testing",
    "section": "What is Bench testing?",
    "text": "What is Bench testing?\nBench testing is the process of thoroughly testing a survey to ensure that it functions correctly and as intended. This involves checking for skip logic issues, verifying that all questions are displayed appropriately, and ensuring that the survey flows smoothly from start to finish. Bench testing helps identify and fix any potential problems before the survey is administered to respondents, thereby improving data quality and reliability.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Bench Testing"
    ]
  },
  {
    "objectID": "data-quality/bench-testing.html#bench-testing-priorities",
    "href": "data-quality/bench-testing.html#bench-testing-priorities",
    "title": "Bench Testing",
    "section": "Bench Testing Priorities",
    "text": "Bench Testing Priorities\nBench testing simulates different response scenarios to verify that your programmed survey works as intended. A thorough bench test involves systematically reviewing each question while considering these key aspects:\n\nSurvey Flow: Does the survey run smoothly from start to finish in all scenarios?\nResponse Options: Are all possible answers covered, including “don’t know” and “refuse”?\nNumeric Constraints: Are appropriate limits set for numeric inputs?\nSkip Logic: Does the branching logic work correctly? Are questions showing or hiding as intended?\nEnumerator Guidance: Are hints provided where needed to ensure consistent question delivery?\n\nThe technical review of SurveyCTO xlsform code should focus on:\n\nChoice Lists: Check for duplicate or overlapping options\nVariable Names: Ensure they’re under 32 characters (shorter in repeat groups)\nBest Practices: Verify compliance with SurveyCTO standards (rosters, audits, etc.)",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Bench Testing"
    ]
  },
  {
    "objectID": "data-quality/bench-testing.html#how-to-bench-test",
    "href": "data-quality/bench-testing.html#how-to-bench-test",
    "title": "Bench Testing",
    "section": "How to Bench Test",
    "text": "How to Bench Test\nEffective bench testing requires input from multiple team members and should be an ongoing process throughout survey development.\n\nIn the Office\nKey resources for office testing include:\n\nField managers\nResearch assistants\nProject managers\nAvailable enumerators\nFresh eyes from other teams\n\nUsing SurveyCTO’s “Test” feature allows you to: - Simulate different scenarios without submitting data - Save progress for various respondent profiles - Review constraints and skip logic in real-time - Quickly switch between testing and editing\n\n\nDuring Enumerator Training\nEnumerator training provides a crucial opportunity for final survey validation:\n\nQuality Feedback: Enumerators can identify:\n\nUnclear wording\nMissing answer options\nConstraint issues\nSkip logic problems\n\nRole-Playing Benefits:\n\nCreates realistic testing scenarios\nGenerates dummy data for analysis\nHelps standardize question delivery\nFamiliarizes enumerators with the survey flow\n\n\nAs enumerators inevitably find issues and bugs within the survey, be sure to write these down and track all changes. One solution is to include the “comments” field type in SurveyCTO. SurveyCTO forms allow for a “comments” field type, where enumerators can add comments to survey questions while administering a survey. In order to use this, include a “comments” field type, and name the variable. See the example below:\n\n\n\nComments field type\n\n\nThis field type creates an option for every question in the survey where enumerators can comment on the question. This can include survey logic issues, missing options, confusing wording, or any other issues an enumerator has with a question. It appears next to other options as a pencil while administering the survey:\n \nAny comments collected through this comments feature will be exported as media files, similar to audio audits or images, with their directory under the variable name that you assigned to the comments field type. For this example, they would appear under the variable q_comments. IPA’s Data Management System includes the command -ipacheckcomment-, which compiles these files into a summary sheet in the outputs. There is also a user-written Stata command named -remedia- that helps quickly rename and move media files.\nThis feature helps catch issues while the survey is being administered to quickly change them during data collection. Once you have dummy data from enumerator training or other types of bench testing, it is important to run your entire data flow to test your checks and inspect the format of your data before the survey enters the field.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Bench Testing"
    ]
  },
  {
    "objectID": "data-quality/data-integrity.html#what-is-the-data-integrity",
    "href": "data-quality/data-integrity.html#what-is-the-data-integrity",
    "title": "Data Integrity",
    "section": "What is the Data Integrity?",
    "text": "What is the Data Integrity?\nEnsuring data integrity and security is crucial for high-quality research. This involves verifying data accuracy through Double Entry, protecting against loss by Maintaining Data Backups, and ensuring secure access by Storing Files on Box. Adopting these best practices minimizes errors, preserves data, and promotes reliability.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Integrity"
    ]
  },
  {
    "objectID": "data-quality/data-integrity.html#double-entry",
    "href": "data-quality/data-integrity.html#double-entry",
    "title": "Data Integrity",
    "section": "Double Entry",
    "text": "Double Entry\nDefinition: Double entry is a method where data is entered twice independently and then compared to detect discrepancies.\nSteps:\n\nInitial Data Entry: Enumerators or data clerks enter data from source documents into the database.\nSecond Independent Entry: A different person re-enters the same data into a separate database.\nComparison & Validation: The two datasets are compared to identify inconsistencies.\nError Resolution: Discrepancies are reviewed and corrected using the original source.\n\nWhy it Matters:\n\nReduces human error in manual data entry.\nEnsures higher accuracy and reliability of data.\nEssential for sensitive data where precision is critical.\n\nBest Practices:\n\nUse automated comparison tools to speed up validation.\nTrain staff on accurate data entry techniques.\nImplement a tracking system to monitor common errors.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Integrity"
    ]
  },
  {
    "objectID": "data-quality/data-integrity.html#maintaining-data-backups",
    "href": "data-quality/data-integrity.html#maintaining-data-backups",
    "title": "Data Integrity",
    "section": "Maintaining Data Backups",
    "text": "Maintaining Data Backups\nDefinition: A backup is a copy of data stored separately to protect against accidental loss, corruption, or hardware failure.\nSteps:\n\nAutomated Backups: Schedule automatic backups at regular intervals.\nMultiple Storage Locations: Store backups in at least two locations (e.g., cloud and external drive).\nVersion Control: Maintain different versions of files to recover previous states.\nRegular Testing: Periodically restore files to ensure backups are functional.\n\nWhy it Matters:\n\nPrevents loss of critical research data.\nEnsures continuity in case of system failure.\nProtects against accidental deletions and cyber threats.\n\nBest Practices:\n\nUse encrypted backups to secure sensitive data.\nFollow the 3-2-1 rule: Keep 3 copies of data, on 2 different media, with 1 copy offsite.\nDocument backup procedures for easy recovery.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Integrity"
    ]
  },
  {
    "objectID": "data-quality/data-integrity.html#storing-files-on-box",
    "href": "data-quality/data-integrity.html#storing-files-on-box",
    "title": "Data Integrity",
    "section": "Storing Files on Box",
    "text": "Storing Files on Box\nDefinition: Box is a secure cloud storage platform that allows teams to store, access, and share files efficiently.\nSteps:\n\nUpload Files to Box: Organize files into appropriate folders.\nSet Access Permissions: Restrict access based on roles (e.g., view-only, edit, admin).\nEnable File Versioning: Maintain previous versions to track changes.\nUse Encryption & Two-Factor Authentication (2FA): Enhance data security.\n\nWhy it Matters:\n\nProvides secure storage with controlled access.\nFacilitates team collaboration with real-time file sharing.\nEnsures compliance with data protection policies.\n\nBest Practices:\n\nRegularly audit file permissions and access logs.\nUse Box Sync or Box Drive for seamless integration with local storage.\nSet up automated alerts for unauthorized access attempts.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Integrity"
    ]
  },
  {
    "objectID": "data-quality/dqap.html#what-is-the-data-quality-action-plan",
    "href": "data-quality/dqap.html#what-is-the-data-quality-action-plan",
    "title": "Data Quality Action Plan",
    "section": "What is the Data Quality Action Plan?",
    "text": "What is the Data Quality Action Plan?\nPreparing for data collection often involves juggling multiple tasks, which can limit the ability of research staff to fully utilize tools like the DMS 4.0. The Data Quality Action Plan (DQAP) addresses this challenge by offering a structured framework for planning and executing data quality activities. It helps teams:\n\nIdentify and resolve data quality issues.\nMaximize the use of the DMS 4.0.\nEnhance the actionability of data quality checks.\n\nThe DQAP focuses on six core data quality tasks, each designed to address specific issues during data collection. This template serves as a centralized repository for planning and tracking these activities, ensuring a comprehensive approach to data quality management.\n\n\n\nMain data quality activities",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Quality Action Plan"
    ]
  },
  {
    "objectID": "data-quality/dqap.html#purpose-of-the-dqap",
    "href": "data-quality/dqap.html#purpose-of-the-dqap",
    "title": "Data Quality Action Plan",
    "section": "Purpose of the DQAP",
    "text": "Purpose of the DQAP\nThe DQAP aims to establish a systematic approach to data quality management, with the following objectives:\n\nFacilitate Training and Tool Adoption: Provide clear guidelines for research staff to effectively plan, program, and act on data quality checks.\nEnhance Actionability: Offer actionable insights and recommendations for addressing data quality issues.\nBoost Accountability: Clearly define roles and responsibilities for Principal Investigators (PIs), Research Managers, Research Associates, and Field Managers in data quality activities.\nPromote DMS 4.0 Use: Ensure the full potential of the DMS 4.0 is leveraged in all IPA data collection initiatives.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Quality Action Plan"
    ]
  },
  {
    "objectID": "data-quality/dqap.html#the-dqap-tool",
    "href": "data-quality/dqap.html#the-dqap-tool",
    "title": "Data Quality Action Plan",
    "section": "The DQAP Tool",
    "text": "The DQAP Tool\nThe DQAP tool is a Google Sheets template with five sheets, three of which require input: DataQuality_Tasks, DMS, and Issues & Actions.\n\n\n\nMain Page of the Data Quality Action Plan\n\n\nThe DQAP template is available to IPA staff on Box. You can access it using the following link: DQAP Template on Box.\nIf you are unable to access the file, please contact Research Support at researchsupport@poverty-action.org.\n\nBelow is an overview of each sheet:\n\n\n\n\n\n\nHow-to Guide\n\n\n\n\n\nThis sheet provides step-by-step instructions for filling out the DQAP. It uses color-coding for clarity:\n\nGreen: Fields that require editing.\nBlue: Fields that should not be modified.\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\nThis sheet summarizes the finalized DQAP for sharing with PIs, Research Managers, and Field Coordinators. It highlights the active tasks and checks, ensuring alignment and accountability across the team.\n\n\n\n\n\n\n\n\n\nData Quality Tasks\n\n\n\n\n\nThis sheet outlines the eight core data quality tasks (see Figure 1). It includes:\n\nBlue Columns (Pre-filled):\n\nDescription: Explains each task.\nHow Can This Activity Help?: Describes how the task identifies issues.\nWhat Does This Activity Require?: Lists prerequisites for implementation.\n\nGreen Columns (To be filled by research staff):\n\nActivity Active in This Project?: Checkbox to indicate if the task is being used.\nWhat Will Our Project Check?: A brief description of the task’s purpose for the project.\nResources: Links to manuals and guides for implementing each task.\n\n\n\n\n\n\n\n\n\n\n\nDMS - Data Management System\n\n\n\n\n\nThis sheet details the checks available in the DMS 4.0. It includes:\n\nPre-filled Columns:\n\nGlobal do-file section: Identifies the section of the do-file to modify.\nInput File/Sheet: Specifies the input files and sheets required.\nOutput File/Sheet: Names the output files and sheets.\nDescription: Explains the purpose of each check.\nHow Can This Information Be Used?: Suggests potential uses for the output.\nRecommended Resources: Links to IPA resources.\n\nGreen Columns (To be filled by research staff):\n\nCheck Active?: Checkbox to indicate if the check is being used.\nSurvey Variables and Information for Checks: Lists variables or parameters needed for the check.\n\n\n\n\n\n\n\n\n\n\n\nIssues & Actions\n\n\n\n\n\nThis sheet serves as a reference for identifying and resolving common data quality issues. It includes:\n\nIssues:\n\nIssue Descriptions: Describes potential data quality issues.\n\nChecks:\n\nIdentifies the data quality activity or DMS output that can detect the issue.\n\nActions:\n\nProgramming Actions: Solutions for issues related to data management and cleaning.\nField Protocol Actions: Recommendations for improving enumerator performance or field logistics.\nPerson Responsible: Specifies the team member responsible for each action (editable).",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Quality Action Plan"
    ]
  },
  {
    "objectID": "data-quality/dqap.html#how-to-design-a-dqap-for-your-project",
    "href": "data-quality/dqap.html#how-to-design-a-dqap-for-your-project",
    "title": "Data Quality Action Plan",
    "section": "How to Design a DQAP for Your Project",
    "text": "How to Design a DQAP for Your Project\nFollow these steps to create a tailored DQAP for your data collection initiative:\n\nSteps for DQAP\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\n1\nCreate a copy of the DQAP template in your project’s Box folder. Keep it as a Google Sheet to preserve conditional formatting.\n\n\n2\nReview and fill out the DataQuality_Tasks sheet. Mark the tasks you plan to use and describe what will be checked.\n\n\n3\nReview and fill out the DMS sheet. Activate relevant checks and specify the required variables.\n\n\n4\nReview the Issues & Actions sheet. Filter active checks and add or modify issues and actions as needed.\n\n\n5\nAssign responsibilities for each action in the Issues & Actions sheet based on your team’s structure.\n\n\n6\nShare the finalized DQAP with your team using the Summary sheet. Gather feedback to ensure alignment and accountability.\n\n\n7\nBegin programming your DMS based on the finalized plan.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Quality Action Plan"
    ]
  },
  {
    "objectID": "data-quality/dqap.html#conclusion",
    "href": "data-quality/dqap.html#conclusion",
    "title": "Data Quality Action Plan",
    "section": "Conclusion",
    "text": "Conclusion\nThe Data Quality Action Plan (DQAP) is a powerful tool for ensuring high-quality data collection. By following this structured approach, research teams can proactively address data quality issues, maximize the use of the DMS 4.0, and ensure accountability across all stages of the data lifecycle.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Data Quality Action Plan"
    ]
  },
  {
    "objectID": "data-quality/ipa-dms.html#what-is-the-dms",
    "href": "data-quality/ipa-dms.html#what-is-the-dms",
    "title": "IPA’s Data Management System",
    "section": "What is the DMS?",
    "text": "What is the DMS?\nIPA’s Data Management System (DMS) is a Stata package that automates and assists with your project’s data flow. The DMS assists you with the following functionality:\n\nCreating folders and do-files: Automatically creates a folder structure, Stata files and documentation, including for projects with multiple surveys (e.g. creates standardized folder structure, input files, do-files and readme files)\nDeciding which quality checks are important to your project: A simple global do-file with a detailed description of the different check features as well as a section to turn on and off specific checks based on your own needs (e.g. backchecks, field comments, survey tracking, duplicates, missing values, outliers, text audits etc)\nDe-duplicating: Automatically flags all duplicates, and provides a summary of the differences of each duplicate group. Also, saves a new de-duplicated clean dataset so high-frequency checks can run.\nChecking and reporting on data quality: Runs high-frequency checks to flag issues with data quality (e.g. asks you to identify important checks and variables in the global do-file and Excel-based inputs sheets and automatically generates reports for interpretation and follow-up actions to improve data quality)\nChecking and reporting on inconsistencies in the dataset: Compares and reports on the differences in responses in the Survey & Backchecks datasets.\nCorrections to the dataset: Includes an easy-to-use excel-based tool for making and logging changes to data including replacements and values, dropping of observations and flagging HFC outliers values as correct.\nReporting on enumerator performance: Generates enumerator reports with indicators of enumerator productivity and other general enumerator performance including Don’t Know/Refuse/Missing/Other specify responses rate and summary statistics by specified variables.\nReporting on survey progress: Generates progress reports on survey completion, by day/week/month and by a customizable filter variable (e.g. progress reports by region, district, village, treatment status)",
    "crumbs": [
      "Data Quality",
      "IPA's Data Management System"
    ]
  },
  {
    "objectID": "data-quality/ipa-dms.html#how-to-install-the-dms",
    "href": "data-quality/ipa-dms.html#how-to-install-the-dms",
    "title": "IPA’s Data Management System",
    "section": "How to install the DMS?",
    "text": "How to install the DMS?\nTo use the DMS, you will need Stata 17 or above. If you do not have Stata 17 or above, click on this knowledge article on Stata to learn how to request an upgrade from IPA’s MIST team.\nIf you are installing the DMS for the first time, use this command in Stata:\nnet install ipacheck, all replace from(\"https://raw.githubusercontent.com/PovertyAction/high-frequency-checks/master\"\") replace\nipacheck update\nTo start your project’s folder structure, use:\nipacheck new, surveys(\"NAME OF SURVEY\") folder(“path/to/file/destination”)\nNote that if you do not use the folder option, the folder structure will be created in your current working directory. There is also an option to make subfolders for multiple surveys:\nipacheck new, surveys(\"Survey1\" \"Survey2\") subfolders",
    "crumbs": [
      "Data Quality",
      "IPA's Data Management System"
    ]
  },
  {
    "objectID": "data-quality/ipa-dms.html#learning-to-use-the-dms",
    "href": "data-quality/ipa-dms.html#learning-to-use-the-dms",
    "title": "IPA’s Data Management System",
    "section": "Learning to use the DMS",
    "text": "Learning to use the DMS\nThe DMS includes a practice exercise that can help you learn how to fill out the globals do-file and the input sheets of the DMS, work through the different output sheets, and make corrections. If you have already updated your ipacheck package using the code in the previous section, you can do the exercise on your computer using this code:\nipacheck new, exercise folder(\"path/to/file/destination\")\nNote that if you do not include the folder- option, the folders will be created in your current directory. This code will download the folder structure and input and replacement files as ipacheck new would, as well as: * Practice survey data (in 4_data/2_survey folder) * Sample data (in 4_data/2_survey) * Backcheck data (in 4_data/3_backcheck) * Text audit media files (in 4_data/2_survey/media) * Comment media files (in 4_data/2_survey/media) * Audio Audit files (in 4_data/2_survey/media)\nIf you already use an existing file structure, you can download the files only using:\nipacheck new, files folder(“path/to/file/destination”)\nPlease note that the folders and input structure of the DMS have changed in v4.0 so you will need to make some changes to the folder structure of do-files.",
    "crumbs": [
      "Data Quality",
      "IPA's Data Management System"
    ]
  },
  {
    "objectID": "data-quality/ipa-dms.html#adapting-the-dms-to-your-project",
    "href": "data-quality/ipa-dms.html#adapting-the-dms-to-your-project",
    "title": "IPA’s Data Management System",
    "section": "Adapting the DMS to your project",
    "text": "Adapting the DMS to your project\nTable 1 describes some of the features that comprise the DMS, and when you should incorporate them based on the stage of your IPA project(s)\n\n\n\nTable 1: Example DMS features by data collection stage Table\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nDescription\nBefore data collection\nDuring data collection\nAfter data collection\n\n\n\n\nipacheck new (Stata Command)\nCreates a folder structure and/or input files for DMS. Also used to create DMS exercise\nX\nX\n\n\n\nREADME files\nEvery folder has a readme file to list files, authors, changes, and anything necessary for a successful handover\n123\n123\n\n\n\nDMS inputs file (Excel file)\nInitializes inputs for outliers, other specify and enumerator stats checks.\n1\n1",
    "crumbs": [
      "Data Quality",
      "IPA's Data Management System"
    ]
  },
  {
    "objectID": "data-quality/ipa-dms.html#dms-4.0-training",
    "href": "data-quality/ipa-dms.html#dms-4.0-training",
    "title": "IPA’s Data Management System",
    "section": "DMS 4.0 Training",
    "text": "DMS 4.0 Training\nSee the following excerpt from the June 2022 Quarterly Data Management Call (QDMC) for a presentation and demonstration of the DMS!\n\n\n\n\n\n\n\nDo you need support with the DMS?\n\n\n\nIf your research project has limited time or capacity to set up or run the DMS, the GRDS team is available at an hourly rate to provide direct technical support to any project. You can read more about these services (What is Direct Support?), or simply email researchsupport@poverty-action.org to discuss your options. If you have configured your own DMS, and need troubleshooting support, please create a case for the GRDS team through the Global Help Desk. You can click the green button to your right that says “CONTACT SUPPORT”, or click here.\n\n\n\n\n\n\n\n\nDo you have ideas for the DMS?\n\n\n\nAnyone can email requests for new features to researchsupport@poverty-action.org – but we can’t promise that we will immediately respond. If you are a skilled coder, we would welcome contributions to our public GitHub repository. Again, email researchsupport@poverty-action.org to discuss a possible collaboration!",
    "crumbs": [
      "Data Quality",
      "IPA's Data Management System"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#why-pilot",
    "href": "data-quality/pilot-survey.html#why-pilot",
    "title": "Pilot Survey",
    "section": "Why Pilot?",
    "text": "Why Pilot?\nAs one of IPA’s Required Research Protocols (or MMDs), piloting is an essential step for which there are no shortcuts. Piloting can be used for different purposes and has numerous benefits:\n\nDesigning a New Survey or Important Module:\n\nAcquire knowledge of unknown phenomena/concepts and answer questions about the overall survey design.\n\nRefining the Content of the Survey and Improving Survey Flow:\n\nAdjust question wording and order.\nIdentify non-essential questions that can be dropped from the final version.\nIdentify common responses so they can be pre-coded.\nIdentify mistakes in translation so they can be corrected.\nPay attention to how experienced surveyors ask questions and incorporate their “conversation” into the question text for a smooth flow.\nVerify that respondents’ interest is sustained.\nVerify that interviewers and respondents are comfortable with the interview flow.\nIdentify potential hitches for the interviewer (e.g., need to repeat questions, correct misinterpretations, or record volunteered information).\n\nTesting Your Data Flow:\n\nVerify your survey programming works well using High-Frequency Checks.\nVerify your preloading from a baseline survey works well.\nCollect metadata.\nCheck the completeness of your pilot dataset.\nTest your back-check strategy and dataset using the Back Check Manual.\n\nTesting Your Field Protocols:\n\nVerify the planned timing of interviews fits respondents.\nCheck the existing infrastructure (e.g., access to electricity, internet, cell phone networks, etc.).\nEnsure your sampling, replacement protocols, and tracking strategy work well in the field.\nVerify your existing sampling frame is up to date or identify the time needed for making a listing.\nIdentify the duration and accuracy of capturing GPS locations with your devices.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-sample",
    "href": "data-quality/pilot-survey.html#pilot-sample",
    "title": "Pilot Survey",
    "section": "Pilot Sample",
    "text": "Pilot Sample\nWhen selecting your piloting sample, ensure that:\n\nThe piloting area is outside your sample area. Pilot the survey with respondents who are outside your sample but in similar neighborhoods/backgrounds (e.g., people from the same village but in different households or people from neighboring villages are good candidates).\nEvery question in every section is piloted several times. Pilot with at least 30 households if the survey contains many new questions or is administered in a new context, or 15 households if it was used before in a similar context.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-phases",
    "href": "data-quality/pilot-survey.html#pilot-phases",
    "title": "Pilot Survey",
    "section": "Pilot Phases",
    "text": "Pilot Phases\nPiloting is an iterative process, meaning surveys should be piloted each time they undergo significant changes. The complete piloting process consists of three phases:\n\nPre-pilot Phase:\n\nConducted when designing a new survey or important sections.\nStart with focus groups and qualitative interviews.\nThis phase should happen early in the piloting process (a few months before data collection) and is intended to help with survey design and demystify important phenomena.\n\n1st Pilot Phase:\n\nConducted before translating the survey.\nPilot the survey instrument yourself with a few experienced surveyors who speak the local language or dialect.\nThis phase is intended to improve the content of the survey.\n\n2nd Pilot Phase:\n\nConducted after finalizing, programming, and translating the survey.\nPilot the final translated instrument with a larger group of surveyors.\nThis phase should happen prior to enumerator training and survey launch and is intended to check the survey flow, programming, data flow, and data quality checks.\n\n\nAt a minimum, every survey must go through the 2nd phase of piloting prior to its launch, but not all surveys have to go through all three phases. Here’s a simple set of rules for piloting:\n\nPiloting Steps by Survey Type\n\n\n\n\n\n\n\n\nSurvey Type\nPre-pilot\n1st Pilot\n2nd Pilot\n\n\n\n\nBrand new survey / important module\n+\n+\n+\n\n\nExisting well-designed survey in a new location/language\n\n+\n+\n\n\nExisting well-designed survey in the same location/language (e.g., endline with small changes)\n\n\n+",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-timeline",
    "href": "data-quality/pilot-survey.html#pilot-timeline",
    "title": "Pilot Survey",
    "section": "Pilot Timeline",
    "text": "Pilot Timeline\nThe amount of time needed to pilot the survey depends on how long and how new the survey is. The newer the survey, the more piloting it requires.\n\nIf designing your survey from scratch, start pre-piloting 5-6 months before the survey launch.\nIf adapting an existing survey to a new context/language, start the 1st pilot 3-4 months before the launch.\nIf making very small changes to an existing survey for the same context/language, start the 2nd phase 4-5 weeks before the launch.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-length",
    "href": "data-quality/pilot-survey.html#pilot-length",
    "title": "Pilot Survey",
    "section": "Pilot Length",
    "text": "Pilot Length\nPiloting is an iterative process, and there is no best practice regarding the required number of iterations. Piloting is over when:\n\nThe survey flows smoothly.\nNo significant changes are needed.\nRespondents can understand all the questions.\n\nHowever, keep in mind that some questions (e.g., hypotheticals) will always require respondents to struggle, even if the question is clearly understood.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-results",
    "href": "data-quality/pilot-survey.html#pilot-results",
    "title": "Pilot Survey",
    "section": "Pilot Results",
    "text": "Pilot Results\nTo effectively use the results of piloting:\n\nTake detailed notes during piloting.\nUse these notes to make changes to your questionnaire, translation, or programming.\nDiscuss important points during enumerator training and include them in the survey manual.\n\n\nOn the Content of the Survey:\n\nReword or re-translate questions that are mistakenly interpreted by respondents.\nDrop or rephrase questions if responses show no variation.\nChange question order if respondents can guess the general hypothesis, as this may indicate biased or leading questions.\n\n\n\nOn the Flow of the Survey:\n\nShorten the survey by dropping non-essential questions if respondents or interviewers show signs of fatigue.\nMove interesting modules (e.g., games) to the middle of the survey to maintain engagement.\n\n\n\nOn the Data Flow and Field Protocols:\n\nCorrect programming mistakes (e.g., adjust relevance fields or constraints).\nUse pilot data to refine survey constraints based on reasonable responses.\nUse pilot metadata (e.g., duration) to adjust survey and field plans.\nAdjust interview timing or provide additional equipment if infrastructure issues (e.g., lack of electricity) are identified.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-vs.-false-launch",
    "href": "data-quality/pilot-survey.html#pilot-vs.-false-launch",
    "title": "Pilot Survey",
    "section": "Pilot vs. False Launch",
    "text": "Pilot vs. False Launch\nThere are two main differences between a survey pilot and a false launch:\n\nTiming: The pilot starts earlier (often during survey design) and is intended to finalize the survey’s content, translation, and programming, and check data flow and field protocols.\nAwareness: Your team is aware of the pilot. In contrast, a false launch is implemented with a final translated instrument, and the field team believes it is the first day of real data collection.\n\nWhile it is possible to organize the 2nd phase of the pilot as a false launch, this is not ideal, as piloting usually requires multiple iterations with debriefing sessions and revisions.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-vs.-soft-launch",
    "href": "data-quality/pilot-survey.html#pilot-vs.-soft-launch",
    "title": "Pilot Survey",
    "section": "Pilot vs. Soft Launch",
    "text": "Pilot vs. Soft Launch\nThere are two main differences between a survey pilot and a soft launch:\n\nTiming: The pilot starts earlier (often during survey design) and is intended to finalize the survey’s content, translation, and programming, and check data flow and field protocols.\nLocation: The pilot is implemented outside your intended sample area. In contrast, a soft launch is always implemented with a final translated instrument and in a small area within the intended sample area (i.e., part of the real data collection).",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#piloting-and-time-constraints",
    "href": "data-quality/pilot-survey.html#piloting-and-time-constraints",
    "title": "Pilot Survey",
    "section": "Piloting and Time Constraints",
    "text": "Piloting and Time Constraints\nWhat If My Team Is in a Rush and We Don’t Have Time for a Pilot? Remember, you do not have time to skip the pilot! Piloting requires effort, but it is an upfront investment that will save time and money during data collection, cleaning, and analysis. Mistakes are least costly when caught during the pilot. Moreover, piloted surveys are much likelier to result in high-quality data than non-piloted surveys. Always pilot your survey!",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "data-quality/pilot-survey.html#pilot-irb",
    "href": "data-quality/pilot-survey.html#pilot-irb",
    "title": "Pilot Survey",
    "section": "Pilot IRB",
    "text": "Pilot IRB\nWhether your pilot requires IRB approval depends on whether the activity constitutes human subjects research. Research is a systematic evaluation designed to produce generalizable knowledge.\n\nIf the pilot is refining a tool (e.g., evaluating text delivery, testing question length, finding programming errors) and the results are used to improve data quality (not as part of outcome measures), it does not require IRB approval.\nIf the pilot collects identifiable data that will be used for the study, it requires IRB approval.\n\nIf you are unsure whether your pilot activity needs IRB approval, email humansubjects@poverty-action.org.",
    "crumbs": [
      "Data Quality",
      "IPA Research Protocols",
      "Pilot Survey"
    ]
  },
  {
    "objectID": "ethics-irb/index.html",
    "href": "ethics-irb/index.html",
    "title": "About IPA IRB",
    "section": "",
    "text": "Institutional Review Boards exist to protect the rights, safety, and welfare of human subjects involved in research projects. Learn about IPA’s IRB, coverage options, meeting schedules, and fee structures.",
    "crumbs": [
      "Ethics and IPA IRB",
      "About IPA IRB"
    ]
  },
  {
    "objectID": "ethics-irb/index.html#what-is-an-institutional-review-board",
    "href": "ethics-irb/index.html#what-is-an-institutional-review-board",
    "title": "About IPA IRB",
    "section": "What is an Institutional Review Board?",
    "text": "What is an Institutional Review Board?\nAn Institutional Review Board (IRB) is a group designated by an institution (e.g., a university or non-profit) to provide ethical and regulatory oversight of research involving human subjects. An IRB reviews, monitors, and, if necessary, requires modifications to these type of studies. Made up of IRB staff and board members, its primary role is to ensure that appropriate measures are taken to protect participants’ rights, safety and welfare.\nIRBs operate based on ethical principles outlined in the Belmont Report—beneficence, respect for persons, and justice—and adhere to minimum standards set by U.S. federal regulations, including the Department of Health and Human Services Regulations (45 CFR part 46). For human subject research conducted internationally, additional local regulations and international standards apply.\n\nHuman Subjects Research\nAccording to 45 CFR part 46, human subjects research means:\n\nResearch: Systematic investigation, including research development, testing and evaluation, designed to develop or contribute to generalizable knowledge.\nHuman subject: Living individual about whom an investigator (whether a professional or student) conducting research (i) obtains information or biospecimens through intervention or interaction with the individual, and uses, studies, or analyzes the information or biospecimens; or (ii) obtains, uses, studies, analyzes, or generates identifiable private information or identifiable biospecimens.\n\n\n\n\n\n\n\nNeed help determining if your project involves Human Subjects Research?\n\n\n\nIRB approval is mandatory for human subjects research. For more information on whether your project constitutes human subjects research, please consult the Office for Human Research Protections decision charts or contact IPA IRB at humansubjects@poverty-action.org.",
    "crumbs": [
      "Ethics and IPA IRB",
      "About IPA IRB"
    ]
  },
  {
    "objectID": "ethics-irb/index.html#about-the-ipa-irb",
    "href": "ethics-irb/index.html#about-the-ipa-irb",
    "title": "About IPA IRB",
    "section": "About the IPA IRB",
    "text": "About the IPA IRB\nIn 2007, IPA established an IRB that would provide ethical oversight to international studies that were primarily randomized trials with vulnerable populations in low and middle income countries where IPA operates. This IRB is hosted by IPA and its administrative functions are handled by IPA staff, but it is independent of IPA staff, management, and researchers. The membership of the IPA IRB is diverse in affiliations and is composed of members who are external to IPA. The IRB convenes on a monthly basis.\nIRB approval is a fundamental part of IPA’s research quality protocols. IPA requires that all projects in which IPA is engaged be reviewed by a U.S. or a similar IRB institution, as well as nationally recognized (or equal) IRB in the country where the research is taking place (if such an IRB exists) before the start of any human subjects activities. When deciding how to arrange IRB coverage for an IPA project, the options are the following:\n\n\nIPA IRB: IPA IRB conducts its own review of the project.\nHealth Media Lab (HML) IRB: HML IRB may review the project in place of IPA IRB. Only projects which are minimal risk, involve no particularly sensitive questions or vulnerable subjects, and are not federally funded should submit to HML IRB.\nReliance agreement with other institution: In some cases, IRB review may be required at another institution (e.g., the PI’s university, or the institution funding the study). If you prefer that IPA IRB cedes oversight to this other institution’s IRB, we will need to set up a “reliance agreement” formally documenting this arrangement.\n\n\n\nMeeting Dates\nThe IRB at IPA convenes regularly to review non-minimal risk studies and other submissions requiring full board review. To ensure timely consideration, researchers must submit all required materials by the deadlines listed in Table 1 below. Submissions received after the deadline will be reviewed at the next available meeting. IRB meetings take place from 15:00 to 16:00 EST on the scheduled dates. Please plan accordingly to avoid delays in your study’s approval process.\n\n\n\nTable 1: IPA IRB Meeting Dates\n\n\n\n\n\n\n\n\n\nMeeting Date\nDeadline for Submission of Materials\n\n\n\n\nThursday, March 27, 2025\nFriday, March 7, 2025, COB\n\n\nThursday, April 24, 2025\nFriday, April 4, 2025, COB\n\n\nThursday, May 29, 2025\nFriday, May 9, 2025, COB\n\n\nThursday, June 26, 2025\nFriday, June 6, 2025, COB\n\n\nThursday, July 31, 2025\nFriday, July 11, 2025, COB\n\n\nThursday, August 28, 2025\nFriday, August 8, 2025, COB\n\n\nThursday, September 25, 2025\nFriday, September 5, 2025, COB\n\n\nThursday, October 30, 2025\nFriday, October 10, 2025, COB\n\n\nThursday, November 20, 2025\nFriday, October 31, 2025, COB\n\n\nThursday, December 18, 2025\nFriday, November 28, 2025, COB\n\n\n\n\n\n\n\n\nIRB Fee Schedule\nThe IPA IRB charges fees for its reviews based on the IPA IRB fee schedule. For more information on these fees, see the fee update documentation. The IRB determines these fees based on several factors. These include staff time and training costs, such as processing submissions, executing reliance agreements, advising projects and responding to questions, preparing templates and customized guidance on consent forms, and recruiting and working with Board members. They also include Board member honoraria, annual CITI organizational subscription for human subjects training, and comparison research to identify fees charged by other IRBs completed in 2024.\nResearch teams should include IRB fees in every research project’s budget. Consider discussing IRB requirements during the project development stage with your donors, PIs, and implementing partners to ensure adequate budgeting for the appropriate IRB costs.",
    "crumbs": [
      "Ethics and IPA IRB",
      "About IPA IRB"
    ]
  },
  {
    "objectID": "ethics-irb/irb-faqs.html",
    "href": "ethics-irb/irb-faqs.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Ethics and IPA IRB",
      "IRB FAQs 🚧"
    ]
  },
  {
    "objectID": "ethics-irb/irb-reliance-agreements.html#what-is-a-reliance-agreement",
    "href": "ethics-irb/irb-reliance-agreements.html#what-is-a-reliance-agreement",
    "title": "Reliance Agreements",
    "section": "What is a Reliance Agreement?",
    "text": "What is a Reliance Agreement?\nA reliance agreement is a formal, written agreement between two (or more) IRBs which enables one institution engaged in research to rely on another institution’s IRB review.\nMany research studies involve collaboration between investigators from multiple institutions which each maintain their own IRB. The advantage of a reliance agreement is that, rather than having multiple IRBs conduct their own full review of a research project, a reliance allows for only one institution to conduct a full review. This streamlines the IRB process and reduces burdens on investigators. A reliance agreement documents, in writing, the responsibilities of both the relying and reviewing institutions regarding IRB review, reporting, and oversight.",
    "crumbs": [
      "Ethics and IPA IRB",
      "Reliance Agreements"
    ]
  },
  {
    "objectID": "ethics-irb/irb-reliance-agreements.html#when-is-a-reliance-agreement-needed",
    "href": "ethics-irb/irb-reliance-agreements.html#when-is-a-reliance-agreement-needed",
    "title": "Reliance Agreements",
    "section": "When is a Reliance Agreement Needed?",
    "text": "When is a Reliance Agreement Needed?\nFor every study IPA is engaged in, IPA IRB must do one of the following:\n\nIPA IRB conducts its own review of the project\nIPA IRB sets up a “reliance agreement” to formally cede oversight of the project to another institution’s IRB.\n\nThese are the only two options. If you do not wish to submit your project to IPA IRB, it will be necessary to set up a reliance agreement with another IRB.\n\n\n\n\n\n\nWhat kinds of institutions can IPA enter reliance agreements with?\n\n\n\n\n\nIPA IRB can only enter reliance agreements with institutions that have a Federalwide Assurance (FWA). An FWA is a document held by an institution which signals that the institution has made a formal commitment to follow US federal regulations for the protection of human subjects. Most US-based university IRBs have FWAs. It is rarer for a local IRB to have an FWA, but some do. You can check whether an institution has an FWA here\n\n\n\n\n\n\n\n\n\nCan I have another IRB rely on IPA IRB instead?\n\n\n\n\n\nYes! You may wish for IPA IRB to review the project and to have another institution (e.g., the PI’s university) rely on IPA IRB’s review. In some cases, a donor, partner organization, or PI’s university may even require that IPA IRB conducts its own review of the study. (As of 2024, J-PAL requires that IPA projects receiving J-PAL funding be reviewed by IPA IRB - or HML IRB.)\n\n\n\n\n\n\n\n\n\nWhat about local IRB?\n\n\n\n\n\nIPA IRB also requires that all projects be reviewed by a local IRB in the country where research is taking place (if such an IRB exists) before human subjects activities begin.",
    "crumbs": [
      "Ethics and IPA IRB",
      "Reliance Agreements"
    ]
  },
  {
    "objectID": "ethics-irb/irb-reliance-agreements.html#setting-up-a-reliance-agreement",
    "href": "ethics-irb/irb-reliance-agreements.html#setting-up-a-reliance-agreement",
    "title": "Reliance Agreements",
    "section": "Setting up a Reliance Agreement",
    "text": "Setting up a Reliance Agreement\nAs early as possible, get in touch with both IPA IRB (humansubjects@poverty-action.org) and the other IRB you would like us to set up a reliance with. Different IRBs may have different policies about whether they are willing to enter reliances and different processes for evaluating reliance requests.\n\n\n\n\n\n\nIf you would like IPA IRB to cede oversight to another IRB…\n\n\n\n\n\nAsk the other IRB if they are willing to allow IPA IRB to rely on their review. Once the other IRB has approved the project, send an email to humansubjects@poverty-action.org with:\n\nA completed Reliance Agreement Assessment Worksheet ([link to download from IPA IRB webpage])\nThe approval letter and all approved materials (protocol, consents, surveys, etc.) from the reviewing IRB.\n\n\n\n\n\n\n\n\n\n\nWhy does IPA IRB have to review project materials if it is ceding oversight of the project?\n\n\n\n\n\nIn order to assess whether we are willing to cede review of any given project, an initial limited review of the project must be done. This is necessary as there are certain kinds of projects (e.g., those involving significant risks or very vulnerable populations) that IPA IRB may be less comfortable ceding to another IRB. We also must make sure that the other IRB to whom we are ceding will do the kind of thorough oversight IPA IRB expects and would do itself. Once a reliance is established, IPA IRB then cedes review/trusts that the other IRB will provide adequate oversight of the project from that point forward (potentially for years, depending on the length of the project) - so it is only initially that a team must go through “review” with IPA IRB.\n\n\n\n\n\n\n\n\n\nIf you would like another IRB to rely on IPA’s review…\n\n\n\n\n\nAsk the other IRB if they are willing to rely on IPA IRB’s review. Then, send an email to humansubjects@poverty-action.org with:\n\nA completed Reliance Agreement Assessment Worksheet ([link to download from IPA IRB webpage])\nIf not done already, prepare and submit an IRB application for your project for IPA IRB review.\n\n\n\n\nIf IPA IRB will cede oversight another IRB, there is a $500 fee. This can be either charged to a grant or invoiced. If another IRB will rely on IPA IRB’s review, there is no fee for the reliance agreement. However, regular IPA IRB review fees apply (for your initial application and any subsequent amendments, renewals, etc.).",
    "crumbs": [
      "Ethics and IPA IRB",
      "Reliance Agreements"
    ]
  },
  {
    "objectID": "research-design/index.html#what-is-stata",
    "href": "research-design/index.html#what-is-stata",
    "title": "Research Design",
    "section": "What is Stata?",
    "text": "What is Stata?\nStata is a statistical software package that is commonly used in the social sciences and economics. It is widely used at IPA for data analysis and management. It offers a comprehensive library of methods for data cleaning, descriptive statistics, and econometric analysis. Stata is very well suited for research data workflows and research design tasks, including power calculations, sample design adjustments, panel data analysis, time series analysis, etc. See Stata Features for a full list of what Stata makes available."
  },
  {
    "objectID": "research-design/theory-of-change.html#what-is-a-theory-of-change",
    "href": "research-design/theory-of-change.html#what-is-a-theory-of-change",
    "title": "Theory of Change",
    "section": "What is a Theory of Change?",
    "text": "What is a Theory of Change?\nA Theory of Change (ToC) is a comprehensive description and illustration of how and why a desired change is expected to happen in a particular context. It maps out the logical sequence from activities to outputs to outcomes to impact, making explicit the assumptions underlying each link in the causal chain.\n\nVisual vs. Narrative Representation\n\n\n\n\n\n\nForms of Theory of Change\n\n\n\n\n\nA ToC can be presented as:\n\nVisual diagram: Shows the causal pathways through boxes and arrows\nNarrative description: Written explanation of the change process\nCombination: Visual diagram with accompanying narrative (most effective)\n\nThe visual representation helps stakeholders quickly grasp the overall logic, while the narrative provides essential detail about mechanisms and assumptions.\n\n\n\n\n\nPurpose and Benefits\n\n\n\n\n\n\nWhy Develop a Theory of Change?\n\n\n\n\n\nCommunication: Provides a clear, concise way to explain your program to stakeholders\nAlignment: Creates shared understanding among team members about goals and strategies\nLearning Framework: Identifies what to monitor and evaluate at each stage\nAdaptation: Highlights assumptions to test and refine through implementation",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#components-of-a-theory-of-change",
    "href": "research-design/theory-of-change.html#components-of-a-theory-of-change",
    "title": "Theory of Change",
    "section": "Components of a Theory of Change",
    "text": "Components of a Theory of Change\nA comprehensive ToC consists of five key components that form a logical chain from implementation to impact.\n\nThe Five Essential Components\n\n\n\n\n\n\n1. Activities\n\n\n\n\n\nDefinition: The specific actions your organization implements\nCharacteristics:\n\nUse active verbs (train, provide, deliver, organize)\nSpecify who does what\nExclude internal processes (e.g., planning, procurement)\n\nExample: “Deliver 10 business skills training sessions to caregivers” NOT “Support caregivers”\n\n\n\n\n\n\n\n\n\n2. Outputs\n\n\n\n\n\nDefinition: The direct products of activities\nCharacteristics:\n\nImmediately measurable\nUnder direct control of the program\nOne output per activity\n\nExample: “Caregivers attend and complete 10 training sessions”\n\n\n\n\n\n\n\n\n\n3. Initial Outcomes\n\n\n\n\n\nDefinition: Short-term changes in participants\nTypes of changes:\n\nKnowledge\nAttitudes\nBeliefs\nBehaviors (sometimes)\n\nMeasurement: During or immediately after implementation Attribution: Directly attributable to program activities\n\n\n\n\n\n\n\n\n\n4. Intermediate Outcomes\n\n\n\n\n\nDefinition: Medium to long-term changes resulting from initial outcomes\nCharacteristics:\n\nMay be influenced by external factors\nRequire initial outcomes to be achieved first\nNeed experimental methods to measure causality\n\nExample: “Caregivers apply business skills to increase income”\n\n\n\n\n\n\n\n\n\n5. Final Outcomes/Impact\n\n\n\n\n\nDefinition: Long-term goals of the program\nCharacteristics:\n\nUltimate changes in beneficiaries’ lives\nInfluenced by multiple factors beyond the program\nRequire rigorous evaluation to establish attribution\n\nExample: “Improved economic stability and wellbeing of families”\n\n\n\n\n\nVisual Representation\n\n\n\nTheory of Change Components Diagram",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#characteristics-of-a-strong-theory-of-change",
    "href": "research-design/theory-of-change.html#characteristics-of-a-strong-theory-of-change",
    "title": "Theory of Change",
    "section": "Characteristics of a Strong Theory of Change",
    "text": "Characteristics of a Strong Theory of Change\n\nThe Four Essential Qualities\n\n\n\n\n\n\n1. Active\n\n\n\n\n\nActivities use specific action verbs:\n\n✅ Good: “Train 20 facilitators in child development”\n❌ Weak: “Support child development”\n\nFocus on what the organization does, not internal processes\n\n\n\n\n\n\n\n\n\n2. Clear\n\n\n\n\n\nEach component is distinct and specific:\n\nSame level of detail across components\nOne output per activity\nNo overlapping elements\n\nAll aspects of the program are represented\n\n\n\n\n\n\n\n\n\n3. Logical\n\n\n\n\n\nArrows represent causal relationships, not chronology:\n\nEach link shows how one element causes the next\nThe pathway makes sense conceptually\nNo logical leaps or missing steps\n\nExample:\n\nLogical: Training → Increased knowledge → Applied skills → Higher income\nNot logical: Training → Higher income (missing intermediate steps)\n\n\n\n\n\n\n\n\n\n\n4. Detailed\n\n\n\n\n\nSufficient detail for monitoring and evaluation:\n\nDistinguishes between initial and intermediate outcomes\nIncludes all necessary steps in the causal chain\nSpecific enough to guide measurement\n\nHelps identify:\n\nWhat outputs to monitor during implementation\nWhich outcomes to measure at different stages\nWhen to conduct evaluations",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#assumptions-and-risks",
    "href": "research-design/theory-of-change.html#assumptions-and-risks",
    "title": "Theory of Change",
    "section": "Assumptions and Risks",
    "text": "Assumptions and Risks\nEvery arrow in a Theory of Change represents assumptions about how change happens. Making these explicit is crucial for learning and adaptation.\n\nUnderstanding Assumptions\n\n\n\n\n\n\nWhat Are Assumptions?\n\n\n\n\n\nDefinition: Conditions that must hold true for the causal pathway to work\nExamples:\n\nParticipants will attend sessions if scheduled conveniently\nNew knowledge will be retained and applied\nMarket conditions will remain stable enough for businesses to grow\n\nWhy they matter: Unmet assumptions can break the causal chain\n\n\n\n\n\nIdentifying and Managing Risks\n\n\n\n\n\n\nFrom Assumptions to Risks\n\n\n\n\n\nRisk: A specific threat to an assumption being met\nExamples of improving risk specification:\n\n\n\n\n\n\n\nWeak Risk Statement\nStrong Risk Statement\n\n\n\n\n“Low attendance”\n“Work schedules prevent 40% of participants from attending morning sessions”\n\n\n“Content not relevant”\n“60% of business curriculum doesn’t match local market conditions”\n\n\n“No behavior change”\n“Social norms discourage women from starting businesses independently”\n\n\n\n\n\n\n\n\nPrioritizing Risks\n\n\n\n\n\n\nRisk Assessment Matrix\n\n\n\n\n\nFocus learning efforts on risks that are both:\n\nImportant: Would significantly impact success if they occur\nUncertain: Limited evidence about likelihood or mitigation strategies\n\nPriority quadrants:\n\nHigh importance + High uncertainty = Priority for testing\nHigh importance + Low uncertainty = Standard mitigation\nLow importance + High uncertainty = Monitor only\nLow importance + Low uncertainty = Acknowledge but don’t focus",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#learning-approaches",
    "href": "research-design/theory-of-change.html#learning-approaches",
    "title": "Theory of Change",
    "section": "Learning Approaches",
    "text": "Learning Approaches\nDifferent methods help test assumptions and understand risks at various stages of implementation.\n\n\n\n\n\n\nPiloting\n\n\n\n\n\n\nWhen to use: Before full implementation\nPurpose: Test feasibility and refine approach\nMethods: Small-scale implementation with intensive monitoring\nExample: Test training curriculum with 2-3 groups before scaling\n\n\n\n\n\n\n\n\n\n\nFocus Groups\n\n\n\n\n\n\nWhen to use: Any stage, especially for understanding “why”\nPurpose: Explore perceptions, motivations, and barriers\nMethods: Facilitated group discussions\nExample: Understand why attendance is lower than expected\n\n\n\n\n\n\n\n\n\n\nAdministrative Data Analysis\n\n\n\n\n\n\nWhen to use: During implementation\nPurpose: Track outputs and early outcomes\nMethods: Analyze program records and monitoring data\nExample: Review attendance records to identify patterns\n\n\n\n\n\n\n\n\n\n\nExpert Consultation\n\n\n\n\n\n\nWhen to use: Design phase or when facing specific challenges\nPurpose: Leverage specialized knowledge\nMethods: Interviews or advisory meetings\nExample: Consult labor economists about local market conditions",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#additional-resources",
    "href": "research-design/theory-of-change.html#additional-resources",
    "title": "Theory of Change",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nIPA’s Right-Fit Evidence Resources\nTheory of Change Guidance - UNICEF\nDIY Toolkit: Theory of Change\nContact: 📧 rightfit@poverty-action.org\nActive: Specific action verbs\nClear: Distinct, same-level components\nLogical: Causal relationships make sense\nDetailed: Sufficient for M&E planning",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#using-theory-of-change-for-monitoring-and-evaluation",
    "href": "research-design/theory-of-change.html#using-theory-of-change-for-monitoring-and-evaluation",
    "title": "Theory of Change",
    "section": "Using Theory of Change for Monitoring and Evaluation",
    "text": "Using Theory of Change for Monitoring and Evaluation\n\nMonitoring Focus\n\n\n\n\n\n\nWhat to Monitor\n\n\n\n\n\nOutputs and Initial Outcomes are the focus of monitoring because:\n\nThey’re under program control\nDirectly attributable to activities\nProvide real-time feedback for improvement\n\nKey indicators:\n\nParticipation rates\nCompletion rates\nQuality measures\nImmediate knowledge/attitude changes\n\n\n\n\n\n\nEvaluation Focus\n\n\n\n\n\n\nWhat to Evaluate\n\n\n\n\n\nIntermediate and Final Outcomes require evaluation because:\n\nExternal factors may influence them\nAttribution needs to be established\nLonger time horizons are involved\n\nMethods:\n\nExperimental designs (RCTs)\nQuasi-experimental approaches\nMixed methods to understand mechanisms",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#ipas-right-fit-evidence-approach",
    "href": "research-design/theory-of-change.html#ipas-right-fit-evidence-approach",
    "title": "Theory of Change",
    "section": "IPA’s Right-Fit Evidence Approach",
    "text": "IPA’s Right-Fit Evidence Approach\nIPA’s Right-Fit Evidence (RFE) team has developed practical tools and frameworks for creating and using Theories of Change effectively.\n\nKey Principles\n\n\n\n\n\n\nRight-Fit Evidence Philosophy\n\n\n\n\n\nMatch methods to learning needs:\n\nNot every question needs an RCT\nStart with the decision you need to make\nUse the most efficient method that provides sufficient confidence\n\nIterative learning:\n\nTest assumptions progressively\nAdapt based on evidence\nDocument changes and rationale\n\n\n\n\n\n\nResources and Support\n\n\n\n\n\n\nAvailable Resources\n\n\n\n\n\nTemplates and Tools:\n\nToC development worksheets\nAssumption mapping guides\nRisk prioritization matrices\n\nCapacity Building:\n\nWorkshops on ToC development\nPeer review processes\nCommunity of practice\n\nTechnical Assistance:\n\nDirect support for complex programs\nReview and feedback services\nConnection to subject matter experts",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#common-pitfalls-and-how-to-avoid-them",
    "href": "research-design/theory-of-change.html#common-pitfalls-and-how-to-avoid-them",
    "title": "Theory of Change",
    "section": "Common Pitfalls and How to Avoid Them",
    "text": "Common Pitfalls and How to Avoid Them\n\n\n\n\n\n\nPitfall 1: Too Vague\n\n\n\n\n\nProblem: Using general terms like “improve wellbeing” or “strengthen capacity” Solution: Be specific about what will change and how you’ll measure it\n\n\n\n\n\n\n\n\n\nPitfall 2: Missing Steps\n\n\n\n\n\nProblem: Jumping from training to long-term impact without intermediate steps Solution: Think through each necessary change in the causal chain\n\n\n\n\n\n\n\n\n\nPitfall 3: Overly Complex\n\n\n\n\n\nProblem: Including every possible pathway and outcome Solution: Focus on the main causal pathways; document others separately\n\n\n\n\n\n\n\n\n\nPitfall 4: Static Document\n\n\n\n\n\nProblem: Creating a ToC once and never updating it Solution: Review and revise based on learning; document changes\n\n\n\n–&gt;",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "research-design/theory-of-change.html#additional-resources-1",
    "href": "research-design/theory-of-change.html#additional-resources-1",
    "title": "Theory of Change",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nIPA’s Right-Fit Evidence Resources\nTheory of Change Guidance - UNICEF\nDIY Toolkit: Theory of Change\nContact: 📧 rightfit@poverty-action.org\n\n\n\n\n\n\n\nNote\n\n\n\nAdditional resources: including templates, worksheets, and practical guides, will be available soon in our Resource Library.",
    "crumbs": [
      "Research Design",
      "Theory of Change"
    ]
  },
  {
    "objectID": "software/github/index.html#how-to-install-github-software",
    "href": "software/github/index.html#how-to-install-github-software",
    "title": "GitHub",
    "section": "How to install GitHub Software?",
    "text": "How to install GitHub Software?\nThere are two main options to consider for interacting with GitHub from your local computer:\n\nGitHub Desktop (Recommended)- GUI for working with Git repositories.\nGitHub CLI - Command-line interface for working with Git repositories. For advanced usage.\n\nIf you are new to Git or prefer working with a graphical user interface (GUI), we recommend that you start with GitHub Desktop. The Desktop interface provides a more transparent way of understanding source control and interacting with remote code repositories on GitHub.\n\nWindowsMacOSLinux\n\n\n# Install GitHub Desktop\nwinget install GitHub.GithubDesktop\n\n# Install GitHub Commandline Interface (CLI)\nwinget install GitHub.cli\n\n\n# Install GitHub Desktop\nbrew install --cask github\n\n# Install Github Commandline Interface (CLI)\nbrew install gh\n\n\n# GitHub Desktop not available.\n\n\n# Install GitHub Commandline Interface (CLI)\nbrew install gh",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "GitHub"
    ]
  },
  {
    "objectID": "software/github/index.html#authenticating-github",
    "href": "software/github/index.html#authenticating-github",
    "title": "GitHub",
    "section": "Authenticating GitHub",
    "text": "Authenticating GitHub\n\nGitHub Desktop\nSee instructions here for getting started with GitHub Desktop.\nIn the File menu, select “Options” and then in the “Accounts” options select “Sign in to GitHub.com” and “Continue with browser” to authenticate with your GitHub account.\n\n\n\nGitHub Desktop Authentication\n\n\n\n\nGitHub CLI\nSee the GitHub CLI Manual for more information on how to authenticate with GitHub CLI.\nTo authenticate with GitHub CLI, run the following command in your terminal:\ngh auth login\nThen walk through the prompts:\n\nWhat account do you want to log into? GitHub.com\nWhat is your preferred protocol for Git operations on this host? HTTPS\nAuthenticate Git with your GitHub credentials? (Y/n) Y\nHow would you like to authenticate GitHub CLI? Login with a web browser",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "GitHub"
    ]
  },
  {
    "objectID": "software/github/index.html#using-github",
    "href": "software/github/index.html#using-github",
    "title": "GitHub",
    "section": "Using GitHub",
    "text": "Using GitHub\nWithin a GitHub repository, there are four main aspects that you should be familiar with:\n\nCode: The files and directories that make up your project.\nIssues: A place to discuss and track tasks, bugs, and enhancements for a project.\nPull Requests: A way to propose changes to a repository and discuss them with others.\n\nIn the Code section of a GitHub repository, you can view the files that make up the project codebase. We work with Branches to manage different versions of the codebase. The main branch is the default branch that GitHub uses for the codebase. When you want to make changes to the codebase, you create a new branch from the main branch, make your changes, and then create a Pull Request to merge your changes back into the main branch.\nFor planning changes to the codebase, you can use Issues to track tasks, bugs, and enhancements. Issues can be assigned to team members, labeled, and linked to Pull Requests. Issues can also be used to discuss changes to the codebase before making them.",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "GitHub"
    ]
  },
  {
    "objectID": "software/github/index.html#learning-resources",
    "href": "software/github/index.html#learning-resources",
    "title": "GitHub",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nGitHub Skills provides a lot of relevant resources for learning how to use GitHub. Some good starting points include:\n\nIntroduction to GitHub\nReview Pull Requests\n\nGitHub Foundations Certificate",
    "crumbs": [
      "Software Guides",
      "Version Control",
      "GitHub"
    ]
  },
  {
    "objectID": "software/index.html#what-is-stata",
    "href": "software/index.html#what-is-stata",
    "title": "Software Guides",
    "section": "What is Stata?",
    "text": "What is Stata?\nStata is a statistical software package that is commonly used in the social sciences and economics. It is widely used at IPA for data analysis and management. It offers a comprehensive library of methods for data cleaning, descriptive statistics, and econometric analysis. Stata is very well suited for research data workflows and research design tasks, including power calculations, sample design adjustments, panel data analysis, time series analysis, etc. See Stata Features for a full list of what Stata makes available."
  },
  {
    "objectID": "software/quarto/basics.html#what-makes-quarto-special",
    "href": "software/quarto/basics.html#what-makes-quarto-special",
    "title": "Writing in Quarto",
    "section": "What Makes Quarto Special?",
    "text": "What Makes Quarto Special?\nQuarto lets you combine text, code, and visualizations in a single document. Write regular text and seamlessly include code that runs and displays results.",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#text-formatting-essentials",
    "href": "software/quarto/basics.html#text-formatting-essentials",
    "title": "Writing in Quarto",
    "section": "Text Formatting Essentials",
    "text": "Text Formatting Essentials\n\nBasic Text Styling\n\nCodeResult\n\n\n*This text is italic*\n**This text is bold** \n***This text is bold and italic***\n~~This text has strikethrough~~\n`This is inline code`\n\n\nThis text is italic\nThis text is bold\nThis text is bold and italic\nThis text has strikethrough\nThis is inline code\n\n\n\n\n\nHeaders\n\nCodeResult\n\n\n# Main Title (H1)\n## Section Header (H2)  \n### Subsection Header (H3)\n#### Smaller Header (H4)\n\n\nHeaders create structure and automatic navigation links.",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#lists-for-clear-organization",
    "href": "software/quarto/basics.html#lists-for-clear-organization",
    "title": "Writing in Quarto",
    "section": "Lists for Clear Organization",
    "text": "Lists for Clear Organization\n\nCodeResult\n\n\n# Unordered Lists\n* Research Design\n* Data Collection\n  + Phone Surveys\n  + In-Person Interviews\n* Data Analysis\n\n# Ordered Lists\n1. Design your survey\n2. Collect pilot data\n3. Refine your instrument\n4. Launch full data collection\n\n\nUnordered Lists * Research Design * Data Collection + Phone Surveys + In-Person Interviews * Data Analysis\nOrdered Lists 1. Design your survey 2. Collect pilot data 3. Refine your instrument 4. Launch full data collection",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#code-blocks",
    "href": "software/quarto/basics.html#code-blocks",
    "title": "Writing in Quarto",
    "section": "Code Blocks",
    "text": "Code Blocks\n\nCodeResult\n\n\n# Simple code display\n```\nsummary(data)\nmean(variable)\n```\n\n# With syntax highlighting\n```python\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\nprint(df.head())\n```\n\n# Executable code cells\n\n::: {#6a701b50 .cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nx = [1, 2, 3, 4]\ny = [1, 4, 9, 16]\nplt.plot(x, y)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](basics_files/figure-html/cell-2-output-1.png){width=566 height=411}\n:::\n:::\n\n\n\nSimple Code Display:\nsummary(data)\nmean(variable)\nWith Syntax Highlighting:\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\nprint(df.head())\nExecutable cells run code and show output in your document.",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#callouts",
    "href": "software/quarto/basics.html#callouts",
    "title": "Writing in Quarto",
    "section": "Callouts",
    "text": "Callouts\n\nCodeResult\n\n\n::: {.callout-note}\nThis is a standard note callout.\n:::\n\n::: {.callout-tip title=\"Pro Tip\"}  \nAlways pilot your survey before deployment!\n:::\n\n::: {.callout-warning}\nRemember to back up your data.\n:::\n\n::: {.callout-important appearance=\"simple\"}\nIRB approval required before data collection.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Potential Issues\nClick to expand details...\n:::\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis is a standard note callout.\n\n\n\n\n\n\n\n\nPro Tip\n\n\n\nAlways pilot your survey before deployment!\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember to back up your data.\n\n\n\n\n\n\n\n\nIRB approval required before data collection.\n\n\n\n\n\n\n\n\n\nPotential Issues\n\n\n\n\n\nClick to expand details…",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#tabsets",
    "href": "software/quarto/basics.html#tabsets",
    "title": "Writing in Quarto",
    "section": "Tabsets",
    "text": "Tabsets\n\nCodeResult\n\n\n::: {.panel-tabset}\n\n## Survey Methods\n- Phone surveys\n- In-person interviews  \n- Online questionnaires\n\n## Analysis Tools  \n- Stata for statistical analysis\n- R for data visualization\n- Python for machine learning\n\n## Best Practices\n- Always clean your data\n- Document your methodology\n- Version control your code\n:::\n\n\n\nSurvey MethodsAnalysis ToolsBest Practices\n\n\n\nPhone surveys\nIn-person interviews\n\nOnline questionnaires\nWhatsApp surveys\n\n\n\n\nStata for statistical analysis\nR for data visualization\nPython for machine learning\nExcel for basic calculations\n\n\n\n\nAlways clean your data\nDocument your methodology\nVersion control your code\nShare reproducible results",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#links-and-images",
    "href": "software/quarto/basics.html#links-and-images",
    "title": "Writing in Quarto",
    "section": "Links and Images",
    "text": "Links and Images\n\nCodeResult\n\n\n# Links\n[Visit IPA's website](https://poverty-action.org)\n[Quarto Documentation](https://quarto.org/docs/)\n\n# Images\n![Survey team in Colombia](/assets/images/Colombia_Survey_2020.jpg){width=75%}\n\n\nLinks: Visit IPA’s website and Quarto Documentation\nImages:",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#custom-styling",
    "href": "software/quarto/basics.html#custom-styling",
    "title": "Writing in Quarto",
    "section": "Custom Styling",
    "text": "Custom Styling\n\nCodeResult\n\n\n::: {.border}\nThis content has a border around it.\n:::\n\n::: {.custom-summary-block}\nThis matches the site's summary block styling.\n:::\n\n\n\nThis content has a border around it.\n\n\nThis matches the site’s summary block styling.",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#mathematical-expressions",
    "href": "software/quarto/basics.html#mathematical-expressions",
    "title": "Writing in Quarto",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\n\nCodeResult\n\n\n# Inline math\nThe formula $E = mc^2$ is famous.\n\n# Block equations\n$$\n\\text{Treatment Effect} = \\bar{Y}_{\\text{treatment}} - \\bar{Y}_{\\text{control}}\n$$\n\n\nInline math: The formula \\(E = mc^2\\) is famous.\nBlock equations: \\[\n\\text{Treatment Effect} = \\bar{Y}_{\\text{treatment}} - \\bar{Y}_{\\text{control}}\n\\]",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#tables",
    "href": "software/quarto/basics.html#tables",
    "title": "Writing in Quarto",
    "section": "Tables",
    "text": "Tables\n\nCodeResult\n\n\n| Survey Type | Response Rate | Cost per Response |\n|-------------|---------------|-------------------|\n| Phone       | 65%           | $12               |\n| In-person   | 85%           | $45               |\n| WhatsApp    | 78%           | $3                |\n\n\n\n\n\nSurvey Type\nResponse Rate\nCost per Response\n\n\n\n\nPhone\n65%\n$12\n\n\nIn-person\n85%\n$45\n\n\nWhatsApp\n78%\n$3",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#next-steps",
    "href": "software/quarto/basics.html#next-steps",
    "title": "Writing in Quarto",
    "section": "Next Steps",
    "text": "Next Steps\n\nCreate Professional Documents: Combine these elements for research reports and analysis guides\nCustomize Your Style: Add a brand.yml file for consistent styling Learn more\nShare Your Work: Publish to GitHub Pages, Netlify, or other platforms\nCollaborate: Use version control with Git to track changes\n\n\n\n\n\n\n\nReady to Practice?\n\n\n\nTry creating your own Quarto document using these elements. Start simple with headers, text formatting, and a callout, then add more complex features.",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/quarto/basics.html#learning-resources",
    "href": "software/quarto/basics.html#learning-resources",
    "title": "Writing in Quarto",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nOfficial Documentation\n\nQuarto Guide - Comprehensive documentation covering all features\nAuthoring Guide - Deep dive into markdown and content creation\nPublishing Guide - How to share your documents online\n\n\n\nInteractive Tutorials\n\nHello, Quarto - Quick start tutorial for VS Code\nComputations - Learn to embed code and outputs\nAuthoring - Advanced formatting and features\n\n\n\nExamples and Inspiration\n\nQuarto Gallery - Showcase of real-world Quarto projects\nAwesome Quarto - Community-curated list of resources\n\n\n\nVideo Resources\n\nIntroduction to Quarto - Overview and key features\nAcademic Workflows with Quarto - Research-focused examples\n\n\n\nExtensions and Tools\n\nQuarto Extensions - Add functionality with community extensions\nVS Code Extension - Enhanced editing experience\n\n\n\nCommunity\n\nQuarto Discussions - Ask questions and share tips\nRStudio Community - Active forum for Quarto users",
    "crumbs": [
      "Software Guides",
      "Quarto",
      "Writing in Quarto"
    ]
  },
  {
    "objectID": "software/stata/coding-stata.html#using-stata-files",
    "href": "software/stata/coding-stata.html#using-stata-files",
    "title": "Coding in Stata",
    "section": "Using Stata Files",
    "text": "Using Stata Files\nStata data files are saved with the extension “.dta”. This means the file is ready to use in Stata and unlike data saved in, for example, an excel file, you do not need to import this into Stata.\nTo start using this data in Stata you simply need to type\nuse \"filepath\\filename.dta\", clear\nAdditionally, you will be able to use this dataset in other commands when combining two datasets such as merge or append.\nmerge 1:1 uid using \"statadata.dta\", options\nappend using \"statadata.dta\"`\nIf your file was not already in the stata format you would not be able to call it directly. You would have to import it before you can use it.\n\nSystem Datasets\nStata comes with pre-loaded datasets that you can use to play around to learn new things on. You can see all of the available datasets by going to “File &gt; Example datasets…” or typing help dta_examples. From here you can click the “use” or “describe” buttons to load the dataset and describe them.\nIf you already know the name of the dataset you want to use, you simply need to type sysuse auto.dta for the auto dataset for example to use the data.\n\n\nCreating a dataset in Stata from scratch\nIn Stata, you can create a dataset from scratch. This can be helpful if you want to test some code, learn or check how something works. When working in a clear Stata session, you can use set obs n where n is an integer, to create that many observations in the dataset. From there, you can gen variables set to whatever you are interested in.\nExample to test how to generate a dummy variable as well as using _n to indicate row numbers\n*Clear your stata console\n  clear all\n*Create how many observations you want your dataset to have\n  set obs 10\n*Create variables to test the code you are interested in\n  gen test_dummy = (_n &lt; 5)",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Coding in Stata"
    ]
  },
  {
    "objectID": "software/stata/coding-stata.html#numerical-formats",
    "href": "software/stata/coding-stata.html#numerical-formats",
    "title": "Coding in Stata",
    "section": "Numerical formats",
    "text": "Numerical formats\nIt’s easy to forget that Stata code is operating a computer with very different rules for counting and numbers than we have in the real world. Ado (the language of .do files) allows for a high-level abstraction, where the programmer does not have to explicitly command the computer to do low-level tasks like allocating memory for data, ordering tasks, or defining how the computer should round values that can’t be precisely displayed in binary. This is rarely important, but there are a few cases where these processes, like precision of stored data, is highly relevant for statistical tasks and may need to be specified. The most relevant cases are: - IDs should be stored as string variables or have less than 8 digits if the storage type of the variable is a float - Asserts should only compare similar storage types. - All values in stata (e.g. 1 or `r(N)') are treated as doubles - Merges that do not match IDs across datasets and display bugs (e.g. 1.0000000784732907 in Excel) can be due to the storage type of the variables or values\n\nStata’s process\nVariables in Stata have storage formats and display formats. Storage formats describe how Stata is storing the variable in the computer memory – what the data are – and display formats describes the default way that the information is presented to a user. Type help format in Stata to get more information on how variables or values are displayed.\nStata has five storage formats for numerical variables that take up different amount of memory. These formats store information to a certain degree of accuracy before rounding. The first three types (byte, int, and long) in the table below can only be used for integers. float and double are the standard type. There is a trade-off for increased precision. More precise storage formats take up more memory. This will make the file larger and slow down Stata’s processes when the data are being used.\n\n\n\n\n\n\n\n\nType\nMaximum digits of accuracy\nBytes of memory for a single value\n\n\n\n\nbyte\n2\n1\n\n\nint\n4\n2\n\n\nlong\n9\n4\n\n\nfloat\n7\n4\n\n\ndouble\n16\n8\n\n\n\nThis is extremely relevant when exact equivalence matters. Stata will always conduct functions in double precision (at about 16 digits of precision). Imagine that you are comparing a variable x and a number .1. Stata defaults to generating variables as floats to conserve memory. To process a calculation, Stata will transform the float x into a double and compare that value to the .1 rounded to a double. This causes results that we may not expect for numbers, like .1, that aren’t stored exactly in binary:\n. set obs 1\n. gen x = .1\n. assert x == .1\n  assertion is false\n  r(9);\n. di \"`=float(.1)'\"\n  .1000000014901161\n. di \"`=.1'\"\n  .1\nStata is not making a mistake here. This is the result of .1 not having an exact value in binary (base 2 v. base 10). Since Stata does all calculations in double precision, the rounded value of .1 is different at float precision than double precision. The code that follows shows a few ways to compare these values exactly.\n. ds x, d\n\n              storage   display    value\nvariable name   type    format     label      variable label\n--------------------------------------------------------------------------------------------------------------\nx               float   %9.0g\n\n. assert x == float(.1) // Force Stata to round double(.1) to float(.1)\n\n// force Stata to display the first and only value of x in a double format\n. assert `: di x[1]' == .1\n\n. gen double y = .1 // generate a new variable at double precision\n. assert y == .1\nThis would not be a problem for a value that can be stored exactly such as 1.\nAlthough this seems very abstract and of limited relevance, this will cause problems in the following cases that are often encountered by IPA projects: - IDs have different storage types (one is a float and one is a double for example) in a merge. Stata will not prevent you from making that merge, but will not be able to match the IDs that the programmer intended to be the same. - Numeric IDs will no longer be unique when they have more digits than their storage type can hold (16 for doubles). No numeric IDs will be unique if they have more than 17 digits, especially if the last digits are changing for individuals that should be unique. It’s best to store IDs as strings or keep ID values at the minimum length needed. - asserts that compare a scalar (r(mean)) to a variable stored as a float may not be accurate. This can be corrected by using functions like inrange() or float() as part of the assert.\n\n\nDataset Size & Memory Usage\nThere are a number of concrete ways to avoid this, as well as a lot written on how this affects computation. Memory conservation is generally not relevant for statistical programming with small N survey data that we normally work with at IPA. But this can be the relevant in large datasets where using memory on extraneous digits will slow basic computations substantively. Administrative data with observations in the hundreds of thousands to millions is an example of this that is relevant for many IPA projects.\nIt’s generally good practice to reduce the size of files using compress or by generating values in the smallest format such as gen byte dummy = (q1 == \"Yes\"), especially when the data are larger or if you are performing commands that are computationally intensive for Stata (various regressions, reshaping, etc.).\nIf you are interested in more details, Stata Corp’s blog has a few good articles on numerical precision and why this happens in computing, as well as the specific digits that float precision loses values.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Coding in Stata"
    ]
  },
  {
    "objectID": "software/stata/coding-stata.html#quality-control",
    "href": "software/stata/coding-stata.html#quality-control",
    "title": "Coding in Stata",
    "section": "Quality Control",
    "text": "Quality Control\nOnce you’ve finished cleaning a dataset, take some time to inspect the final product by using a command like codebookout. This command outputs an excel file that is a codebook of your final data including variable names, labels, types, values and value labels. Check that variables are labeled and take on a range of values that make sense.\nAnother helpful command in quality control is assert. You should include many asserts throughout your do files in order to check that your assumptions while cleaning hold. This is especially important if you are going to be collecting more data later.\nFinally, you can use the checklist in this folder to perform checks on your dataset. (To open, click on the link for the checklist and then click “view raw” to download.)\n\nChecking for Consistency Across Datasets\nOnce you have a grasp on the overall organization of a dataset — including the variable names, labels, and formats, as well as the number of observations — it’s time to dive into the relationships among variables and the distribution of values within each variable. Here, you want to check that things make sense. Can someone who said they don’t have a business really be bringing in $1 million in profits each week? Unlikely. Well-programmed surveys should minimize the need for these tests, although they are still good to implement as a check on the quality of the programming.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Coding in Stata"
    ]
  },
  {
    "objectID": "software/stata/coding-stata.html#relative-references",
    "href": "software/stata/coding-stata.html#relative-references",
    "title": "Coding in Stata",
    "section": "Relative references",
    "text": "Relative references\nIt is important to ensure that code can be run on multiple computers, and that code will not require hours of repair if a folder is renamed. To do this, we use relative references for file paths. The principle behind this is simple: any time a file (data, log file, another piece of code, etc.) is references in the script, the code only specifies the name of the file and some shorthand for the filepath. This shorthand will vary depending on the software used and the preferences of the analyst. In Stata, this is generally a global macro. Scripts that modify data should avoid calling any absolute file paths to ensure that any script is as flexible as possible to changes in the file path.\nFor example, if I am loading data from “C:/My Documents/My Project Folder/data.dta”, I could type use \"${relative_reference}/data.dta\" if I had defined a global called relative_reference that contained C:/My Documents/My Project Folder. In this example, I would have defined that global to save the file path somewhere earlier in the script. One thing to note is that this global uses the entire file path. A relative reference such as ${directory}/My Project Folder/data.dta introduces more possibility for error by including an absolute name of a folder. Full file paths used in the project should preferable be saved as globals or called using macro extended functions.\nThere are multiple ways to make relative references including local and global macros, setting working directories, or user written commands in Stata such as fastcd. We suggest defining global macros in the master do file or a specific global.do do file so that file paths are set in one location and are able to be called at any point during the dataflow.\n\nSetting Relative References in Stata\nTo define relative references, do files can define a global for a particular path and then use the macro name throughout to refer to the set path.\n*Set directory path\nglobal path \"C:/My Documents/My Project Folder\"\n\n*Set folder directories\nglobal data \"${path}/01_data\"\nglobal dos  \"${path}/02_do\"\nThen, whenever we call a particular file, we include the correct file path:\n*Run cleaning do file\ndo \"${dos}/clean.do\"\n\n*Use clean data:\nuse \"${data}/clean.dta\"\nNote that this names the directory where all project files are stored as the first global. After that it names relative references for each folder that contains files used by the do file using the global that contains the location of the project folder. This two-step process makes it easier to modify the do file for multiple users. Generally, the only folder that will be unique between users is the file path before the project folder (e.g. C:\\Users\\[username] is a common prefix that will change based on the username on Windows machines).\n\n\nWorking Default References\nWhat if someone new uses the project that you don’t know their username? Often, it may not be possible to match a system variables stored by Stata to a unique identify a user. There are multiple solutions to this problem. Some master do files will start with a local user command that defines who the user is and sets relative references using a conditional:\n*Define user\nloc user Me\n\n*Set project folder directory\nif \"`user`\" == \"Me\" {\n    global directory \"C:/My Documents/My Project Folder/\"\"\n}\nHowever, this requires manual management in the do file any time a new user is added to a project. To create a general case, the do file can take advantage of how Stata defines a project. When Stata is opened, State defaults to assigning a working directory by first, the location of the file being opened by Stata and second, the homepath in the profile.do file.\nWe suggest using `c(pwd)’ as a stand-in for file location and assume the user had opened the master do file: If you add this as an else at the end of the if \"`user'\"== conditionals, then there is a good chance the do file will run even if you haven’t made a specific local for the user.\n*Set default directory\nelse {\n    global directory = subinstr(\"`c(pwd)'\", \"\\\", \"/\" ,.)\n    global directory = subinstr(\"`cdloc'\", \"/02_do\", \"\", .)\n}\nThis will not work if the instance of Stata is opened from a file in a different directory than the do file that contains the code shown above. Text editors such as Atom and Sublime preserve the same instance of Stata. This code will be more likely to cause an error if the user does not use the do file editor or opens do files from the command line with doedit.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Coding in Stata"
    ]
  },
  {
    "objectID": "software/stata/coding-stata.html#useful-stata-commands",
    "href": "software/stata/coding-stata.html#useful-stata-commands",
    "title": "Coding in Stata",
    "section": "Useful Stata commands",
    "text": "Useful Stata commands\nBelow we have listed some frequently overlooked commands that we enjoy using. They will make your life a lot easier if you know about them. We provide a quick summary of what the commands do and where they can be used.\nWhere we appropriate, there is a page dedicated to specific commands that provides more examples of our common uses tips and tricks, and potential concerns to be aware of when using these particular command. For full documentation simply type help [commandname] in Stata to read all about available options and examples for usage.\n\nfillin\nThis is a simple to use, but yet powerful command. Frequently in cleaning data sets, you will have an unbalanced panel, i.e. you are missing an observation for one person for some time periods. For example, imagine you have a dataset of your sample that is supposed to have one observation for each survey round such as the baseline and two endlines. However, as is common, some people were not found in the endline surveys and thus there is no observation for them at that endline. You can use this command to create all of the pairwise combinations of values of two variables i.e. you would have every survey round observation for every person.\nFrequently in cleaning data sets, you will have an unbalanced panel, i.e. you are missing an observation for one person for some time periods. For example, imagine you have a dataset of your sample that is supposed to have one observation for each survey round such as the baseline and two endlines. However, as is common, some people were not found in the endline surveys and thus there is no observation for them at that endline. See the example data below where you can see person 1 is missing an observation at endline 2.\n\n\n\nID\nSurvey_Round\nGender\n\n\n\n\n1\nbaseline\nFemale\n\n\n1\nendline1\nFemale\n\n\n2\nbaseline\nMale\n\n\n2\nendline1\nMale\n\n\n2\nendline2\nMale\n\n\n\nWe can use fillin ID Survey_Round to get the following\n\n\n\nID\nSurvey_Round\nGender\n_fillin\n\n\n\n\n1\nbaseline\nFemale\n0\n\n\n1\nendline1\nFemale\n0\n\n\n1\nendline2\n.\n1\n\n\n2\nbaseline\nMale\n0\n\n\n2\nendline1\nMale\n0\n\n\n2\nendline2\nMale\n0\n\n\n\nA couple things to note: 1. This command automatically creates an indicator variable called \\_fillin that keeps track of observations that were created from the command 2. Variables not specified in the fillin are filled in with a missing value. So after you run fillin you will need to go back and replace observations as you see appropriate. For example, for typically constant variables such as gender you could replace this new missing value to match the one above it.\nsort ID Survey_Round\nreplace Gender = Gender[_n-1] if ID == ID[_n-1] & _fillin == 1\n\n\nlabeldup\nlabeldup is a user-written command that compares value labels which have duplicate contents. For example, if in your dataset the variable q1 has a value label named q1_label with 0 \"No\" 1 \"Yes\" and the variable q2 has the same value label (the SurveyCTO standard). By using labeldup, select, the q1 and q2 will be combined to a single value label that describes both variables. This is an easy way to cut down on duplicate information in value labels.\n\n\nlabelrename\nThis user-written command allows you to rename value labels using similar syntax to the rename command. Stata does not allow you to rename value labels using the label values command. This command adds that functionality with the similar syntax as the rename command. One difference is that no wildcards are allowed.\n\n\nlevelsof\nThis command will provide you with a list of all of the unique values of a variable. This comes in handy all of the time when cleaning. A very helpful option that comes with this command is local() in which you can store the list of values as a local. This makes looping through all of the values of a variable possible and easy.\n\n\nlookfor\nThis command searches across all variable names and variable labels, and allows for searching for more than one string or a phrase through the use of \"[string]\". Since lookfor searches across both variable names and variable labels at the same time, it will return a different set of results than ds can.\n\n\nmissing\nThis is not a built-in Stata command and thus you will need to type ssc install missing to get this command before you can use it or read the help file.\nThis group of commands allows for several ways to investigate the missing values in variables. Missing values are typically forgotten about or ignored, but that is a big mistake. They can complicate cleaning and analysis greatly. You should be aware of the missing values and variables in your dataset. This command includes ways to report, list, tag, and drop missing values and variables.\nA very helpful command within this group is missing dropvars which allows you to eliminate variables that are missing on all observations. This is much easier than looping through vars and obs to assert they are missing to drop them.\n\n\nmmerge\nThis is not a built-in Stata command and can be installed by typing ssc install mmerge.\nmmerge provides additional options for merge that make merging datasets more user friendly by removing a signfiicant amount of preprocessing work for complex datasets: - It allows for missing values in the match variable and let’s the user determine how they are treated with the missing() option. - It allows for differing merge variable names with the umatch() option - It allows for all merged variables from the using file to be prefixed as part of the merge with the uname() option - It stores shared variable names that are not merged in a local r(common)\nThere are a number of other options and syntax changes. You can see these by typing help mmerge once mmerge is installed.\n\n\nreturn list\nThis command allows you to see all of the stored results in working memory and their value. For example, if you ran summarize [variarble], the return list command would show all of the scalars stored by summarize. In this case that would be r(N), r(sum_w), and r(sum). Similar commands also allow you to see estimation and system commands using ereturn list and creturn list. The help file (help return list) shows more options.\n\n\nsencode\nThis is not a built-in Stata command and can be installed by typing ssc install sencode.\nsencode makes a number of improvements on the Stata command encode by including a options that allow you to replace the string variable with the numeric variable and set the order of encded values in a user-specified ways, among other user-friendly additions.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Coding in Stata"
    ]
  },
  {
    "objectID": "software/stata/data-exploration-stata.html",
    "href": "software/stata/data-exploration-stata.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "software/stata/index.html",
    "href": "software/stata/index.html",
    "title": "Getting Started with Stata",
    "section": "",
    "text": "Stata is a general-purpose statistical software package developed by StataCorp and used for data manipulation, visualization, and statistical analysis. It is used by lots of researchers in different fields of study. Although there are other statistical software – including R, SAS, SPSS and Python – Stata is the primary statistical tool used at IPA due to its flexibility and ease of use and also because it is most widely used by social science researchers. Over the years, IPA and J-PAL have developed a lot of training materials and user-written programs for Stata—this course is based on the work of many colleagues across many countries and projects.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#why-use-stata",
    "href": "software/stata/index.html#why-use-stata",
    "title": "Getting Started with Stata",
    "section": "Why use Stata?",
    "text": "Why use Stata?\nWhile spreadsheet software – like Microsoft Excel – is widely available and easy to use, these often lack the flexibility and sophistication required for complex statistical analyses. Stata, on the other hand, is a powerful statistical software package that provides a wide range of tools and capabilities for data analysis and management. Some of Stata’s capabilities as a statistical software include:\n\nAbility to handle large and complex datasets\nPowerful data management and cleaning tools\nExtensive library of statistical procedures\nAn active user community with a wide range of resources\nHigh-quality graphics and visualization tools\nCompatibility and integration with a wide range of file formats, including Excel, CSV, and SAS\nExtensive documentation and user guides\nRegular updates and improvements to keep up with new methods.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#installing-stata",
    "href": "software/stata/index.html#installing-stata",
    "title": "Getting Started with Stata",
    "section": "Installing Stata",
    "text": "Installing Stata\nIf Stata requires purchasing or securing a license from StataCorp. At IPA, staff have access to an instutional license. Once you have a licenses, you should install the relevant version for your computer.\n\n\n\n\n\n\nTip\n\n\n\nRemember that Stata can be installed on any computer owned by IPA. IPA staff can manage this installation directly—you do not need to request support from IPA’s Technology team unless you encounter a problem. Please note that IPA’s Stata license should only be used on IPA devices and should not be installed on your personal computers.\nIPA staff can download and install the relevant version (.exe for Windows, .dmg for MacOS, or .tar.gz for Linux) from IPA Box installation documentation.\nAlso note that Stata is not currently available for mobile devices. If you encounter problems after carefully reviewing all instructions, send an email to the IPA Technology team at support@poverty-action.org.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#the-stata-interface",
    "href": "software/stata/index.html#the-stata-interface",
    "title": "Getting Started with Stata",
    "section": "The Stata Interface",
    "text": "The Stata Interface\nStata’s interface is designed to provide users with a user-friendly environment that allows them to interact with the software and perform statistical analyses efficiently. That being said, there are several windows and tools (explained below) that you can use to interact with the software and conduct your work.\n\n\n\nStata’s User Interface\n\n\n\n\nCommand window: Displays the output of commands executed in the command window. This includes tables, graphs, and other results generated by Stata. In other words, all the results from your analyses appear here.\nResults window: Displays the output of commands executed in the command window. This includes tables, graphs, and other results generated by Stata. In other words, all the results from your analyses appear here.\nHistory window: This is your command history, and it shows all commands you have typed during your Stata session and all commands Stata created for you when you work with the GUI.\nVariables window: The variables window displays information about the variables in the dataset currently loaded in Stata. Users can view the variable name, label, type, and properties, among other information.\nProperties window: You can use this window to manage your variables, including their names, labels, value labels, notes, formats, and storage types.\n\n\nBesides the five main windows, Stata offers other specialized tools and features to help with your data-related work. Some of these include the project manager, the data and graph editors, and the do-file. More on these later.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#interacting-with-stata",
    "href": "software/stata/index.html#interacting-with-stata",
    "title": "Getting Started with Stata",
    "section": "Interacting with Stata",
    "text": "Interacting with Stata\nYou can use the menus and toolbars contained in Stata’s graphical user interface rather than writing code to perform common tasks, such as opening datasets, running statistical analyses, and creating graphs. We refer to this method as point-and-click. To execute a specific task, you can simply click on the “Run” button in the toolbar.\n\n\n\nExample of point-and-click interaction\n\n\nHowever, a more typical (and recommended) approach involves typing “commands” into the program to manipulate and analyze large quantities of data; we refer to this as the commandline. This may feel unfamiliar if you don’t have a background in statistical analysis or coding, but most data-oriented professionals use the command-line approach as it eliminates the need to navigate menus and toolbars. It also allows for easier automation and scripting of analyses, which can be helpful for more advanced users.\n\n\n\nExample of Stata commands",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#statas-command-syntax",
    "href": "software/stata/index.html#statas-command-syntax",
    "title": "Getting Started with Stata",
    "section": "Stata’s command syntax",
    "text": "Stata’s command syntax\nStata syntax is the language we use to communicate with Stata. This means that, as with any other language, we need to learn it, understand it, and use it for effective communication with the software. The standard syntax of Stata commands is as follows:\n[by varlist]: command [varlist] [=exp] [if exp] [in range] [weight] [using filename][, options]\nWhere varlist denotes a list of variable names, command denotes a Stata command, exp denotes an algebraic expression, range denotes an observation range, weight denotes a weighting expression, and options denotes a list of command-specific options. In other words, this means that any Stata command we run is accompanied by multiple options in brackets, [], that alter the output we receive from said command. Other than the command itself, everything in brackets is optional.\n\n\n\n\n\n\nStata is case sensitive!\n\n\n\nAnother important thing about syntax: Stata commands and syntax never come in CAPITAL LETTERS. Therefore, always use small letters when typing Stata commands.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#setting-up-a-working-directory",
    "href": "software/stata/index.html#setting-up-a-working-directory",
    "title": "Getting Started with Stata",
    "section": "Setting up a working directory",
    "text": "Setting up a working directory\nWhile working in Stata, you will often need to import or export files into directories – or folders – on your computer. When importing or exporting a file, you need to indicate the location in which the file can be found or saved so that Stata is able to pinpoint the exact file you are looking for or output to the exact folder that you want. In this section, we will explore how Stata handles file directories.\nWhenever you open up Stata, Stata sets a default directory. You can see this directory at the bottom left corner of the Stata window.\n\n\n\nStata Working Directory\n\n\nStata also provides a convenient command for displaying your current directory. Type the following into your Command window:\npwd\nYou will notice that Stata has displayed the same directory that is displayed at the bottom left of your Stata window. This directory is your current working directory—whenever you try to import or export in Stata without specifying a directory, Stata will assume that this is the one you mean. You can also list the names of the files and folders of your current working directory by using the following commands:\ndir\nls\nFor most projects, you will want to change your working directory to a folder that contains the files you want to work with. You can change your current working directory using the cd command. Pull up and read the help file for the following command:\ncd \"target folder\"",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#absolute-vs.-relative-paths",
    "href": "software/stata/index.html#absolute-vs.-relative-paths",
    "title": "Getting Started with Stata",
    "section": "Absolute vs. Relative Paths",
    "text": "Absolute vs. Relative Paths\nWhen working with Stata, it is important to keep a good file system that allows you to easily find project files and subfolders that you may be looking for. Sometimes you may be working alone and can set all your paths with only your own workspace in mind. However, in most cases you will want to write your Stata code in a way that makes it replicable on other computers without additional setup.\nA relative path denotes a file path in relation to the current working directory, while an absolute path denotes a file’s path at a fixed location on a disk. In most cases, you want to use relative paths. Examine the folder shown below. Take notice of the path at the top as well as the subfolders in this folder.\n\n\n\nAbsolute vs. Relative Paths in Stata\n\n\nLet’s assume that your current working directory in Stata is D:\\Files\\Data Cleaning\\Main Data, which is the folder in the picture above. You want to navigate within Stata to the 1 dofiles subfolder. You could achieve this using either of the following codes:\n* Option 1\ncd \"D:\\Files\\Data Cleaning\\Main Data/1 dofiles\"\n\n* Option 2\ncd \"1 dofiles\"\nCode option 1 is an example of using an absolute path; it directs Stata to an exact location every single time you run this code. This means that regardless of your current working directory in Stata, you can always switch to this target directory using Code option 1. However, this code may not work on another computer unless the other user has the Main Data folder located in the path D:\\Files\\Data Cleaning.\nCode option 2 directs Stata to the same folder using a relative path. Based on this code, Stata will assume that you want to move to a folder named 1 dofiles which is located in your current working directory. This code will only work if your current working directory contains the folder 1 dofiles.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "software/stata/index.html#loading-a-dataset",
    "href": "software/stata/index.html#loading-a-dataset",
    "title": "Getting Started with Stata",
    "section": "Loading a dataset",
    "text": "Loading a dataset\nWhen working in Stata, you will work with datasets from different sources and in different formats. Stata provides a list of commands for importing and exporting various data in various formats including Excel spreadsheets (.xls and .xlsx files), text files, and datasets from other software such as SPSS and SAS. Stata can also create and store data in a Stata-format dataset with the filename extension .dta. The .dta format is the primary format you will use when storing and analyzing data in Stata.\nThere are several ways to import a dataset into Stata, including:\n\nThe use command\nUsing File &gt; Open in the menu bar to select a file\nClicking on the “Open” icon – which looks like a folder – in the Menu bar to select a file.\nDouble clicking on the dataset within your computer’s file directory to open a new Stata session with the dataset already loaded\n\nIn most applications, we should be using the use command. For example, let’s download a sample dataset into our current working directory using this command:\ncopy \"https://raw.githubusercontent.com/PovertyAction/IPA-Stata-Trainings/master/Stata%20101/Data/intro.dta\" \"intro.dta\", replace\nNote that you will not see a change in your Stata display after running this command. If you open the folder that you have designated as the current working directory, you should now see a .dta file (marked with the Stata icon) titled intro.dta.\nNext, import this dataset from the current working directory into Stata. To do this, use the use command to import the dataset intro.dta as follows:\nuse \"intro.dta\", clear\n\n\n\n\n\n\nTip\n\n\n\n\nBecause the file is located in your current working directory, you do not need to specify the file path.\nIf you already have a different dataset loaded in Stata’s memory, you will need to include the , clear option as part of your command.\n\n\n\nThe use command also works directly with URLs. Let’s re-import the intro dataset straight from the GitHub website by running the following code in Stata:\nuse \"https://raw.githubusercontent.com/PovertyAction/IPA-Stata-Trainings/master/Stata%20101/Data/intro.dta\", clear\nYou will see that Stata has automatically detected and imported the dataset directly from the website without you needing to download it first.",
    "crumbs": [
      "Software Guides",
      "Stata",
      "Getting Started with Stata"
    ]
  },
  {
    "objectID": "under-construction.html",
    "href": "under-construction.html",
    "title": "Research & Data Science Hub",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Research Design",
      "Measurement 🚧"
    ]
  }
]