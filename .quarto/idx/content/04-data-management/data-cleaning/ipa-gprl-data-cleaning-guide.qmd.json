{"title":"IPA/GPRL Data Cleaning Guide","markdown":{"yaml":{"title":"IPA/GPRL Data Cleaning Guide","authors-ipa":null,"contributors":["[Cristhian Pulido](https://poverty-action.org/people/cristhian-pulido)"]},"headingText":"About the guide","containsRefs":false,"markdown":"\n\n:::{.subtitle-style}\nThis guide outlines best practices in data cleaning, primarily concentrating on converting raw survey data into usable data for analysis of RCTs using Stata.\n:::\n\n\n\nProper data cleaning is essential for analytical accuracy. Raw data needs to be modified before it can be used for data analysis. These modifications are called cleaning. The cleaning process should always be reproducible, well documented, and defensive – the code should tell the user if the data isn’t as expected.\n\nThis guide outlines best practices in data cleaning, primarily concentrating on converting raw survey data to usable data for analysis of RCTs using Stata. The scope of the guide is to cover the principles of cleaning data over a project lifecycle with the goal of producing clean data in an accurate and reproducible fashion. The guide does not cover best practices in designing surveys, coding, or conducting data analysis.\n\nIn each section, we describe a set of common tasks and provide information on “what” this step is and “how” we suggest this step is completed in Stata. We also flag potential complexities. This guide assumes basic knowledge of Stata (introductory Stata training can be found [here](https://github.com/PovertyAction/IPA-Stata-Trainings)).\n\nAs part of this guide, we briefly cover other parts of the data flow, including coding best practices, deidentification, and version control. In many ways these topics are distinct from data cleaning, but all interrelate to some extent. Effective data cleaning will follow coding best practices, have a version control system, and be well documented.\n\n## Data flow\n\nAt a high-level, the process that data goes through from when it is generated, in a survey or from an automated banking systems, is a transition from a format that reflects the structure of what is collecting the data to a structure that can be used for analyzing the information. The contents of the data do not change during this process, but the format in which they’re stored, aggregated, and labeled do.\n\nThis entire process is called a data flow. At GPRL and IPA, we think of the steps in the data flow that take place in statistical software in the four steps below. It is worth noting that differences in the data may make it impossible to follow this order exactly. Generally, deidentification should happen as soon as possible in the data flow if the data contains PII:\n\n![Data Flow Process](/assets/images/data-flow.png){fig-cap=\"Data Flow Process\" width=75%}\n\n:::{.custom-ol}\n1. **Import data** – all collected data is combined into a format readable by statistical software. In this step, the raw data is imported, corrections from enumerators are applied, and duplicates observations are removed.\n2. **Deidentify data** – personally identifying information (PII) is removed. This includes all individually identifying PII (geographic information, names, addresses, enumerator comments, etc.), as well as group identifying information (a combination of village and birthdate for example).\n3. **Clean data** – data content, formats, and encoding is standardized. After this, data consistency is verified and similar datasets are appended to create single datasets used to create outcomes.\n4. **Create outcomes** – individual outcome variables are created from the clean data. Data are merged and appended as part of this project to make a dataset at the level of analysis needed.\n:::\n\n## Data cleaning\nIt goes without saying that raw data cannot be used for analysis. Individual survey items will not be informative on their own in most cases. Outcome variables need to be created from standardized sets of variables. In addition, documentation needs to be added so users of the data are clear on what each dataset contains.\n\nRaw data often needs corrections and deduplication that often requires additional data from enumerators or respondents. We view data collection for replacement as part of the data collection process. Often, these replacements are collected and made as part of the monitoring process. IPA and GPRL produced many tools and resources to help this process. In particular, [IPA’s Data Management System](https://github.com/PovertyAction/high-frequency-checks) supports data quality monitoring, duplicate management, and corrections.\n\nOnce data is in a format to be imported, the raw data will have its own idiosyncrasies. The cleaning process attempts to standardize these idiosyncrasies in a reproducible way. Imagine you have three surveys each with slightly different outputs. Cleaning would make the output from those datasets equivalent in format, and standardized modifications made to the content. The code that produces those data should be able to be run any number of times and should tell the user if something about the data has changed so that it can’t accomplish its function.\n\nWe find it useful to think about the cleaning processing in four rough stage:\n\n* Raw Survey Data Management\n* Variable Management\n* Dataset, Value, and Variable Documentation\n* Data Aggregation\n\nEach of these stages has a description in the guide, as well as a list of tasks which each has a subpage in the guide. In addition, this guide briefly touches on Stata coding practices relevant to this process, as well as some tasks related to outcome creation that require data management and are particularly prone to error in Stata.\n\n\n","srcMarkdownNoYaml":"\n\n:::{.subtitle-style}\nThis guide outlines best practices in data cleaning, primarily concentrating on converting raw survey data into usable data for analysis of RCTs using Stata.\n:::\n\n\n## About the guide\n\nProper data cleaning is essential for analytical accuracy. Raw data needs to be modified before it can be used for data analysis. These modifications are called cleaning. The cleaning process should always be reproducible, well documented, and defensive – the code should tell the user if the data isn’t as expected.\n\nThis guide outlines best practices in data cleaning, primarily concentrating on converting raw survey data to usable data for analysis of RCTs using Stata. The scope of the guide is to cover the principles of cleaning data over a project lifecycle with the goal of producing clean data in an accurate and reproducible fashion. The guide does not cover best practices in designing surveys, coding, or conducting data analysis.\n\nIn each section, we describe a set of common tasks and provide information on “what” this step is and “how” we suggest this step is completed in Stata. We also flag potential complexities. This guide assumes basic knowledge of Stata (introductory Stata training can be found [here](https://github.com/PovertyAction/IPA-Stata-Trainings)).\n\nAs part of this guide, we briefly cover other parts of the data flow, including coding best practices, deidentification, and version control. In many ways these topics are distinct from data cleaning, but all interrelate to some extent. Effective data cleaning will follow coding best practices, have a version control system, and be well documented.\n\n## Data flow\n\nAt a high-level, the process that data goes through from when it is generated, in a survey or from an automated banking systems, is a transition from a format that reflects the structure of what is collecting the data to a structure that can be used for analyzing the information. The contents of the data do not change during this process, but the format in which they’re stored, aggregated, and labeled do.\n\nThis entire process is called a data flow. At GPRL and IPA, we think of the steps in the data flow that take place in statistical software in the four steps below. It is worth noting that differences in the data may make it impossible to follow this order exactly. Generally, deidentification should happen as soon as possible in the data flow if the data contains PII:\n\n![Data Flow Process](/assets/images/data-flow.png){fig-cap=\"Data Flow Process\" width=75%}\n\n:::{.custom-ol}\n1. **Import data** – all collected data is combined into a format readable by statistical software. In this step, the raw data is imported, corrections from enumerators are applied, and duplicates observations are removed.\n2. **Deidentify data** – personally identifying information (PII) is removed. This includes all individually identifying PII (geographic information, names, addresses, enumerator comments, etc.), as well as group identifying information (a combination of village and birthdate for example).\n3. **Clean data** – data content, formats, and encoding is standardized. After this, data consistency is verified and similar datasets are appended to create single datasets used to create outcomes.\n4. **Create outcomes** – individual outcome variables are created from the clean data. Data are merged and appended as part of this project to make a dataset at the level of analysis needed.\n:::\n\n## Data cleaning\nIt goes without saying that raw data cannot be used for analysis. Individual survey items will not be informative on their own in most cases. Outcome variables need to be created from standardized sets of variables. In addition, documentation needs to be added so users of the data are clear on what each dataset contains.\n\nRaw data often needs corrections and deduplication that often requires additional data from enumerators or respondents. We view data collection for replacement as part of the data collection process. Often, these replacements are collected and made as part of the monitoring process. IPA and GPRL produced many tools and resources to help this process. In particular, [IPA’s Data Management System](https://github.com/PovertyAction/high-frequency-checks) supports data quality monitoring, duplicate management, and corrections.\n\nOnce data is in a format to be imported, the raw data will have its own idiosyncrasies. The cleaning process attempts to standardize these idiosyncrasies in a reproducible way. Imagine you have three surveys each with slightly different outputs. Cleaning would make the output from those datasets equivalent in format, and standardized modifications made to the content. The code that produces those data should be able to be run any number of times and should tell the user if something about the data has changed so that it can’t accomplish its function.\n\nWe find it useful to think about the cleaning processing in four rough stage:\n\n* Raw Survey Data Management\n* Variable Management\n* Dataset, Value, and Variable Documentation\n* Data Aggregation\n\nEach of these stages has a description in the guide, as well as a list of tasks which each has a subpage in the guide. In addition, this guide briefly touches on Stata coding practices relevant to this process, as well as some tasks related to outcome creation that require data management and are particularly prone to error in Stata.\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../assets/styles.css"],"toc":true,"output-file":"ipa-gprl-data-cleaning-guide.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"Search","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","theme":{"light":["cosmo","../../../assets/light-theme.scss"],"dark":["cosmo","../../../assets/dark-theme.scss"]},"template-partials":["../../../assets/toc.html"],"grid":{"sidebar-width":"385px","body-width":"675px","margin-width":"350px","gutter-width":"2.5rem"},"title":"IPA/GPRL Data Cleaning Guide","authors-ipa":null,"contributors":["[Cristhian Pulido](https://poverty-action.org/people/cristhian-pulido)"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}