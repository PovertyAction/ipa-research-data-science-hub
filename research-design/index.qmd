---
title: "Research Design"
abstract: "Essential considerations for designing rigorous impact evaluations, from theoretical foundations to practical implementation strategies for randomized controlled trials and quasi-experimental studies."
date: last-modified

authors-ipa:
  - "[Niall Keleher](https://poverty-action.org/people/niall-keleher)"

contributors:
  - "[David Torres](https://poverty-action.org/people/david-francisco-torres-leon)"
  - "[Cristhian Pulido](https://poverty-action.org/people/cristhian-pulido)"

keywords:
  - research design
  - theory of change
  - impact evaluation
  - randomized controlled trials
  - experimental design
  - causal inference
  - explanation

license: "CC BY"
---

Research design is a key ingredient for reliable, policy-relevant research and data science projects. It determines whether you can credibly measure and attribute observed changes to your intervention, rather than to other factors. This page provides an overview of key research design considerations and links to detailed guidance on specific topics.

## Core Research Design Elements

Every research and data science project must address several fundamental questions that determine the strength and credibility of your findings:

### Theory of Change and Causal Pathways

Before designing your project -- whether exploratory analysis, predictive modeling, or causal inference -- you need a clear understanding of your research context. You also need to understand how change occurs within that context. A **Theory of Change** maps the logical sequence from program activities to intended outcomes, making explicit the assumptions that underlie each step.

**Key considerations:**

- What specific changes do you expect to see?
- What are the key assumptions about how change happens?
- What risks could break the causal chain?

ðŸ‘‰ **Learn more:** [Theory of Change](theory-of-change.qmd)

### Statistical Power and Sample Size

Your study must be adequately powered to detect meaningful effects. This requires careful consideration of the minimum effect size worth detecting, expected variability in outcomes, and practical constraints.

**Key considerations:**

- What is the minimum detectable effect that would be policy-relevant?
- What sample size do you need to achieve adequate statistical power?
- How will attrition and non-compliance affect your power?

ðŸ‘‰ **Learn more:** [Sample and Power Calculations](sample-size-power.qmd) | [How-to Guide to Power Calculations](how-to-power-calculation.qmd)

### Randomization Strategy

The method of assigning participants to treatment and control groups is crucial for causal identification. The right approach depends on your intervention, context, and implementation constraints.

**Key considerations:**

- Should you randomize at the individual or cluster level?
- Do you need stratification to ensure balance on key characteristics?
- How will you handle spillovers between treatment and control groups?

ðŸ‘‰ **Learn more:** [Randomization](randomization.qmd) | [How-to Guide to Randomization](how-to-randomization.qmd)

### Measurement Strategy

Valid and reliable measurement of outcomes is essential for credible impact evaluation. This involves both technical considerations about instruments and practical considerations about data collection.

**Key considerations:**

- Which outcomes should you measure and when?
- How will you ensure measurement validity and reliability?
- What baseline data do you need for analysis and balance checks?

ðŸ‘‰ **Learn more:** [Measurement](measurement.qmd)

## Research Design Process

Designing a rigorous research and data science project involves several interconnected steps:

### 1. Define Your Research Questions

Start with clear, specific questions about what you want to learn. Policy needs and your Theory of Change should tell you what questions to ask.

### 2. Choose Your Identification Strategy

Decide how you will establish causal attribution. Randomized experiments offer the strongest identification, but quasi-experimental methods may be necessary in some contexts.

### 3. Plan Your Implementation

Consider practical constraints and implementation challenges that might affect your design. This includes compliance, attrition, spillovers, and logistical feasibility.

### 4. Design Your Analysis Plan

Pre-specify your analysis approach, including primary outcomes, estimation methods, and strategies for handling missing data or non-compliance.

### 5. Consider Ethical Implications

Ensure your design meets ethical standards for research with human subjects, including considerations of balance, informed consent, and potential harms.

## Getting Started

When beginning a new impact evaluation:

1. **Start with your Theory of Change** to understand the causal pathways you want to test
2. **Conduct power calculations** early to understand sample size requirements
3. **Choose your randomization strategy** based on your intervention and context
4. **Plan your measurement approach** to ensure you can test your key hypotheses
5. **Consider implementation challenges** that might affect your design

Remember that research design is iterative. You may need to revisit and refine your approach as you learn more about the intervention and context.
